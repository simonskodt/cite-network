<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dcat%3Acs.%2A%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=cat:cs.*&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api//Sr0Ktnalppie/A9qvr4BIZuOfQ</id>
  <updated>2024-10-27T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">683485</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/cs/9904016v1</id>
    <updated>1999-04-22T15:47:22Z</updated>
    <published>1999-04-22T15:47:22Z</published>
    <title>Brittle System Analysis</title>
    <summary>  The goal of this paper is to define and analyze systems which exhibit brittle
behavior. This behavior is characterized by a sudden and steep decline in
performance as the system approaches the limits of tolerance. This can be due
to input parameters which exceed a specified input, or environmental conditions
which exceed specified operating boundaries. An analogy is made between brittle
commmunication systems in particular and materials science.
</summary>
    <author>
      <name>Stephen F. Bush</name>
    </author>
    <author>
      <name>John Hershey</name>
    </author>
    <author>
      <name>Kirby Vosburgh</name>
    </author>
    <link href="http://arxiv.org/abs/cs/9904016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9904016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2;C.4;B.8;F.2;H.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701021v2</id>
    <updated>2013-07-05T14:09:11Z</updated>
    <published>2007-01-04T09:45:28Z</published>
    <title>The Unix KISS: A Case Study</title>
    <summary>  In this paper we show that the initial philosophy used in designing and
developing UNIX in early times has been forgotten due to "fast practices". We
question the leitmotif that microkernels, though being by design adherent to
the KISS principle, have a number of context switches higher than their
monolithic counterparts, running a test suite and verify the results with
standard statistical validation tests. We advocate a wiser distribution of
shared libraries by statistically analyzing the weight of each shared object in
a typical UNIX system, showing that the majority of shared libraries exist in a
common space for no real evidence of need. Finally we examine the UNIX heritage
with an historical point of view, noticing how habits swiftly replaced the
intents of the original authors, moving the focus from the earliest purpose of
is avoiding complications, keeping a system simple to use and maintain.
</summary>
    <author>
      <name>Franco Milicchio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Removed from arXiv and other sources</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0701021v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701021v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2207.01849v1</id>
    <updated>2022-07-05T07:27:04Z</updated>
    <published>2022-07-05T07:27:04Z</published>
    <title>Learnings from an Under the Hood Analysis of an Object Storage Node IO
  Stack</title>
    <summary>  Conventional object-stores are built on top of traditional OS storage stack,
where I/O requests typically transfers through multiple hefty and redundant
layers. The complexity of object management has grown dramatically with the
ever increasing requirements of performance, consistency and fault-tolerance
from storage subsystems. Simply stated, more number of intermediate layers are
encountered in the I/O data path, with each passing layer adding its own syntax
and semantics. Thereby increasing the overheads of request processing. In this
paper, through comprehensive under-the-hood analysis of an object-storage node,
we characterize the impact of object-store (and user-application) workloads on
the OS I/O stack and its subsequent rippling effect on the underlying
object-storage devices (OSD). We observe that the legacy architecture of the OS
based I/O storage stack coupled with complex data management policies leads to
a performance mismatch between what an end-storage device is capable of
delivering and what it actually delivers in a production environment.
Therefore, the gains derived from developing faster storage devices is often
nullified. These issues get more pronounced in highly concurrent and
multiplexed cloud environments. Owing to the associated issues of
object-management and the vulnerabilities of the OS I/O software stacks, we
discuss the potential of a new class of storage devices, known as
Object-Drives. Samsung Key-Value SSD (KV-SSD) [1] and Seagate Kinetic Drive [2]
are classic industrial implementations of object-drives, where host data
management functionalities can be offloaded to the storage device. This leads
towards the simplification of the over-all storage stack. Based on our
analysis, we believe object-drives can alleviate object-stores from highly
taxing overheads of data management with 20-38% time-savings over traditional
Operating Systems (OS) stack.
</summary>
    <author>
      <name>Pratik Mishra</name>
    </author>
    <author>
      <name>Rekha Pitchumani</name>
    </author>
    <author>
      <name>Yang Suk Kee</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.48550/arXiv.2207.01849</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.48550/arXiv.2207.01849" rel="related"/>
    <link href="http://arxiv.org/abs/2207.01849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2207.01849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0410044v5</id>
    <updated>2005-12-09T13:19:43Z</updated>
    <published>2004-10-18T17:39:51Z</published>
    <title>An Example of Clifford Algebras Calculations with GiNaC</title>
    <summary>  This example of Clifford algebras calculations uses GiNaC
(http://www.ginac.de/) library, which includes a support for generic Clifford
algebra starting from version~1.3.0. Both symbolic and numeric calculation are
possible and can be blended with other functions of GiNaC. This calculations
was made for the paper math.CV/0410399.
  Described features of GiNaC are already available at PyGiNaC
(http://sourceforge.net/projects/pyginac/) and due to course should propagate
into other software like GNU Octave (http://www.octave.org/), gTybalt
(http://www.fis.unipr.it/~stefanw/gtybalt.html), which use GiNaC library as
their back-end.
</summary>
    <author>
      <name>Vladimir V. Kisil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, LaTeX2e, 12 PS graphics in one figure; v3 code
  improvements; v4 small code correction for new libraries; v5 comments are
  redesined to be more readable</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Applied Clifford Algebras, 15(2005), no. 2, pp.
  239-269</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0410044v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0410044v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2407.10098v1</id>
    <updated>2024-07-14T06:36:19Z</updated>
    <published>2024-07-14T06:36:19Z</published>
    <title>Accelerator-as-a-Service in Public Clouds: An Intra-Host Traffic
  Management View for Performance Isolation in the Wild</title>
    <summary>  I/O devices in public clouds have integrated increasing numbers of hardware
accelerators, e.g., AWS Nitro, Azure FPGA and Nvidia BlueField. However, such
specialized compute (1) is not explicitly accessible to cloud users with
performance guarantee, (2) cannot be leveraged simultaneously by both providers
and users, unlike general-purpose compute (e.g., CPUs). Through ten
observations, we present that the fundamental difficulty of democratizing
accelerators is insufficient performance isolation support. The key obstacles
to enforcing accelerator isolation are (1) too many unknown traffic patterns in
public clouds and (2) too many possible contention sources in the datapath. In
this work, instead of scheduling such complex traffic on-the-fly and augmenting
isolation support on each system component, we propose to model traffic as
network flows and proactively re-shape the traffic to avoid unpredictable
contention. We discuss the implications of our findings on the design of future
I/O management stacks and device interfaces.
</summary>
    <author>
      <name>Jiechen Zhao</name>
    </author>
    <author>
      <name>Ran Shu</name>
    </author>
    <author>
      <name>Katie Lim</name>
    </author>
    <author>
      <name>Zewen Fan</name>
    </author>
    <author>
      <name>Thomas Anderson</name>
    </author>
    <author>
      <name>Mingyu Gao</name>
    </author>
    <author>
      <name>Natalie Enright Jerger</name>
    </author>
    <link href="http://arxiv.org/abs/2407.10098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2407.10098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2203.04910v3</id>
    <updated>2023-02-06T20:18:16Z</updated>
    <published>2022-03-09T17:44:56Z</published>
    <title>GPU-Initiated On-Demand High-Throughput Storage Access in the BaM System
  Architecture</title>
    <summary>  Graphics Processing Units (GPUs) have traditionally relied on the host CPU to
initiate access to the data storage. This approach is well-suited for GPU
applications with known data access patterns that enable partitioning of their
dataset to be processed in a pipelined fashion in the GPU. However, emerging
applications such as graph and data analytics, recommender systems, or graph
neural networks, require fine-grained, data-dependent access to storage. CPU
initiation of storage access is unsuitable for these applications due to high
CPU-GPU synchronization overheads, I/O traffic amplification, and long CPU
processing latencies. GPU-initiated storage removes these overheads from the
storage control path and, thus, can potentially support these applications at
much higher speed. However, there is a lack of systems architecture and
software stack that enable efficient GPU-initiated storage access. This work
presents a novel system architecture, BaM, that fills this gap. BaM features a
fine-grained software cache to coalesce data storage requests while minimizing
I/O traffic amplification. This software cache communicates with the storage
system via high-throughput queues that enable the massive number of concurrent
threads in modern GPUs to make I/O requests at a high rate to fully utilize the
storage devices and the system interconnect. Experimental results show that BaM
delivers 1.0x and 1.49x end-to-end speed up for BFS and CC graph analytics
benchmarks while reducing hardware costs by up to 21.7x over accessing the
graph data from the host memory. Furthermore, BaM speeds up data-analytics
workloads by 5.3x over CPU-initiated storage access on the same hardware.
</summary>
    <author>
      <name>Zaid Qureshi</name>
    </author>
    <author>
      <name>Vikram Sharma Mailthody</name>
    </author>
    <author>
      <name>Isaac Gelado</name>
    </author>
    <author>
      <name>Seung Won Min</name>
    </author>
    <author>
      <name>Amna Masood</name>
    </author>
    <author>
      <name>Jeongmin Park</name>
    </author>
    <author>
      <name>Jinjun Xiong</name>
    </author>
    <author>
      <name>CJ Newburn</name>
    </author>
    <author>
      <name>Dmitri Vainbrand</name>
    </author>
    <author>
      <name>I-Hsin Chung</name>
    </author>
    <author>
      <name>Michael Garland</name>
    </author>
    <author>
      <name>William Dally</name>
    </author>
    <author>
      <name>Wen-mei Hwu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3575693.3575748</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3575693.3575748" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is an extension to the published conference paper at ASPLOS'23:
  https://dl.acm.org/doi/abs/10.1145/3575693.3575748</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ASPLOS 2023: Proceedings of the 28th ACM International Conference
  on Architectural Support for Programming Languages and Operating Systems,
  Volume 2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2203.04910v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2203.04910v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.01013v1</id>
    <updated>2024-08-02T05:15:38Z</updated>
    <published>2024-08-02T05:15:38Z</published>
    <title>Understanding and Enhancing Linux Kernel-based Packet Switching on WiFi
  Access Points</title>
    <summary>  As the number of WiFi devices and their traffic demands continue to rise, the
need for a scalable and high-performance wireless infrastructure becomes
increasingly essential. Central to this infrastructure are WiFi Access Points
(APs), which facilitate packet switching between Ethernet and WiFi interfaces.
Despite APs' reliance on the Linux kernel's data plane for packet switching,
the detailed operations and complexities of switching packets between Ethernet
and WiFi interfaces have not been investigated in existing works. This paper
makes the following contributions towards filling this research gap. Through
macro and micro-analysis of empirical experiments, our study reveals insights
in two distinct categories. Firstly, while the kernel's statistics offer
valuable insights into system operations, we identify and discuss potential
pitfalls that can severely affect system analysis. For instance, we reveal the
implications of device drivers on the meaning and accuracy of the statistics
related to packet-switching tasks and processor utilization. Secondly, we
analyze the impact of the packet switching path and core configuration on
performance and power consumption. Specifically, we identify the differences in
Ethernet-to-WiFi and WiFi-to-Ethernet data paths regarding processing
components, multi-core utilization, and energy efficiency. We show that the
WiFi-to-Ethernet data path leverages better multi-core processing and exhibits
lower power consumption.
</summary>
    <author>
      <name>Shiqi Zhang</name>
    </author>
    <author>
      <name>Mridul Gupta</name>
    </author>
    <author>
      <name>Behnam Dezfouli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work has been submitted to the IEEE for possible publication</arxiv:comment>
    <link href="http://arxiv.org/abs/2408.01013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2408.01013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1459v1</id>
    <updated>2013-05-07T10:22:31Z</updated>
    <published>2013-05-07T10:22:31Z</published>
    <title>EURETILE 2010-2012 summary: first three years of activity of the
  European Reference Tiled Experiment</title>
    <summary>  This is the summary of first three years of activity of the EURETILE FP7
project 247846. EURETILE investigates and implements brain-inspired and
fault-tolerant foundational innovations to the system architecture of massively
parallel tiled computer architectures and the corresponding programming
paradigm. The execution targets are a many-tile HW platform, and a many-tile
simulator. A set of SW process - HW tile mapping candidates is generated by the
holistic SW tool-chain using a combination of analytic and bio-inspired
methods. The Hardware dependent Software is then generated, providing OS
services with maximum efficiency/minimal overhead. The many-tile simulator
collects profiling data, closing the loop of the SW tool chain. Fine-grain
parallelism inside processes is exploited by optimized intra-tile compilation
techniques, but the project focus is above the level of the elementary tile.
The elementary HW tile is a multi-processor, which includes a fault tolerant
Distributed Network Processor (for inter-tile communication) and ASIP
accelerators. Furthermore, EURETILE investigates and implements the innovations
for equipping the elementary HW tile with high-bandwidth, low-latency
brain-like inter-tile communication emulating 3 levels of connection hierarchy,
namely neural columns, cortical areas and cortex, and develops a dedicated
cortical simulation benchmark: DPSNN-STDP (Distributed Polychronous Spiking
Neural Net with synaptic Spiking Time Dependent Plasticity). EURETILE leverages
on the multi-tile HW paradigm and SW tool-chain developed by the FET-ACA SHAPES
Integrated Project (2006-2009).
</summary>
    <author>
      <name>Pier Stanislao Paolucci</name>
    </author>
    <author>
      <name>Iuliana Bacivarov</name>
    </author>
    <author>
      <name>Gert Goossens</name>
    </author>
    <author>
      <name>Rainer Leupers</name>
    </author>
    <author>
      <name>Frédéric Rousseau</name>
    </author>
    <author>
      <name>Christoph Schumacher</name>
    </author>
    <author>
      <name>Lothar Thiele</name>
    </author>
    <author>
      <name>Piero Vicini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.12837/2013T01</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.12837/2013T01" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">56 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.1459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.4; C.3; B.7.2; F.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9301114v1</id>
    <updated>1991-11-01T00:00:00Z</updated>
    <published>1991-11-01T00:00:00Z</published>
    <title>Theory and practice</title>
    <summary>  The author argues to Silicon Valley that the most important and powerful part
of computer science is work that is simultaneously theoretical and practical.
He particularly considers the intersection of the theory of algorithms and
practical software development. He combines examples from the development of
the TeX typesetting system with clever jokes, criticisms, and encouragements.
</summary>
    <author>
      <name>Donald E. Knuth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Abstract added by Greg Kuperberg</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Theoretical Comp. Sci. 90 (1991), 1--15</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9301114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9301114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809010v1</id>
    <updated>1998-09-02T19:39:25Z</updated>
    <published>1998-09-02T19:39:25Z</published>
    <title>The Revolution Yet to Happen</title>
    <summary>  All information about physical objects including humans, buildings,
processes, and organizations will be online. This trend is both desirable and
inevitable. Cyberspace will provide the basis for wonderful new ways to inform,
entertain, and educate people. The information and the corresponding systems
will streamline commerce, but will also provide new levels of personal service,
health care, and automation. The most significant benefit will be a
breakthrough in our ability to remotely communicate with one another using all
our senses.
  The ACM and the transistor were born in 1947. At that time the stored program
computer was a revolutionary idea and the transistor was just a curiosity. Both
ideas evolved rapidly. By the mid 1960s integrated circuits appeared --
allowing mass fabrication of transistors on silicon substrates. This allowed
low-cost mass-produced computers. These technologies enabled extraordinary
increases in processing speed and memory coupled with extraordinary price
declines.
  The only form of processing and memory more easily, cheaply, and rapidly
fabricated is the human brain. Peter Cohrane (1996) estimates the brain to have
a processing power of around 1000 million-million operations per second, (one
Petaops) and a memory of 10 Terabytes. If current trends continue, computers
could have these capabilities by 2047. Such computers could be 'on body'
personal assistants able to recall everything one reads, hears, and sees.
</summary>
    <author>
      <name>C. Gordon Bell</name>
    </author>
    <author>
      <name>Jim Gray</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Original document at:
  http://research.microsoft.com/~gray/Revolution.doc</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9809010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
