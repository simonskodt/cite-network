<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dcat%3Acs.%2A%26id_list%3D%26start%3D0%26max_results%3D200" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=cat:cs.*&amp;id_list=&amp;start=0&amp;max_results=200</title>
  <id>http://arxiv.org/api/6Lw8FK+eogrvcw4SkRSTE0kNlGM</id>
  <updated>2024-10-27T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">683485</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">200</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2410.18979v1</id>
    <updated>2024-10-24T17:59:58Z</updated>
    <published>2024-10-24T17:59:58Z</published>
    <title>PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary
  Views</title>
    <summary>  We propose PixelGaussian, an efficient feed-forward framework for learning
generalizable 3D Gaussian reconstruction from arbitrary views. Most existing
methods rely on uniform pixel-wise Gaussian representations, which learn a
fixed number of 3D Gaussians for each view and cannot generalize well to more
input views. Differently, our PixelGaussian dynamically adapts both the
Gaussian distribution and quantity based on geometric complexity, leading to
more efficient representations and significant improvements in reconstruction
quality. Specifically, we introduce a Cascade Gaussian Adapter to adjust
Gaussian distribution according to local geometry complexity identified by a
keypoint scorer. CGA leverages deformable attention in context-aware
hypernetworks to guide Gaussian pruning and splitting, ensuring accurate
representation in complex regions while reducing redundancy. Furthermore, we
design a transformer-based Iterative Gaussian Refiner module that refines
Gaussian representations through direct image-Gaussian interactions. Our
PixelGaussian can effectively reduce Gaussian redundancy as input views
increase. We conduct extensive experiments on the large-scale ACID and
RealEstate10K datasets, where our method achieves state-of-the-art performance
with good generalization to various numbers of views. Code:
https://github.com/Barrybarry-Smith/PixelGaussian.
</summary>
    <author>
      <name>Xin Fei</name>
    </author>
    <author>
      <name>Wenzhao Zheng</name>
    </author>
    <author>
      <name>Yueqi Duan</name>
    </author>
    <author>
      <name>Wei Zhan</name>
    </author>
    <author>
      <name>Masayoshi Tomizuka</name>
    </author>
    <author>
      <name>Kurt Keutzer</name>
    </author>
    <author>
      <name>Jiwen Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code is available at:
  https://github.com/Barrybarry-Smith/PixelGaussian</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18979v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18979v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18978v1</id>
    <updated>2024-10-24T17:59:51Z</updated>
    <published>2024-10-24T17:59:51Z</published>
    <title>Framer: Interactive Frame Interpolation</title>
    <summary>  We propose Framer for interactive frame interpolation, which targets
producing smoothly transitioning frames between two images as per user
creativity. Concretely, besides taking the start and end frames as inputs, our
approach supports customizing the transition process by tailoring the
trajectory of some selected keypoints. Such a design enjoys two clear benefits.
First, incorporating human interaction mitigates the issue arising from
numerous possibilities of transforming one image to another, and in turn
enables finer control of local motions. Second, as the most basic form of
interaction, keypoints help establish the correspondence across frames,
enhancing the model to handle challenging cases (e.g., objects on the start and
end frames are of different shapes and styles). It is noteworthy that our
system also offers an "autopilot" mode, where we introduce a module to estimate
the keypoints and refine the trajectory automatically, to simplify the usage in
practice. Extensive experimental results demonstrate the appealing performance
of Framer on various applications, such as image morphing, time-lapse video
generation, cartoon interpolation, etc. The code, the model, and the interface
will be released to facilitate further research.
</summary>
    <author>
      <name>Wen Wang</name>
    </author>
    <author>
      <name>Qiuyu Wang</name>
    </author>
    <author>
      <name>Kecheng Zheng</name>
    </author>
    <author>
      <name>Hao Ouyang</name>
    </author>
    <author>
      <name>Zhekai Chen</name>
    </author>
    <author>
      <name>Biao Gong</name>
    </author>
    <author>
      <name>Hao Chen</name>
    </author>
    <author>
      <name>Yujun Shen</name>
    </author>
    <author>
      <name>Chunhua Shen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project page: https://aim-uofa.github.io/Framer/</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18978v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18978v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18977v1</id>
    <updated>2024-10-24T17:59:45Z</updated>
    <published>2024-10-24T17:59:45Z</published>
    <title>MotionCLR: Motion Generation and Training-free Editing via Understanding
  Attention Mechanisms</title>
    <summary>  This research delves into the problem of interactive editing of human motion
generation. Previous motion diffusion models lack explicit modeling of the
word-level text-motion correspondence and good explainability, hence
restricting their fine-grained editing ability. To address this issue, we
propose an attention-based motion diffusion model, namely MotionCLR, with CLeaR
modeling of attention mechanisms. Technically, MotionCLR models the in-modality
and cross-modality interactions with self-attention and cross-attention,
respectively. More specifically, the self-attention mechanism aims to measure
the sequential similarity between frames and impacts the order of motion
features. By contrast, the cross-attention mechanism works to find the
fine-grained word-sequence correspondence and activate the corresponding
timesteps in the motion sequence. Based on these key properties, we develop a
versatile set of simple yet effective motion editing methods via manipulating
attention maps, such as motion (de-)emphasizing, in-place motion replacement,
and example-based motion generation, etc. For further verification of the
explainability of the attention mechanism, we additionally explore the
potential of action-counting and grounded motion generation ability via
attention maps. Our experimental results show that our method enjoys good
generation and editing ability with good explainability.
</summary>
    <author>
      <name>Ling-Hao Chen</name>
    </author>
    <author>
      <name>Wenxun Dai</name>
    </author>
    <author>
      <name>Xuan Ju</name>
    </author>
    <author>
      <name>Shunlin Lu</name>
    </author>
    <author>
      <name>Lei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">MotionCLR v1 technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18977v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18977v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18976v1</id>
    <updated>2024-10-24T17:59:38Z</updated>
    <published>2024-10-24T17:59:38Z</published>
    <title>CAMEL-Bench: A Comprehensive Arabic LMM Benchmark</title>
    <summary>  Recent years have witnessed a significant interest in developing large
multimodal models (LMMs) capable of performing various visual reasoning and
understanding tasks. This has led to the introduction of multiple LMM
benchmarks to evaluate LMMs on different tasks. However, most existing LMM
evaluation benchmarks are predominantly English-centric. In this work, we
develop a comprehensive LMM evaluation benchmark for the Arabic language to
represent a large population of over 400 million speakers. The proposed
benchmark, named CAMEL-Bench, comprises eight diverse domains and 38
sub-domains including, multi-image understanding, complex visual perception,
handwritten document understanding, video understanding, medical imaging, plant
diseases, and remote sensing-based land use understanding to evaluate broad
scenario generalizability. Our CAMEL-Bench comprises around 29,036 questions
that are filtered from a larger pool of samples, where the quality is manually
verified by native speakers to ensure reliable model assessment. We conduct
evaluations of both closed-source, including GPT-4 series, and open-source
LMMs. Our analysis reveals the need for substantial improvement, especially
among the best open-source models, with even the closed-source GPT-4o achieving
an overall score of 62%. Our benchmark and evaluation scripts are open-sourced.
</summary>
    <author>
      <name>Sara Ghaboura</name>
    </author>
    <author>
      <name>Ahmed Heakl</name>
    </author>
    <author>
      <name>Omkar Thawakar</name>
    </author>
    <author>
      <name>Ali Alharthi</name>
    </author>
    <author>
      <name>Ines Riahi</name>
    </author>
    <author>
      <name>Abduljalil Saif</name>
    </author>
    <author>
      <name>Jorma Laaksonen</name>
    </author>
    <author>
      <name>Fahad S. Khan</name>
    </author>
    <author>
      <name>Salman Khan</name>
    </author>
    <author>
      <name>Rao M. Anwer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, NAACL</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18975v1</id>
    <updated>2024-10-24T17:59:31Z</updated>
    <published>2024-10-24T17:59:31Z</published>
    <title>Unbounded: A Generative Infinite Game of Character Life Simulation</title>
    <summary>  We introduce the concept of a generative infinite game, a video game that
transcends the traditional boundaries of finite, hard-coded systems by using
generative models. Inspired by James P. Carse's distinction between finite and
infinite games, we leverage recent advances in generative AI to create
Unbounded: a game of character life simulation that is fully encapsulated in
generative models. Specifically, Unbounded draws inspiration from sandbox life
simulations and allows you to interact with your autonomous virtual character
in a virtual world by feeding, playing with and guiding it - with open-ended
mechanics generated by an LLM, some of which can be emergent. In order to
develop Unbounded, we propose technical innovations in both the LLM and visual
generation domains. Specifically, we present: (1) a specialized, distilled
large language model (LLM) that dynamically generates game mechanics,
narratives, and character interactions in real-time, and (2) a new dynamic
regional image prompt Adapter (IP-Adapter) for vision models that ensures
consistent yet flexible visual generation of a character across multiple
environments. We evaluate our system through both qualitative and quantitative
analysis, showing significant improvements in character life simulation, user
instruction following, narrative coherence, and visual consistency for both
characters and the environments compared to traditional related approaches.
</summary>
    <author>
      <name>Jialu Li</name>
    </author>
    <author>
      <name>Yuanzhen Li</name>
    </author>
    <author>
      <name>Neal Wadhwa</name>
    </author>
    <author>
      <name>Yael Pritch</name>
    </author>
    <author>
      <name>David E. Jacobs</name>
    </author>
    <author>
      <name>Michael Rubinstein</name>
    </author>
    <author>
      <name>Mohit Bansal</name>
    </author>
    <author>
      <name>Nataniel Ruiz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages; Project page: https://generative-infinite-game.github.io/</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18975v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18975v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18974v1</id>
    <updated>2024-10-24T17:59:30Z</updated>
    <published>2024-10-24T17:59:30Z</published>
    <title>3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D
  Generation</title>
    <summary>  Multi-view image diffusion models have significantly advanced open-domain 3D
object generation. However, most existing models rely on 2D network
architectures that lack inherent 3D biases, resulting in compromised geometric
consistency. To address this challenge, we introduce 3D-Adapter, a plug-in
module designed to infuse 3D geometry awareness into pretrained image diffusion
models. Central to our approach is the idea of 3D feedback augmentation: for
each denoising step in the sampling loop, 3D-Adapter decodes intermediate
multi-view features into a coherent 3D representation, then re-encodes the
rendered RGBD views to augment the pretrained base model through feature
addition. We study two variants of 3D-Adapter: a fast feed-forward version
based on Gaussian splatting and a versatile training-free version utilizing
neural fields and meshes. Our extensive experiments demonstrate that 3D-Adapter
not only greatly enhances the geometry quality of text-to-multi-view models
such as Instant3D and Zero123++, but also enables high-quality 3D generation
using the plain text-to-image Stable Diffusion. Furthermore, we showcase the
broad application potential of 3D-Adapter by presenting high quality results in
text-to-3D, image-to-3D, text-to-texture, and text-to-avatar tasks.
</summary>
    <author>
      <name>Hansheng Chen</name>
    </author>
    <author>
      <name>Bokui Shen</name>
    </author>
    <author>
      <name>Yulin Liu</name>
    </author>
    <author>
      <name>Ruoxi Shi</name>
    </author>
    <author>
      <name>Linqi Zhou</name>
    </author>
    <author>
      <name>Connor Z. Lin</name>
    </author>
    <author>
      <name>Jiayuan Gu</name>
    </author>
    <author>
      <name>Hao Su</name>
    </author>
    <author>
      <name>Gordon Wetzstein</name>
    </author>
    <author>
      <name>Leonidas Guibas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project page: https://lakonik.github.io/3d-adapter/</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18974v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18974v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18973v1</id>
    <updated>2024-10-24T17:59:23Z</updated>
    <published>2024-10-24T17:59:23Z</published>
    <title>Tuning-free coreset Markov chain Monte Carlo</title>
    <summary>  A Bayesian coreset is a small, weighted subset of a data set that replaces
the full data during inference to reduce computational cost. The
state-of-the-art coreset construction algorithm, Coreset Markov chain Monte
Carlo (Coreset MCMC), uses draws from an adaptive Markov chain targeting the
coreset posterior to train the coreset weights via stochastic gradient
optimization. However, the quality of the constructed coreset, and thus the
quality of its posterior approximation, is sensitive to the stochastic
optimization learning rate. In this work, we propose a learning-rate-free
stochastic gradient optimization procedure, Hot-start Distance over Gradient
(Hot DoG), for training coreset weights in Coreset MCMC without user tuning
effort. Empirical results demonstrate that Hot DoG provides higher quality
posterior approximations than other learning-rate-free stochastic gradient
methods, and performs competitively to optimally-tuned ADAM.
</summary>
    <author>
      <name>Naitong Chen</name>
    </author>
    <author>
      <name>Jonathan H. Huggins</name>
    </author>
    <author>
      <name>Trevor Campbell</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18973v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18973v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18972v1</id>
    <updated>2024-10-24T17:59:21Z</updated>
    <published>2024-10-24T17:59:21Z</published>
    <title>Deep Insights into Cognitive Decline: A Survey of Leveraging
  Non-Intrusive Modalities with Deep Learning Techniques</title>
    <summary>  Cognitive decline is a natural part of aging, often resulting in reduced
cognitive abilities. In some cases, however, this decline is more pronounced,
typically due to disorders such as Alzheimer's disease. Early detection of
anomalous cognitive decline is crucial, as it can facilitate timely
professional intervention. While medical data can help in this detection, it
often involves invasive procedures. An alternative approach is to employ
non-intrusive techniques such as speech or handwriting analysis, which do not
necessarily affect daily activities. This survey reviews the most relevant
methodologies that use deep learning techniques to automate the cognitive
decline estimation task, including audio, text, and visual processing. We
discuss the key features and advantages of each modality and methodology,
including state-of-the-art approaches like Transformer architecture and
foundation models. In addition, we present works that integrate different
modalities to develop multimodal models. We also highlight the most significant
datasets and the quantitative results from studies using these resources. From
this review, several conclusions emerge. In most cases, the textual modality
achieves the best results and is the most relevant for detecting cognitive
decline. Moreover, combining various approaches from individual modalities into
a multimodal model consistently enhances performance across nearly all
scenarios.
</summary>
    <author>
      <name>David Ortiz-Perez</name>
    </author>
    <author>
      <name>Manuel Benavent-Lledo</name>
    </author>
    <author>
      <name>Jose Garcia-Rodriguez</name>
    </author>
    <author>
      <name>David Tomás</name>
    </author>
    <author>
      <name>M. Flores Vizcaya-Moreno</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18972v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18972v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18970v1</id>
    <updated>2024-10-24T17:59:16Z</updated>
    <published>2024-10-24T17:59:16Z</published>
    <title>ConceptDrift: Uncovering Biases through the Lens of Foundational Models</title>
    <summary>  Datasets and pre-trained models come with intrinsic biases. Most methods rely
on spotting them by analysing misclassified samples, in a semi-automated
human-computer validation. In contrast, we propose ConceptDrift, a method which
analyzes the weights of a linear probe, learned on top a foundational model. We
capitalize on the weight update trajectory, which starts from the embedding of
the textual representation of the class, and proceeds to drift towards
embeddings that disclose hidden biases. Different from prior work, with this
approach we can pin-point unwanted correlations from a dataset, providing more
than just possible explanations for the wrong predictions. We empirically prove
the efficacy of our method, by significantly improving zero-shot performance
with biased-augmented prompting. Our method is not bounded to a single
modality, and we experiment in this work with both image (Waterbirds, CelebA,
Nico++) and text datasets (CivilComments).
</summary>
    <author>
      <name>Cristian Daniel Păduraru</name>
    </author>
    <author>
      <name>Antonio Bărbălau</name>
    </author>
    <author>
      <name>Radu Filipescu</name>
    </author>
    <author>
      <name>Andrei Liviu Nicolicioiu</name>
    </author>
    <author>
      <name>Elena Burceanu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18970v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18970v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18969v1</id>
    <updated>2024-10-24T17:59:14Z</updated>
    <published>2024-10-24T17:59:14Z</published>
    <title>Self-Improving Autonomous Underwater Manipulation</title>
    <summary>  Underwater robotic manipulation faces significant challenges due to complex
fluid dynamics and unstructured environments, causing most manipulation systems
to rely heavily on human teleoperation. In this paper, we introduce AquaBot, a
fully autonomous manipulation system that combines behavior cloning from human
demonstrations with self-learning optimization to improve beyond human
teleoperation performance. With extensive real-world experiments, we
demonstrate AquaBot's versatility across diverse manipulation tasks, including
object grasping, trash sorting, and rescue retrieval. Our real-world
experiments show that AquaBot's self-optimized policy outperforms a human
operator by 41% in speed. AquaBot represents a promising step towards
autonomous and self-improving underwater manipulation systems. We open-source
both hardware and software implementation details.
</summary>
    <author>
      <name>Ruoshi Liu</name>
    </author>
    <author>
      <name>Huy Ha</name>
    </author>
    <author>
      <name>Mengxue Hou</name>
    </author>
    <author>
      <name>Shuran Song</name>
    </author>
    <author>
      <name>Carl Vondrick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project Page: https://aquabot.cs.columbia.edu/</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18969v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18969v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18967v1</id>
    <updated>2024-10-24T17:58:31Z</updated>
    <published>2024-10-24T17:58:31Z</published>
    <title>Ferret-UI 2: Mastering Universal User Interface Understanding Across
  Platforms</title>
    <summary>  Building a generalist model for user interface (UI) understanding is
challenging due to various foundational issues, such as platform diversity,
resolution variation, and data limitation. In this paper, we introduce
Ferret-UI 2, a multimodal large language model (MLLM) designed for universal UI
understanding across a wide range of platforms, including iPhone, Android,
iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI
2 introduces three key innovations: support for multiple platform types,
high-resolution perception through adaptive scaling, and advanced task training
data generation powered by GPT-4o with set-of-mark visual prompting. These
advancements enable Ferret-UI 2 to perform complex, user-centered interactions,
making it highly versatile and adaptable for the expanding diversity of
platform ecosystems. Extensive empirical experiments on referring, grounding,
user-centric advanced tasks (comprising 9 subtasks $\times$ 5 platforms), GUIDE
next-action prediction dataset, and GUI-World multi-platform benchmark
demonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also
shows strong cross-platform transfer capabilities.
</summary>
    <author>
      <name>Zhangheng Li</name>
    </author>
    <author>
      <name>Keen You</name>
    </author>
    <author>
      <name>Haotian Zhang</name>
    </author>
    <author>
      <name>Di Feng</name>
    </author>
    <author>
      <name>Harsh Agrawal</name>
    </author>
    <author>
      <name>Xiujun Li</name>
    </author>
    <author>
      <name>Mohana Prasad Sathya Moorthy</name>
    </author>
    <author>
      <name>Jeff Nichols</name>
    </author>
    <author>
      <name>Yinfei Yang</name>
    </author>
    <author>
      <name>Zhe Gan</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18967v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18967v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18966v1</id>
    <updated>2024-10-24T17:58:22Z</updated>
    <published>2024-10-24T17:58:22Z</published>
    <title>Does Data Contamination Detection Work (Well) for LLMs? A Survey and
  Evaluation on Detection Assumptions</title>
    <summary>  Large language models (LLMs) have demonstrated great performance across
various benchmarks, showing potential as general-purpose task solvers. However,
as LLMs are typically trained on vast amounts of data, a significant concern in
their evaluation is data contamination, where overlap between training data and
evaluation datasets inflates performance assessments. While multiple approaches
have been developed to identify data contamination, these approaches rely on
specific assumptions that may not hold universally across different settings.
To bridge this gap, we systematically review 47 papers on data contamination
detection, categorize the underlying assumptions, and assess whether they have
been rigorously validated. We identify and analyze eight categories of
assumptions and test three of them as case studies. Our analysis reveals that
when classifying instances used for pretraining LLMs, detection approaches
based on these three assumptions perform close to random guessing, suggesting
that current LLMs learn data distributions rather than memorizing individual
instances. Overall, this work underscores the importance of approaches clearly
stating their underlying assumptions and testing their validity across various
scenarios.
</summary>
    <author>
      <name>Yujuan Fu</name>
    </author>
    <author>
      <name>Ozlem Uzuner</name>
    </author>
    <author>
      <name>Meliha Yetisgen</name>
    </author>
    <author>
      <name>Fei Xia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 tables and 1 figures in the main text. This is a preprint, under
  review</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18965v1</id>
    <updated>2024-10-24T17:58:21Z</updated>
    <published>2024-10-24T17:58:21Z</published>
    <title>On the Crucial Role of Initialization for Matrix Factorization</title>
    <summary>  This work revisits the classical low-rank matrix factorization problem and
unveils the critical role of initialization in shaping convergence rates for
such nonconvex and nonsmooth optimization. We introduce Nystrom initialization,
which significantly improves the global convergence of Scaled Gradient Descent
(ScaledGD) in both symmetric and asymmetric matrix factorization tasks.
Specifically, we prove that ScaledGD with Nystrom initialization achieves
quadratic convergence in cases where only linear rates were previously known.
Furthermore, we extend this initialization to low-rank adapters (LoRA) commonly
used for finetuning foundation models. Our approach, NoRA, i.e., LoRA with
Nystrom initialization, demonstrates superior performance across various
downstream tasks and model scales, from 1B to 7B parameters, in large language
and diffusion models.
</summary>
    <author>
      <name>Bingcong Li</name>
    </author>
    <author>
      <name>Liang Zhang</name>
    </author>
    <author>
      <name>Aryan Mokhtari</name>
    </author>
    <author>
      <name>Niao He</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18964v1</id>
    <updated>2024-10-24T17:58:11Z</updated>
    <published>2024-10-24T17:58:11Z</published>
    <title>Learning to Look: Seeking Information for Decision Making via Policy
  Factorization</title>
    <summary>  Many robot manipulation tasks require active or interactive exploration
behavior in order to be performed successfully. Such tasks are ubiquitous in
embodied domains, where agents must actively search for the information
necessary for each stage of a task, e.g., moving the head of the robot to find
information relevant to manipulation, or in multi-robot domains, where one
scout robot may search for the information that another robot needs to make
informed decisions. We identify these tasks with a new type of problem,
factorized Contextual Markov Decision Processes, and propose DISaM, a
dual-policy solution composed of an information-seeking policy that explores
the environment to find the relevant contextual information and an
information-receiving policy that exploits the context to achieve the
manipulation goal. This factorization allows us to train both policies
separately, using the information-receiving one to provide reward to train the
information-seeking policy. At test time, the dual agent balances exploration
and exploitation based on the uncertainty the manipulation policy has on what
the next best action is. We demonstrate the capabilities of our dual policy
solution in five manipulation tasks that require information-seeking behaviors,
both in simulation and in the real-world, where DISaM significantly outperforms
existing methods. More information at
https://robin-lab.cs.utexas.edu/learning2look/.
</summary>
    <author>
      <name>Shivin Dass</name>
    </author>
    <author>
      <name>Jiaheng Hu</name>
    </author>
    <author>
      <name>Ben Abbatematteo</name>
    </author>
    <author>
      <name>Peter Stone</name>
    </author>
    <author>
      <name>Roberto Martín-Martín</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project Website: https://robin-lab.cs.utexas.edu/learning2look/</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18964v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18964v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18963v1</id>
    <updated>2024-10-24T17:58:08Z</updated>
    <published>2024-10-24T17:58:08Z</published>
    <title>OSCAR: Operating System Control via State-Aware Reasoning and
  Re-Planning</title>
    <summary>  Large language models (LLMs) and large multimodal models (LMMs) have shown
great potential in automating complex tasks like web browsing and gaming.
However, their ability to generalize across diverse applications remains
limited, hindering broader utility. To address this challenge, we present
OSCAR: Operating System Control via state-Aware reasoning and Re-planning.
OSCAR is a generalist agent designed to autonomously navigate and interact with
various desktop and mobile applications through standardized controls, such as
mouse and keyboard inputs, while processing screen images to fulfill user
commands. OSCAR translates human instructions into executable Python code,
enabling precise control over graphical user interfaces (GUIs). To enhance
stability and adaptability, OSCAR operates as a state machine, equipped with
error-handling mechanisms and dynamic task re-planning, allowing it to
efficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR's
effectiveness through extensive experiments on diverse benchmarks across
desktop and mobile platforms, where it transforms complex workflows into simple
natural language commands, significantly boosting user productivity. Our code
will be open-source upon publication.
</summary>
    <author>
      <name>Xiaoqiang Wang</name>
    </author>
    <author>
      <name>Bang Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in progress</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18963v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18963v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18962v1</id>
    <updated>2024-10-24T17:58:05Z</updated>
    <published>2024-10-24T17:58:05Z</published>
    <title>Where Am I and What Will I See: An Auto-Regressive Model for Spatial
  Localization and View Prediction</title>
    <summary>  Spatial intelligence is the ability of a machine to perceive, reason, and act
in three dimensions within space and time. Recent advancements in large-scale
auto-regressive models have demonstrated remarkable capabilities across various
reasoning tasks. However, these models often struggle with fundamental aspects
of spatial reasoning, particularly in answering questions like "Where am I?"
and "What will I see?". While some attempts have been done, existing approaches
typically treat them as separate tasks, failing to capture their interconnected
nature. In this paper, we present Generative Spatial Transformer (GST), a novel
auto-regressive framework that jointly addresses spatial localization and view
prediction. Our model simultaneously estimates the camera pose from a single
image and predicts the view from a new camera pose, effectively bridging the
gap between spatial awareness and visual prediction. The proposed innovative
camera tokenization method enables the model to learn the joint distribution of
2D projections and their corresponding spatial perspectives in an
auto-regressive manner. This unified training paradigm demonstrates that joint
optimization of pose estimation and novel view synthesis leads to improved
performance in both tasks, for the first time, highlighting the inherent
relationship between spatial awareness and visual prediction.
</summary>
    <author>
      <name>Junyi Chen</name>
    </author>
    <author>
      <name>Di Huang</name>
    </author>
    <author>
      <name>Weicai Ye</name>
    </author>
    <author>
      <name>Wanli Ouyang</name>
    </author>
    <author>
      <name>Tong He</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18962v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18962v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18959v1</id>
    <updated>2024-10-24T17:56:08Z</updated>
    <published>2024-10-24T17:56:08Z</published>
    <title>Context is Key: A Benchmark for Forecasting with Essential Textual
  Information</title>
    <summary>  Forecasting is a critical task in decision making across various domains.
While numerical data provides a foundation, it often lacks crucial context
necessary for accurate predictions. Human forecasters frequently rely on
additional information, such as background knowledge or constraints, which can
be efficiently communicated through natural language. However, the ability of
existing forecasting models to effectively integrate this textual information
remains an open question. To address this, we introduce "Context is Key" (CiK),
a time series forecasting benchmark that pairs numerical data with diverse
types of carefully crafted textual context, requiring models to integrate both
modalities. We evaluate a range of approaches, including statistical models,
time series foundation models, and LLM-based forecasters, and propose a simple
yet effective LLM prompting method that outperforms all other tested methods on
our benchmark. Our experiments highlight the importance of incorporating
contextual information, demonstrate surprising performance when using LLM-based
forecasting models, and also reveal some of their critical shortcomings. By
presenting this benchmark, we aim to advance multimodal forecasting, promoting
models that are both accurate and accessible to decision-makers with varied
technical expertise. The benchmark can be visualized at
https://servicenow.github.io/context-is-key-forecasting/v0/ .
</summary>
    <author>
      <name>Andrew Robert Williams</name>
    </author>
    <author>
      <name>Arjun Ashok</name>
    </author>
    <author>
      <name>Étienne Marcotte</name>
    </author>
    <author>
      <name>Valentina Zantedeschi</name>
    </author>
    <author>
      <name>Jithendaraa Subramanian</name>
    </author>
    <author>
      <name>Roland Riachi</name>
    </author>
    <author>
      <name>James Requeima</name>
    </author>
    <author>
      <name>Alexandre Lacoste</name>
    </author>
    <author>
      <name>Irina Rish</name>
    </author>
    <author>
      <name>Nicolas Chapados</name>
    </author>
    <author>
      <name>Alexandre Drouin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint; under review. First two authors contributed equally</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18958v1</id>
    <updated>2024-10-24T17:55:52Z</updated>
    <published>2024-10-24T17:55:52Z</published>
    <title>Stable Consistency Tuning: Understanding and Improving Consistency
  Models</title>
    <summary>  Diffusion models achieve superior generation quality but suffer from slow
generation speed due to the iterative nature of denoising. In contrast,
consistency models, a new generative family, achieve competitive performance
with significantly faster sampling. These models are trained either through
consistency distillation, which leverages pretrained diffusion models, or
consistency training/tuning directly from raw data. In this work, we propose a
novel framework for understanding consistency models by modeling the denoising
process of the diffusion model as a Markov Decision Process (MDP) and framing
consistency model training as the value estimation through Temporal
Difference~(TD) Learning. More importantly, this framework allows us to analyze
the limitations of current consistency training/tuning strategies. Built upon
Easy Consistency Tuning (ECT), we propose Stable Consistency Tuning (SCT),
which incorporates variance-reduced learning using the score identity. SCT
leads to significant performance improvements on benchmarks such as CIFAR-10
and ImageNet-64. On ImageNet-64, SCT achieves 1-step FID 2.42 and 2-step FID
1.55, a new SoTA for consistency models.
</summary>
    <author>
      <name>Fu-Yun Wang</name>
    </author>
    <author>
      <name>Zhengyang Geng</name>
    </author>
    <author>
      <name>Hongsheng Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code is available at
  https://github.com/G-U-N/Stable-Consistency-Tuning</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18957v1</id>
    <updated>2024-10-24T17:55:03Z</updated>
    <published>2024-10-24T17:55:03Z</published>
    <title>Bridge-Coder: Unlocking LLMs' Potential to Overcome Language Gaps in
  Low-Resource Code</title>
    <summary>  Large Language Models (LLMs) demonstrate strong proficiency in generating
code for high-resource programming languages (HRPLs) like Python but struggle
significantly with low-resource programming languages (LRPLs) such as Racket or
D. This performance gap deepens the digital divide, preventing developers using
LRPLs from benefiting equally from LLM advancements and reinforcing disparities
in innovation within underrepresented programming communities. While generating
additional training data for LRPLs is promising, it faces two key challenges:
manual annotation is labor-intensive and costly, and LLM-generated LRPL code is
often of subpar quality. The underlying cause of this issue is the gap between
natural language to programming language gap (NL-PL Gap), which is especially
pronounced in LRPLs due to limited aligned data. In this work, we introduce a
novel approach called Bridge-Coder, which leverages LLMs' intrinsic
capabilities to enhance the performance on LRPLs. Our method consists of two
key stages. Bridge Generation, where we create high-quality dataset by
utilizing LLMs' general knowledge understanding, proficiency in HRPLs, and
in-context learning abilities. Then, we apply the Bridged Alignment, which
progressively improves the alignment between NL instructions and LRPLs.
Experimental results across multiple LRPLs show that Bridge-Coder significantly
enhances model performance, demonstrating the effectiveness and generalization
of our approach. Furthermore, we offer a detailed analysis of the key
components of our method, providing valuable insights for future work aimed at
addressing the challenges associated with LRPLs.
</summary>
    <author>
      <name>Jipeng Zhang</name>
    </author>
    <author>
      <name>Jianshu Zhang</name>
    </author>
    <author>
      <name>Yuanzhe Li</name>
    </author>
    <author>
      <name>Renjie Pi</name>
    </author>
    <author>
      <name>Rui Pan</name>
    </author>
    <author>
      <name>Runtao Liu</name>
    </author>
    <author>
      <name>Ziqiang Zheng</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18956v1</id>
    <updated>2024-10-24T17:54:42Z</updated>
    <published>2024-10-24T17:54:42Z</published>
    <title>Large Spatial Model: End-to-end Unposed Images to Semantic 3D</title>
    <summary>  Reconstructing and understanding 3D structures from a limited number of
images is a well-established problem in computer vision. Traditional methods
usually break this task into multiple subtasks, each requiring complex
transformations between different data representations. For instance, dense
reconstruction through Structure-from-Motion (SfM) involves converting images
into key points, optimizing camera parameters, and estimating structures.
Afterward, accurate sparse reconstructions are required for further dense
modeling, which is subsequently fed into task-specific neural networks. This
multi-step process results in considerable processing time and increased
engineering complexity.
  In this work, we present the Large Spatial Model (LSM), which processes
unposed RGB images directly into semantic radiance fields. LSM simultaneously
estimates geometry, appearance, and semantics in a single feed-forward
operation, and it can generate versatile label maps by interacting with
language at novel viewpoints. Leveraging a Transformer-based architecture, LSM
integrates global geometry through pixel-aligned point maps. To enhance spatial
attribute regression, we incorporate local context aggregation with multi-scale
fusion, improving the accuracy of fine local details. To tackle the scarcity of
labeled 3D semantic data and enable natural language-driven scene manipulation,
we incorporate a pre-trained 2D language-based segmentation model into a
3D-consistent semantic feature field. An efficient decoder then parameterizes a
set of semantic anisotropic Gaussians, facilitating supervised end-to-end
learning. Extensive experiments across various tasks show that LSM unifies
multiple 3D vision tasks directly from unposed images, achieving real-time
semantic 3D reconstruction for the first time.
</summary>
    <author>
      <name>Zhiwen Fan</name>
    </author>
    <author>
      <name>Jian Zhang</name>
    </author>
    <author>
      <name>Wenyan Cong</name>
    </author>
    <author>
      <name>Peihao Wang</name>
    </author>
    <author>
      <name>Renjie Li</name>
    </author>
    <author>
      <name>Kairun Wen</name>
    </author>
    <author>
      <name>Shijie Zhou</name>
    </author>
    <author>
      <name>Achuta Kadambi</name>
    </author>
    <author>
      <name>Zhangyang Wang</name>
    </author>
    <author>
      <name>Danfei Xu</name>
    </author>
    <author>
      <name>Boris Ivanovic</name>
    </author>
    <author>
      <name>Marco Pavone</name>
    </author>
    <author>
      <name>Yue Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project Website: https://largespatialmodel.github.io</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18956v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18956v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18955v1</id>
    <updated>2024-10-24T17:53:53Z</updated>
    <published>2024-10-24T17:53:53Z</published>
    <title>BioMistral-NLU: Towards More Generalizable Medical Language
  Understanding through Instruction Tuning</title>
    <summary>  Large language models (LLMs) such as ChatGPT are fine-tuned on large and
diverse instruction-following corpora, and can generalize to new tasks.
However, those instruction-tuned LLMs often perform poorly in specialized
medical natural language understanding (NLU) tasks that require domain
knowledge, granular text comprehension, and structured data extraction. To
bridge the gap, we: (1) propose a unified prompting format for 7 important NLU
tasks, % through span extraction and multi-choice question-answering (QA), (2)
curate an instruction-tuning dataset, MNLU-Instruct, utilizing diverse existing
open-source medical NLU corpora, and (3) develop BioMistral-NLU, a
generalizable medical NLU model, through fine-tuning BioMistral on
MNLU-Instruct. We evaluate BioMistral-NLU in a zero-shot setting, across 6
important NLU tasks, from two widely adopted medical NLU benchmarks: Biomedical
Language Understanding Evaluation (BLUE) and Biomedical Language Understanding
and Reasoning Benchmark (BLURB). Our experiments show that our BioMistral-NLU
outperforms the original BioMistral, as well as the proprietary LLMs - ChatGPT
and GPT-4. Our dataset-agnostic prompting strategy and instruction tuning step
over diverse NLU tasks enhance LLMs' generalizability across diverse medical
NLU tasks. Our ablation experiments show that instruction-tuning on a wider
variety of tasks, even when the total number of training instances remains
constant, enhances downstream zero-shot generalization.
</summary>
    <author>
      <name>Yujuan Velvin Fu</name>
    </author>
    <author>
      <name>Giridhar Kaushik Ramachandran</name>
    </author>
    <author>
      <name>Namu Park</name>
    </author>
    <author>
      <name>Kevin Lybarger</name>
    </author>
    <author>
      <name>Fei Xia</name>
    </author>
    <author>
      <name>Ozlem Uzuner</name>
    </author>
    <author>
      <name>Meliha Yetisgen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 figures an 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18954v1</id>
    <updated>2024-10-24T17:53:33Z</updated>
    <published>2024-10-24T17:53:33Z</published>
    <title>Learning Structured Compressed Sensing with Automatic Resource
  Allocation</title>
    <summary>  Multidimensional data acquisition often requires extensive time and poses
significant challenges for hardware and software regarding data storage and
processing. Rather than designing a single compression matrix as in
conventional compressed sensing, structured compressed sensing yields
dimension-specific compression matrices, reducing the number of optimizable
parameters. Recent advances in machine learning (ML) have enabled task-based
supervised learning of subsampling matrices, albeit at the expense of complex
downstream models. Additionally, the sampling resource allocation across
dimensions is often determined in advance through heuristics. To address these
challenges, we introduce Structured COmpressed Sensing with Automatic Resource
Allocation (SCOSARA) with an information theory-based unsupervised learning
strategy. SCOSARA adaptively distributes samples across sampling dimensions
while maximizing Fisher information content. Using ultrasound localization as a
case study, we compare SCOSARA to state-of-the-art ML-based and greedy search
algorithms. Simulation results demonstrate that SCOSARA can produce
high-quality subsampling matrices that achieve lower Cram\'er-Rao Bound values
than the baselines. In addition, SCOSARA outperforms other ML-based algorithms
in terms of the number of trainable parameters, computational complexity, and
memory requirements while automatically choosing the number of samples per
axis.
</summary>
    <author>
      <name>Han Wang</name>
    </author>
    <author>
      <name>Eduardo Pérez</name>
    </author>
    <author>
      <name>Iris A. M. Huijben</name>
    </author>
    <author>
      <name>Hans van Gorp</name>
    </author>
    <author>
      <name>Ruud van Sloun</name>
    </author>
    <author>
      <name>Florian Römer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Unsupervised Learning, Information Theory, Compressed Sensing,
  Subsampling</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18954v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18954v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18953v1</id>
    <updated>2024-10-24T17:53:02Z</updated>
    <published>2024-10-24T17:53:02Z</published>
    <title>The Learning Stabilizers with Noise problem</title>
    <summary>  Random classical codes have good error correcting properties, and yet they
are notoriously hard to decode in practice. Despite many decades of extensive
study, the fastest known algorithms still run in exponential time. The Learning
Parity with Noise (LPN) problem, which can be seen as the task of decoding a
random linear code in the presence of noise, has thus emerged as a prominent
hardness assumption with numerous applications in both cryptography and
learning theory.
  Is there a natural quantum analog of the LPN problem? In this work, we
introduce the Learning Stabilizers with Noise (LSN) problem, the task of
decoding a random stabilizer code in the presence of local depolarizing noise.
We give both polynomial-time and exponential-time quantum algorithms for
solving LSN in various depolarizing noise regimes, ranging from extremely low
noise, to low constant noise rates, and even higher noise rates up to a
threshold. Next, we provide concrete evidence that LSN is hard. First, we show
that LSN includes LPN as a special case, which suggests that it is at least as
hard as its classical counterpart. Second, we prove a worst-case to
average-case reduction for variants of LSN. We then ask: what is the
computational complexity of solving LSN? Because the task features quantum
inputs, its complexity cannot be characterized by traditional complexity
classes. Instead, we show that the LSN problem lies in a recently introduced
(distributional and oracle) unitary synthesis class. Finally, we identify
several applications of our LSN assumption, ranging from the construction of
quantum bit commitment schemes to the computational limitations of learning
from quantum data.
</summary>
    <author>
      <name>Alexander Poremba</name>
    </author>
    <author>
      <name>Yihui Quek</name>
    </author>
    <author>
      <name>Peter Shor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">61 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18953v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18953v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18952v1</id>
    <updated>2024-10-24T17:52:31Z</updated>
    <published>2024-10-24T17:52:31Z</published>
    <title>Dynamic Vocabulary Pruning in Early-Exit LLMs</title>
    <summary>  Increasing the size of large language models (LLMs) has been shown to lead to
better performance. However, this comes at the cost of slower and more
expensive inference. Early-exiting is a promising approach for improving the
efficiency of LLM inference by enabling next token prediction at intermediate
layers. Yet, the large vocabulary size in modern LLMs makes the confidence
estimation required for exit decisions computationally expensive, diminishing
the efficiency gains. To address this, we propose dynamically pruning the
vocabulary at test time for each token. Specifically, the vocabulary is pruned
at one of the initial layers, and the smaller vocabulary is then used
throughout the rest of the forward pass. Our experiments demonstrate that such
post-hoc dynamic vocabulary pruning improves the efficiency of confidence
estimation in early-exit LLMs while maintaining competitive performance.
</summary>
    <author>
      <name>Jort Vincenti</name>
    </author>
    <author>
      <name>Karim Abdel Sadek</name>
    </author>
    <author>
      <name>Joan Velja</name>
    </author>
    <author>
      <name>Matteo Nulli</name>
    </author>
    <author>
      <name>Metod Jazbec</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18950v1</id>
    <updated>2024-10-24T17:50:08Z</updated>
    <published>2024-10-24T17:50:08Z</published>
    <title>Adjusted Overfitting Regression</title>
    <summary>  In this paper, I will introduce a new form of regression, that can adjust
overfitting and underfitting through, "distance-based regression." Overfitting
often results in finding false patterns causing inaccurate results, so by
having a new approach that minimizes overfitting, more accurate predictions can
be derived. Then I will proceed with a test of my regression form and show
additional ways to optimize the regression. Finally, I will apply my new
technique to a specific data set to demonstrate its practical value.
</summary>
    <author>
      <name>Dylan Wilson</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18944v1</id>
    <updated>2024-10-24T17:35:12Z</updated>
    <published>2024-10-24T17:35:12Z</published>
    <title>Path Guiding for Monte Carlo PDE Solvers</title>
    <summary>  In recent years, Monte Carlo PDE solvers have garnered increasing attention
in computer graphics, demonstrating value across a wide range of applications.
Despite offering clear advantages over traditional methods-such as avoiding
discretization and enabling local evaluations-Monte Carlo PDE solvers face
challenges due to their stochastic nature, including high variance and slow
convergence rates. To mitigate the variance issue, we draw inspiration from
Monte Carlo path tracing and apply the path guiding technique to the Walk on
Stars estimator. Specifically, we examine the target sampling distribution at
each step of the Walk on Stars estimator, parameterize it, and introduce neural
implicit representations to model the spatially-varying guiding distribution.
This path guiding approach is implemented in a wavefront-style PDE solver, and
experimental results demonstrate that it effectively reduces variance in Monte
Carlo PDE solvers.
</summary>
    <author>
      <name>Tianyu Huang</name>
    </author>
    <author>
      <name>Jingwang Ling</name>
    </author>
    <author>
      <name>Shuang Zhao</name>
    </author>
    <author>
      <name>Feng Xu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18938v1</id>
    <updated>2024-10-24T17:24:34Z</updated>
    <published>2024-10-24T17:24:34Z</published>
    <title>A Random Matrix Theory Perspective on the Spectrum of Learned Features
  and Asymptotic Generalization Capabilities</title>
    <summary>  A key property of neural networks is their capacity of adapting to data
during training. Yet, our current mathematical understanding of feature
learning and its relationship to generalization remain limited. In this work,
we provide a random matrix analysis of how fully-connected two-layer neural
networks adapt to the target function after a single, but aggressive, gradient
descent step. We rigorously establish the equivalence between the updated
features and an isotropic spiked random feature model, in the limit of large
batch size. For the latter model, we derive a deterministic equivalent
description of the feature empirical covariance matrix in terms of certain
low-dimensional operators. This allows us to sharply characterize the impact of
training in the asymptotic feature spectrum, and in particular, provides a
theoretical grounding for how the tails of the feature spectrum modify with
training. The deterministic equivalent further yields the exact asymptotic
generalization error, shedding light on the mechanisms behind its improvement
in the presence of feature learning. Our result goes beyond standard random
matrix ensembles, and therefore we believe it is of independent technical
interest. Different from previous work, our result holds in the challenging
maximal learning rate regime, is fully rigorous and allows for finitely
supported second layer initialization, which turns out to be crucial for
studying the functional expressivity of the learned features. This provides a
sharp description of the impact of feature learning in the generalization of
two-layer neural networks, beyond the random features and lazy training
regimes.
</summary>
    <author>
      <name>Yatin Dandi</name>
    </author>
    <author>
      <name>Luca Pesce</name>
    </author>
    <author>
      <name>Hugo Cui</name>
    </author>
    <author>
      <name>Florent Krzakala</name>
    </author>
    <author>
      <name>Yue M. Lu</name>
    </author>
    <author>
      <name>Bruno Loureiro</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18938v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18938v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18936v1</id>
    <updated>2024-10-24T17:22:24Z</updated>
    <published>2024-10-24T17:22:24Z</published>
    <title>Matching Composition and Efficient Weight Reduction in Dynamic Matching</title>
    <summary>  We consider the foundational problem of maintaining a
$(1-\varepsilon)$-approximate maximum weight matching (MWM) in an $n$-node
dynamic graph undergoing edge insertions and deletions. We provide a general
reduction that reduces the problem on graphs with a weight range of
$\mathrm{poly}(n)$ to $\mathrm{poly}(1/\varepsilon)$ at the cost of just an
additive $\mathrm{poly}(1/\varepsilon)$ in update time. This improves upon the
prior reduction of Gupta-Peng (FOCS 2013) which reduces the problem to a weight
range of $\varepsilon^{-O(1/\varepsilon)}$ with a multiplicative cost of
$O(\log n)$.
  When combined with a reduction of Bernstein-Dudeja-Langley (STOC 2021) this
yields a reduction from dynamic $(1-\varepsilon)$-approximate MWM in bipartite
graphs with a weight range of $\mathrm{poly}(n)$ to dynamic
$(1-\varepsilon)$-approximate maximum cardinality matching in bipartite graphs
at the cost of a multiplicative $\mathrm{poly}(1/\varepsilon)$ in update time,
thereby resolving an open problem in [GP'13; BDL'21]. Additionally, we show
that our approach is amenable to MWM problems in streaming, shared-memory
work-depth, and massively parallel computation models. We also apply our
techniques to obtain an efficient dynamic algorithm for rounding weighted
fractional matchings in general graphs. Underlying our framework is a new
structural result about MWM that we call the "matching composition lemma" and
new dynamic matching subroutines that may be of independent interest.
</summary>
    <author>
      <name>Aaron Bernstein</name>
    </author>
    <author>
      <name>Jiale Chen</name>
    </author>
    <author>
      <name>Aditi Dudeja</name>
    </author>
    <author>
      <name>Zachary Langley</name>
    </author>
    <author>
      <name>Aaron Sidford</name>
    </author>
    <author>
      <name>Ta-Wei Tu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18936v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18936v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18935v1</id>
    <updated>2024-10-24T17:21:43Z</updated>
    <published>2024-10-24T17:21:43Z</published>
    <title>Schema-Guided Culture-Aware Complex Event Simulation with Multi-Agent
  Role-Play</title>
    <summary>  Complex news events, such as natural disasters and socio-political conflicts,
require swift responses from the government and society. Relying on historical
events to project the future is insufficient as such events are sparse and do
not cover all possible conditions and nuanced situations. Simulation of these
complex events can help better prepare and reduce the negative impact. We
develop a controllable complex news event simulator guided by both the event
schema representing domain knowledge about the scenario and user-provided
assumptions representing case-specific conditions. As event dynamics depend on
the fine-grained social and cultural context, we further introduce a
geo-diverse commonsense and cultural norm-aware knowledge enhancement
component. To enhance the coherence of the simulation, apart from the global
timeline of events, we take an agent-based approach to simulate the individual
character states, plans, and actions. By incorporating the schema and cultural
norms, our generated simulations achieve much higher coherence and
appropriateness and are received favorably by participants from a humanitarian
assistance organization.
</summary>
    <author>
      <name>Sha Li</name>
    </author>
    <author>
      <name>Revanth Gangi Reddy</name>
    </author>
    <author>
      <name>Khanh Duy Nguyen</name>
    </author>
    <author>
      <name>Qingyun Wang</name>
    </author>
    <author>
      <name>May Fung</name>
    </author>
    <author>
      <name>Chi Han</name>
    </author>
    <author>
      <name>Jiawei Han</name>
    </author>
    <author>
      <name>Kartik Natarajan</name>
    </author>
    <author>
      <name>Clare R. Voss</name>
    </author>
    <author>
      <name>Heng Ji</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted as EMNLP 2024 Demo</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18935v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18935v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18932v1</id>
    <updated>2024-10-24T17:19:53Z</updated>
    <published>2024-10-24T17:19:53Z</published>
    <title>ANAVI: Audio Noise Awareness using Visuals of Indoor environments for
  NAVIgation</title>
    <summary>  We propose Audio Noise Awareness using Visuals of Indoors for NAVIgation for
quieter robot path planning. While humans are naturally aware of the noise they
make and its impact on those around them, robots currently lack this awareness.
A key challenge in achieving audio awareness for robots is estimating how loud
will the robot's actions be at a listener's location? Since sound depends upon
the geometry and material composition of rooms, we train the robot to passively
perceive loudness using visual observations of indoor environments. To this
end, we generate data on how loud an 'impulse' sounds at different listener
locations in simulated homes, and train our Acoustic Noise Predictor (ANP).
Next, we collect acoustic profiles corresponding to different actions for
navigation. Unifying ANP with action acoustics, we demonstrate experiments with
wheeled (Hello Robot Stretch) and legged (Unitree Go2) robots so that these
robots adhere to the noise constraints of the environment. See code and data at
https://anavi-corl24.github.io/
</summary>
    <author>
      <name>Vidhi Jain</name>
    </author>
    <author>
      <name>Rishi Veerapaneni</name>
    </author>
    <author>
      <name>Yonatan Bisk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8th Conference on Robot Learning (CoRL) 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18931v1</id>
    <updated>2024-10-24T17:18:01Z</updated>
    <published>2024-10-24T17:18:01Z</published>
    <title>Sort-free Gaussian Splatting via Weighted Sum Rendering</title>
    <summary>  Recently, 3D Gaussian Splatting (3DGS) has emerged as a significant
advancement in 3D scene reconstruction, attracting considerable attention due
to its ability to recover high-fidelity details while maintaining low
complexity. Despite the promising results achieved by 3DGS, its rendering
performance is constrained by its dependence on costly non-commutative
alpha-blending operations. These operations mandate complex view dependent
sorting operations that introduce computational overhead, especially on the
resource-constrained platforms such as mobile phones. In this paper, we propose
Weighted Sum Rendering, which approximates alpha blending with weighted sums,
thereby removing the need for sorting. This simplifies implementation, delivers
superior performance, and eliminates the "popping" artifacts caused by sorting.
Experimental results show that optimizing a generalized Gaussian splatting
formulation to the new differentiable rendering yields competitive image
quality. The method was implemented and tested in a mobile device GPU,
achieving on average $1.23\times$ faster rendering.
</summary>
    <author>
      <name>Qiqi Hou</name>
    </author>
    <author>
      <name>Randall Rauwendaal</name>
    </author>
    <author>
      <name>Zifeng Li</name>
    </author>
    <author>
      <name>Hoang Le</name>
    </author>
    <author>
      <name>Farzad Farhadzadeh</name>
    </author>
    <author>
      <name>Fatih Porikli</name>
    </author>
    <author>
      <name>Alexei Bourd</name>
    </author>
    <author>
      <name>Amir Said</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18931v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18931v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18929v1</id>
    <updated>2024-10-24T17:17:11Z</updated>
    <published>2024-10-24T17:17:11Z</published>
    <title>AutoStep: Locally adaptive involutive MCMC</title>
    <summary>  Many common Markov chain Monte Carlo (MCMC) kernels can be formulated using a
deterministic involutive proposal with a step size parameter. Selecting an
appropriate step size is often a challenging task in practice; and for complex
multiscale targets, there may not be one choice of step size that works well
globally. In this work, we address this problem with a novel class of
involutive MCMC methods -- AutoStep MCMC -- that selects an appropriate step
size at each iteration adapted to the local geometry of the target
distribution. We prove that AutoStep MCMC is $\pi$-invariant and has other
desirable properties under mild assumptions on the target distribution $\pi$
and involutive proposal. Empirical results examine the effect of various step
size selection design choices, and show that AutoStep MCMC is competitive with
state-of-the-art methods in terms of effective sample size per unit cost on a
range of challenging target distributions.
</summary>
    <author>
      <name>Tiange Liu</name>
    </author>
    <author>
      <name>Nikola Surjanovic</name>
    </author>
    <author>
      <name>Miguel Biron-Lattes</name>
    </author>
    <author>
      <name>Alexandre Bouchard-Côté</name>
    </author>
    <author>
      <name>Trevor Campbell</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18929v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18929v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18928v1</id>
    <updated>2024-10-24T17:16:19Z</updated>
    <published>2024-10-24T17:16:19Z</published>
    <title>Learning $k$-body Hamiltonians via compressed sensing</title>
    <summary>  We study the problem of learning a $k$-body Hamiltonian with $M$ unknown
Pauli terms that are not necessarily geometrically local. We propose a protocol
that learns the Hamiltonian to precision $\epsilon$ with total evolution time
${\mathcal{O}}(M^{1/2+1/p}/\epsilon)$ up to logarithmic factors, where the
error is quantified by the $\ell^p$-distance between Pauli coefficients. Our
learning protocol uses only single-qubit control operations and a GHZ state
initial state, is non-adaptive, is robust against SPAM errors, and performs
well even if $M$ and $k$ are not precisely known in advance or if the
Hamiltonian is not exactly $M$-sparse. Methods from the classical theory of
compressed sensing are used for efficiently identifying the $M$ terms in the
Hamiltonian from among all possible $k$-body Pauli operators. We also provide a
lower bound on the total evolution time needed in this learning task, and we
discuss the operational interpretations of the $\ell^1$ and $\ell^2$ error
metrics. In contrast to previous works, our learning protocol requires neither
geometric locality nor any other relaxed locality conditions.
</summary>
    <author>
      <name>Muzhou Ma</name>
    </author>
    <author>
      <name>Steven T. Flammia</name>
    </author>
    <author>
      <name>John Preskill</name>
    </author>
    <author>
      <name>Yu Tong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30+12 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18927v1</id>
    <updated>2024-10-24T17:14:40Z</updated>
    <published>2024-10-24T17:14:40Z</published>
    <title>SafeBench: A Safety Evaluation Framework for Multimodal Large Language
  Models</title>
    <summary>  Multimodal Large Language Models (MLLMs) are showing strong safety concerns
(e.g., generating harmful outputs for users), which motivates the development
of safety evaluation benchmarks. However, we observe that existing safety
benchmarks for MLLMs show limitations in query quality and evaluation
reliability limiting the detection of model safety implications as MLLMs
continue to evolve. In this paper, we propose \toolns, a comprehensive
framework designed for conducting safety evaluations of MLLMs. Our framework
consists of a comprehensive harmful query dataset and an automated evaluation
protocol that aims to address the above limitations, respectively. We first
design an automatic safety dataset generation pipeline, where we employ a set
of LLM judges to recognize and categorize the risk scenarios that are most
harmful and diverse for MLLMs; based on the taxonomy, we further ask these
judges to generate high-quality harmful queries accordingly resulting in 23
risk scenarios with 2,300 multi-modal harmful query pairs. During safety
evaluation, we draw inspiration from the jury system in judicial proceedings
and pioneer the jury deliberation evaluation protocol that adopts collaborative
LLMs to evaluate whether target models exhibit specific harmful behaviors,
providing a reliable and unbiased assessment of content security risks. In
addition, our benchmark can also be extended to the audio modality showing high
scalability and potential. Based on our framework, we conducted large-scale
experiments on 15 widely-used open-source MLLMs and 6 commercial MLLMs (e.g.,
GPT-4o, Gemini), where we revealed widespread safety issues in existing MLLMs
and instantiated several insights on MLLM safety performance such as image
quality and parameter size.
</summary>
    <author>
      <name>Zonghao Ying</name>
    </author>
    <author>
      <name>Aishan Liu</name>
    </author>
    <author>
      <name>Siyuan Liang</name>
    </author>
    <author>
      <name>Lei Huang</name>
    </author>
    <author>
      <name>Jinyang Guo</name>
    </author>
    <author>
      <name>Wenbo Zhou</name>
    </author>
    <author>
      <name>Xianglong Liu</name>
    </author>
    <author>
      <name>Dacheng Tao</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18926v1</id>
    <updated>2024-10-24T17:13:39Z</updated>
    <published>2024-10-24T17:13:39Z</published>
    <title>LoRANN: Low-Rank Matrix Factorization for Approximate Nearest Neighbor
  Search</title>
    <summary>  Approximate nearest neighbor (ANN) search is a key component in many modern
machine learning pipelines; recent use cases include retrieval-augmented
generation (RAG) and vector databases. Clustering-based ANN algorithms, that
use score computation methods based on product quantization (PQ), are often
used in industrial-scale applications due to their scalability and suitability
for distributed and disk-based implementations. However, they have slower query
times than the leading graph-based ANN algorithms. In this work, we propose a
new supervised score computation method based on the observation that inner
product approximation is a multivariate (multi-output) regression problem that
can be solved efficiently by reduced-rank regression. Our experiments show that
on modern high-dimensional data sets, the proposed reduced-rank regression
(RRR) method is superior to PQ in both query latency and memory usage. We also
introduce LoRANN, a clustering-based ANN library that leverages the proposed
score computation method. LoRANN is competitive with the leading graph-based
algorithms and outperforms the state-of-the-art GPU ANN methods on
high-dimensional data sets.
</summary>
    <author>
      <name>Elias Jääsaari</name>
    </author>
    <author>
      <name>Ville Hyvönen</name>
    </author>
    <author>
      <name>Teemu Roos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to NeurIPS 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18924v1</id>
    <updated>2024-10-24T17:12:51Z</updated>
    <published>2024-10-24T17:12:51Z</published>
    <title>Swarm manipulation: An efficient and accurate technique for multi-object
  manipulation in virtual reality</title>
    <summary>  The theory of swarm control shows promise for controlling multiple objects,
however, scalability is hindered by cost constraints, such as hardware and
infrastructure. Virtual Reality (VR) can overcome these limitations, but
research on swarm interaction in VR is limited. This paper introduces a novel
Swarm Manipulation interaction technique and compares it with two baseline
techniques: Virtual Hand and Controller (ray-casting). We evaluated these
techniques in a user study ($N$ = 12) in three tasks (selection, rotation, and
resizing) across five conditions. Our results indicate that Swarm Manipulation
yielded superior performance, with significantly faster speeds in most
conditions across the three tasks. It notably reduced resizing size deviations
but introduced a trade-off between speed and accuracy in the rotation task.
Additionally, we conducted a follow-up user study ($N$ = 6) using Swarm
Manipulation in two complex VR scenarios and obtained insights through
semi-structured interviews, shedding light on optimized swarm control
mechanisms and perceptual changes induced by this interaction paradigm. These
results demonstrate the potential of the Swarm Manipulation technique to
enhance the usability and user experience in VR compared to conventional
manipulation techniques. In future studies, we aim to understand and improve
swarm interaction via internal swarm particle cooperation.
</summary>
    <author>
      <name>Xiang Li</name>
    </author>
    <author>
      <name>Jin-Du Wang</name>
    </author>
    <author>
      <name>John J. Dudley</name>
    </author>
    <author>
      <name>Per Ola Kristensson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, accepted at Computers &amp; Graphics</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18923v1</id>
    <updated>2024-10-24T17:11:52Z</updated>
    <published>2024-10-24T17:11:52Z</published>
    <title>SegLLM: Multi-round Reasoning Segmentation</title>
    <summary>  We present SegLLM, a novel multi-round interactive reasoning segmentation
model that enhances LLM-based segmentation by exploiting conversational memory
of both visual and textual outputs. By leveraging a mask-aware multimodal LLM,
SegLLM re-integrates previous segmentation results into its input stream,
enabling it to reason about complex user intentions and segment objects in
relation to previously identified entities, including positional,
interactional, and hierarchical relationships, across multiple interactions.
This capability allows SegLLM to respond to visual and text queries in a
chat-like manner. Evaluated on the newly curated MRSeg benchmark, SegLLM
outperforms existing methods in multi-round interactive reasoning segmentation
by over 20%. Additionally, we observed that training on multi-round reasoning
segmentation data enhances performance on standard single-round referring
segmentation and localization tasks, resulting in a 5.5% increase in cIoU for
referring expression segmentation and a 4.5% improvement in Acc@0.5 for
referring expression localization.
</summary>
    <author>
      <name>XuDong Wang</name>
    </author>
    <author>
      <name>Shaolun Zhang</name>
    </author>
    <author>
      <name>Shufan Li</name>
    </author>
    <author>
      <name>Konstantinos Kallidromitis</name>
    </author>
    <author>
      <name>Kehan Li</name>
    </author>
    <author>
      <name>Yusuke Kato</name>
    </author>
    <author>
      <name>Kazuki Kozuka</name>
    </author>
    <author>
      <name>Trevor Darrell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 10 figures, 11 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18922v1</id>
    <updated>2024-10-24T17:11:37Z</updated>
    <published>2024-10-24T17:11:37Z</published>
    <title>How to Design a Quantum Streaming Algorithm Without Knowing Anything
  About Quantum Computing</title>
    <summary>  A series of work [GKK+08, Kal22, KPV24] has shown that asymptotic advantages
in space complexity are possible for quantum algorithms over their classical
counterparts in the streaming model. We give a simple quantum sketch that
encompasses all these results, allowing them to be derived from entirely
classical algorithms using our quantum sketch as a black box. The quantum
sketch and its proof of correctness are designed to be accessible to a reader
with no background in quantum computation, relying on only a small number of
self-contained quantum postulates.
</summary>
    <author>
      <name>John Kallaugher</name>
    </author>
    <author>
      <name>Ojas Parekh</name>
    </author>
    <author>
      <name>Nadezhda Voronova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in SOSA 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18921v1</id>
    <updated>2024-10-24T17:10:39Z</updated>
    <published>2024-10-24T17:10:39Z</published>
    <title>From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical
  Integrity on Faulty Mathematical Problems</title>
    <summary>  Consider the math problem: "Lily received 3 cookies from her best friend
yesterday and ate 5 for breakfast. Today, her friend gave her 3 more cookies.
How many cookies does Lily have now?" Many large language models (LLMs) in
previous research approach this problem by calculating the answer "1" using the
equation "3 - 5 + 3." However, from a human perspective, we recognize the
inherent flaw in this problem: Lily cannot eat 5 cookies if she initially only
had 3. This discrepancy prompts a key question: Are current LLMs merely Blind
Solver that apply mathematical operations without deeper reasoning, or can they
function as Logical Thinker capable of identifying logical inconsistencies?
  To explore this question, we propose a benchmark dataset, FaultyMath, which
includes faulty math problems of rich diversity: i) multiple mathematical
categories, e.g., algebra, geometry, number theory, etc., ii) varying levels of
difficulty, and iii) different origins of faultiness -- ranging from violations
of common sense and ambiguous statements to mathematical contradictions and
more. We evaluate a broad spectrum of LLMs, including open-source,
closed-source, and math-specialized models, using FaultyMath across three
dimensions: (i) How accurately can the models detect faulty math problems
without being explicitly prompted to do so? (ii) When provided with hints --
either correct or misleading -- about the validity of the problems, to what
extent do LLMs adapt to become reliable Logical Thinker? (iii) How trustworthy
are the explanations generated by LLMs when they recognize a math problem as
flawed? Through extensive experimentation and detailed analysis, our results
demonstrate that existing LLMs largely function as Blind Solver and fall short
of the reasoning capabilities required to perform as Logical Thinker.
</summary>
    <author>
      <name>A M Muntasir Rahman</name>
    </author>
    <author>
      <name>Junyi Ye</name>
    </author>
    <author>
      <name>Wei Yao</name>
    </author>
    <author>
      <name>Wenpeng Yin</name>
    </author>
    <author>
      <name>Guiling Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18921v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18921v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18919v1</id>
    <updated>2024-10-24T17:09:37Z</updated>
    <published>2024-10-24T17:09:37Z</published>
    <title>Optimizing Edge Offloading Decisions for Object Detection</title>
    <summary>  Recent advances in machine learning and hardware have produced embedded
devices capable of performing real-time object detection with commendable
accuracy. We consider a scenario in which embedded devices rely on an onboard
object detector, but have the option to offload detection to a more powerful
edge server when local accuracy is deemed too low. Resource constraints,
however, limit the number of images that can be offloaded to the edge. Our goal
is to identify which images to offload to maximize overall detection accuracy
under those constraints. To that end, the paper introduces a reward metric
designed to quantify potential accuracy improvements from offloading individual
images, and proposes an efficient approach to make offloading decisions by
estimating this reward based only on local detection results. The approach is
computationally frugal enough to run on embedded devices, and empirical
findings indicate that it outperforms existing alternatives in improving
detection accuracy even when the fraction of offloaded images is small.
</summary>
    <author>
      <name>Jiaming Qiu</name>
    </author>
    <author>
      <name>Ruiqi Wang</name>
    </author>
    <author>
      <name>Brooks Hu</name>
    </author>
    <author>
      <name>Roch Guerin</name>
    </author>
    <author>
      <name>Chenyang Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SEC 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18918v1</id>
    <updated>2024-10-24T17:09:10Z</updated>
    <published>2024-10-24T17:09:10Z</published>
    <title>MissNODAG: Differentiable Cyclic Causal Graph Learning from Incomplete
  Data</title>
    <summary>  Causal discovery in real-world systems, such as biological networks, is often
complicated by feedback loops and incomplete data. Standard algorithms, which
assume acyclic structures or fully observed data, struggle with these
challenges. To address this gap, we propose MissNODAG, a differentiable
framework for learning both the underlying cyclic causal graph and the
missingness mechanism from partially observed data, including data missing not
at random. Our framework integrates an additive noise model with an
expectation-maximization procedure, alternating between imputing missing values
and optimizing the observed data likelihood, to uncover both the cyclic
structures and the missingness mechanism. We demonstrate the effectiveness of
MissNODAG through synthetic experiments and an application to real-world gene
perturbation data.
</summary>
    <author>
      <name>Muralikrishnna G. Sethuraman</name>
    </author>
    <author>
      <name>Razieh Nabi</name>
    </author>
    <author>
      <name>Faramarz Fekri</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18918v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18918v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18917v1</id>
    <updated>2024-10-24T17:08:20Z</updated>
    <published>2024-10-24T17:08:20Z</published>
    <title>Using Parametric PINNs for Predicting Internal and External Turbulent
  Flows</title>
    <summary>  Computational fluid dynamics (CFD) solvers employing two-equation eddy
viscosity models are the industry standard for simulating turbulent flows using
the Reynolds-averaged Navier-Stokes (RANS) formulation. While these methods are
computationally less expensive than direct numerical simulations, they can
still incur significant computational costs to achieve the desired accuracy. In
this context, physics-informed neural networks (PINNs) offer a promising
approach for developing parametric surrogate models that leverage both
existing, but limited CFD solutions and the governing differential equations to
predict simulation outcomes in a computationally efficient, differentiable, and
near real-time manner. In this work, we build upon the previously proposed
RANS-PINN framework, which only focused on predicting flow over a cylinder. To
investigate the efficacy of RANS-PINN as a viable approach to building
parametric surrogate models, we investigate its accuracy in predicting relevant
turbulent flow variables for both internal and external flows. To ensure
training convergence with a more complex loss function, we adopt a novel
sampling approach that exploits the domain geometry to ensure a proper balance
among the contributions from various regions within the solution domain. The
effectiveness of this framework is then demonstrated for two scenarios that
represent a broad class of internal and external flow problems.
</summary>
    <author>
      <name>Shinjan Ghosh</name>
    </author>
    <author>
      <name>Amit Chakraborty</name>
    </author>
    <author>
      <name>Georgia Olympia Brikis</name>
    </author>
    <author>
      <name>Biswadip Dey</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be presented at the Data-driven and Differentiable Simulations,
  Surrogates, and Solvers (D3S3) Workshop at NeurIPS'2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18915v1</id>
    <updated>2024-10-24T17:05:34Z</updated>
    <published>2024-10-24T17:05:34Z</published>
    <title>Testing Support Size More Efficiently Than Learning Histograms</title>
    <summary>  Consider two problems about an unknown probability distribution $p$:
  1. How many samples from $p$ are required to test if $p$ is supported on $n$
elements or not? Specifically, given samples from $p$, determine whether it is
supported on at most $n$ elements, or it is "$\epsilon$-far" (in total
variation distance) from being supported on $n$ elements.
  2. Given $m$ samples from $p$, what is the largest lower bound on its support
size that we can produce?
  The best known upper bound for problem (1) uses a general algorithm for
learning the histogram of the distribution $p$, which requires
$\Theta(\tfrac{n}{\epsilon^2 \log n})$ samples. We show that testing can be
done more efficiently than learning the histogram, using only
$O(\tfrac{n}{\epsilon \log n} \log(1/\epsilon))$ samples, nearly matching the
best known lower bound of $\Omega(\tfrac{n}{\epsilon \log n})$. This algorithm
also provides a better solution to problem (2), producing larger lower bounds
on support size than what follows from previous work. The proof relies on an
analysis of Chebyshev polynomial approximations outside the range where they
are designed to be good approximations, and the paper is intended as an
accessible self-contained exposition of the Chebyshev polynomial method.
</summary>
    <author>
      <name>Renato Ferreira Pinto Jr.</name>
    </author>
    <author>
      <name>Nathaniel Harms</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18912v1</id>
    <updated>2024-10-24T17:02:52Z</updated>
    <published>2024-10-24T17:02:52Z</published>
    <title>Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling</title>
    <summary>  Videos of robots interacting with objects encode rich information about the
objects' dynamics. However, existing video prediction approaches typically do
not explicitly account for the 3D information from videos, such as robot
actions and objects' 3D states, limiting their use in real-world robotic
applications. In this work, we introduce a framework to learn object dynamics
directly from multi-view RGB videos by explicitly considering the robot's
action trajectories and their effects on scene dynamics. We utilize the 3D
Gaussian representation of 3D Gaussian Splatting (3DGS) to train a
particle-based dynamics model using Graph Neural Networks. This model operates
on sparse control particles downsampled from the densely tracked 3D Gaussian
reconstructions. By learning the neural dynamics model on offline robot
interaction data, our method can predict object motions under varying initial
configurations and unseen robot actions. The 3D transformations of Gaussians
can be interpolated from the motions of control particles, enabling the
rendering of predicted future object states and achieving action-conditioned
video prediction. The dynamics model can also be applied to model-based
planning frameworks for object manipulation tasks. We conduct experiments on
various kinds of deformable materials, including ropes, clothes, and stuffed
animals, demonstrating our framework's ability to model complex shapes and
dynamics. Our project page is available at https://gs-dynamics.github.io.
</summary>
    <author>
      <name>Mingtong Zhang</name>
    </author>
    <author>
      <name>Kaifeng Zhang</name>
    </author>
    <author>
      <name>Yunzhu Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project Page: https://gs-dynamics.github.io</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18912v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18912v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18907v1</id>
    <updated>2024-10-24T16:59:26Z</updated>
    <published>2024-10-24T16:59:26Z</published>
    <title>SkillMimicGen: Automated Demonstration Generation for Efficient Skill
  Learning and Deployment</title>
    <summary>  Imitation learning from human demonstrations is an effective paradigm for
robot manipulation, but acquiring large datasets is costly and
resource-intensive, especially for long-horizon tasks. To address this issue,
we propose SkillMimicGen (SkillGen), an automated system for generating
demonstration datasets from a few human demos. SkillGen segments human demos
into manipulation skills, adapts these skills to new contexts, and stitches
them together through free-space transit and transfer motion. We also propose a
Hybrid Skill Policy (HSP) framework for learning skill initiation, control, and
termination components from SkillGen datasets, enabling skills to be sequenced
using motion planning at test-time. We demonstrate that SkillGen greatly
improves data generation and policy learning performance over a
state-of-the-art data generation framework, resulting in the capability to
produce data for large scene variations, including clutter, and agents that are
on average 24% more successful. We demonstrate the efficacy of SkillGen by
generating over 24K demonstrations across 18 task variants in simulation from
just 60 human demonstrations, and training proficient, often near-perfect, HSP
agents. Finally, we apply SkillGen to 3 real-world manipulation tasks and also
demonstrate zero-shot sim-to-real transfer on a long-horizon assembly task.
Videos, and more at https://skillgen.github.io.
</summary>
    <author>
      <name>Caelan Garrett</name>
    </author>
    <author>
      <name>Ajay Mandlekar</name>
    </author>
    <author>
      <name>Bowen Wen</name>
    </author>
    <author>
      <name>Dieter Fox</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2024 Conference on Robot Learning (CoRL)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2410.18907v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18907v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18906v1</id>
    <updated>2024-10-24T16:57:20Z</updated>
    <published>2024-10-24T16:57:20Z</published>
    <title>PRISM: A Methodology for Auditing Biases in Large Language Models</title>
    <summary>  Auditing Large Language Models (LLMs) to discover their biases and
preferences is an emerging challenge in creating Responsible Artificial
Intelligence (AI). While various methods have been proposed to elicit the
preferences of such models, countermeasures have been taken by LLM trainers,
such that LLMs hide, obfuscate or point blank refuse to disclosure their
positions on certain subjects. This paper presents PRISM, a flexible,
inquiry-based methodology for auditing LLMs - that seeks to illicit such
positions indirectly through task-based inquiry prompting rather than direct
inquiry of said preferences. To demonstrate the utility of the methodology, we
applied PRISM on the Political Compass Test, where we assessed the political
leanings of twenty-one LLMs from seven providers. We show LLMs, by default,
espouse positions that are economically left and socially liberal (consistent
with prior work). We also show the space of positions that these models are
willing to espouse - where some models are more constrained and less compliant
than others - while others are more neutral and objective. In sum, PRISM can
more reliably probe and audit LLMs to understand their preferences, biases and
constraints.
</summary>
    <author>
      <name>Leif Azzopardi</name>
    </author>
    <author>
      <name>Yashar Moshfeghi</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18906v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18906v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18904v1</id>
    <updated>2024-10-24T16:48:32Z</updated>
    <published>2024-10-24T16:48:32Z</published>
    <title>Modulated Adaptive Fourier Neural Operators for Temporal Interpolation
  of Weather Forecasts</title>
    <summary>  Weather and climate data are often available at limited temporal resolution,
either due to storage limitations, or in the case of weather forecast models
based on deep learning, their inherently long time steps. The coarse temporal
resolution makes it difficult to capture rapidly evolving weather events. To
address this limitation, we introduce an interpolation model that reconstructs
the atmospheric state between two points in time for which the state is known.
The model makes use of a novel network layer that modifies the adaptive Fourier
neural operator (AFNO), which has been previously used in weather prediction
and other applications of machine learning to physics problems. The modulated
AFNO (ModAFNO) layer takes an embedding, here computed from the interpolation
target time, as an additional input and applies a learned shift-scale operation
inside the AFNO layers to adapt them to the target time. Thus, one model can be
used to produce all intermediate time steps. Trained to interpolate between two
time steps 6 h apart, the ModAFNO-based interpolation model produces 1 h
resolution intermediate time steps that are visually nearly indistinguishable
from the actual corresponding 1 h resolution data. The model reduces the RMSE
loss of reconstructing the intermediate steps by approximately 50% compared to
linear interpolation. We also demonstrate its ability to reproduce the
statistics of extreme weather events such as hurricanes and heat waves better
than 6 h resolution data. The ModAFNO layer is generic and is expected to be
applicable to other problems, including weather forecasting with tunable lead
time.
</summary>
    <author>
      <name>Jussi Leinonen</name>
    </author>
    <author>
      <name>Boris Bonev</name>
    </author>
    <author>
      <name>Thorsten Kurth</name>
    </author>
    <author>
      <name>Yair Cohen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18902v1</id>
    <updated>2024-10-24T16:48:12Z</updated>
    <published>2024-10-24T16:48:12Z</published>
    <title>LLMs for Extremely Low-Resource Finno-Ugric Languages</title>
    <summary>  The advancement of large language models (LLMs) has predominantly focused on
high-resource languages, leaving low-resource languages, such as those in the
Finno-Ugric family, significantly underrepresented. This paper addresses this
gap by focusing on V\~oro, Livonian, and Komi. We cover almost the entire cycle
of LLM creation, from data collection to instruction tuning and evaluation. Our
contributions include developing multilingual base and instruction-tuned
models; creating evaluation benchmarks, including the smugri-MT-bench
multi-turn conversational benchmark; and conducting human evaluation. We intend
for this work to promote linguistic diversity, ensuring that lesser-resourced
languages can benefit from advancements in NLP.
</summary>
    <author>
      <name>Taido Purason</name>
    </author>
    <author>
      <name>Hele-Andra Kuulmets</name>
    </author>
    <author>
      <name>Mark Fishel</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18902v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18902v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18900v1</id>
    <updated>2024-10-24T16:40:36Z</updated>
    <published>2024-10-24T16:40:36Z</published>
    <title>Comparative Analysis of Indicators for Multiobjective Diversity
  Optimization</title>
    <summary>  Indicator-based (multiobjective) diversity optimization aims at finding a set
of near (Pareto-)optimal solutions that maximizes a diversity indicator, where
diversity is typically interpreted as the number of essentially different
solutions. Whereas, in the first diversity-oriented evolutionary multiobjective
optimization algorithm, the NOAH algorithm by Ulrich and Thiele, the Solow
Polasky Diversity (also related to Magnitude) served as a metric, other
diversity indicators might be considered, such as the parameter-free Max-Min
Diversity, and the Riesz s-Energy, which features uniformly distributed
solution sets. In this paper, focusing on multiobjective diversity
optimization, we discuss different diversity indicators from the perspective of
indicator-based evolutionary algorithms (IBEA) with multiple objectives. We
examine theoretical, computational, and practical properties of these
indicators, such as monotonicity in species, twinning, monotonicity in
distance, strict monotonicity in distance, uniformity of maximizing point sets,
computational effort for a set of size~n, single-point contributions, subset
selection, and submodularity. We present new theorems -- including a proof of
the NP-hardness of the Riesz s-Energy Subset Selection Problem -- and
consolidate existing results from the literature. In the second part, we apply
these indicators in the NOAH algorithm and analyze search dynamics through an
example. We examine how optimizing with one indicator affects the performance
of others and propose NOAH adaptations specific to the Max-Min indicator.
</summary>
    <author>
      <name>Ksenia Pereverdieva</name>
    </author>
    <author>
      <name>André Deutz</name>
    </author>
    <author>
      <name>Tessa Ezendam</name>
    </author>
    <author>
      <name>Thomas Bäck</name>
    </author>
    <author>
      <name>Hèrm Hofmeyer</name>
    </author>
    <author>
      <name>Michael T. M. Emmerich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18900v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18900v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18895v1</id>
    <updated>2024-10-24T16:35:23Z</updated>
    <published>2024-10-24T16:35:23Z</published>
    <title>ArterialNet: Reconstructing Arterial Blood Pressure Waveform with
  Wearable Pulsatile Signals, a Cohort-Aware Approach</title>
    <summary>  Continuous arterial blood pressure (ABP) monitoring is invasive but essential
for hemodynamic monitoring. Recent techniques have reconstructed ABP
non-invasively using pulsatile signals but produced inaccurate systolic and
diastolic blood pressure (SBP and DBP) values and were sensitive to individual
variability. ArterialNet integrates generalized pulsatile-to-ABP signal
translation and personalized feature extraction using hybrid loss functions and
regularization. We validated ArterialNet using the MIMIC-III dataset and
achieved a root mean square error (RMSE) of 5.41 mmHg, with at least a 58%
lower standard deviation. ArterialNet reconstructed ABP with an RMSE of 7.99
mmHg in remote health scenarios. ArterialNet achieved superior performance in
ABP reconstruction and SBP and DBP estimations, with significantly reduced
subject variance, demonstrating its potential in remote health settings. We
also ablated ArterialNet architecture to investigate the contributions of each
component and evaluated its translational impact and robustness by conducting a
series of ablations on data quality and availability.
</summary>
    <author>
      <name>Sicong Huang</name>
    </author>
    <author>
      <name>Roozbeh Jafari</name>
    </author>
    <author>
      <name>Bobak J. Mortazavi</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18895v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18895v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18894v1</id>
    <updated>2024-10-24T16:32:23Z</updated>
    <published>2024-10-24T16:32:23Z</published>
    <title>Meta-Learning with Heterogeneous Tasks</title>
    <summary>  Meta-learning is a general approach to equip machine learning models with the
ability to handle few-shot scenarios when dealing with many tasks. Most
existing meta-learning methods work based on the assumption that all tasks are
of equal importance. However, real-world applications often present
heterogeneous tasks characterized by varying difficulty levels, noise in
training samples, or being distinctively different from most other tasks. In
this paper, we introduce a novel meta-learning method designed to effectively
manage such heterogeneous tasks by employing rank-based task-level learning
objectives, Heterogeneous Tasks Robust Meta-learning (HeTRoM). HeTRoM is
proficient in handling heterogeneous tasks, and it prevents easy tasks from
overwhelming the meta-learner. The approach allows for an efficient iterative
optimization algorithm based on bi-level optimization, which is then improved
by integrating statistical guidance. Our experimental results demonstrate that
our method provides flexibility, enabling users to adapt to diverse task
settings and enhancing the meta-learner's overall performance.
</summary>
    <author>
      <name>Zhaofeng Si</name>
    </author>
    <author>
      <name>Shu Hu</name>
    </author>
    <author>
      <name>Kaiyi Ji</name>
    </author>
    <author>
      <name>Siwei Lyu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18894v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18894v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18893v1</id>
    <updated>2024-10-24T16:30:14Z</updated>
    <published>2024-10-24T16:30:14Z</published>
    <title>Creating and Repairing Robot Programs in Open-World Domains</title>
    <summary>  Using Large Language Models (LLMs) to produce robot programs from natural
language has allowed for robot systems that can complete a higher diversity of
tasks. However, LLM-generated programs may be faulty, either due to ambiguity
in instructions, misinterpretation of the desired task, or missing information
about the world state. As these programs run, the state of the world changes
and they gather new information. When a failure occurs, it is important that
they recover from the current world state and avoid repeating steps that they
they previously completed successfully. We propose RoboRepair, a system which
traces the execution of a program up until error, and then runs an LLM-produced
recovery program that minimizes repeated actions.
  To evaluate the efficacy of our system, we create a benchmark consisting of
eleven tasks with various error conditions that require the generation of a
recovery program. We compare the efficiency of the recovery program to a plan
built with an oracle that has foreknowledge of future errors.
</summary>
    <author>
      <name>Claire Schlesinger</name>
    </author>
    <author>
      <name>Arjun Guha</name>
    </author>
    <author>
      <name>Joydeep Biswas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under review at ACL Rolling Review</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18893v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18893v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18890v1</id>
    <updated>2024-10-24T16:27:35Z</updated>
    <published>2024-10-24T16:27:35Z</published>
    <title>Improving Small-Scale Large Language Models Function Calling for
  Reasoning Tasks</title>
    <summary>  Recent advancements in Large Language Models (LLMs) have demonstrated
exceptional capabilities in natural language understanding and generation.
While these models excel in general complex reasoning tasks, they still face
challenges in mathematical problem-solving and logical reasoning. To address
these limitations, researchers have explored function calling abilities,
allowing LLMs to execute provided functions and utilize their outputs for task
completion. However, concentrating on specific tasks can be very inefficient
for large-scale LLMs to be used, because of the expensive cost of training and
inference stages they need in terms of computational resources. This study
introduces a novel framework for training smaller language models in function
calling, focusing on specific logical and mathematical reasoning tasks. The
approach aims to improve performances of small-scale models for these tasks
using function calling, ensuring a high level of accuracy. Our framework
employs an agent that, given a problem and a set of callable functions, queries
the LLM by injecting a description and examples of the usable functions into
the prompt and managing their calls in a step-by-step reasoning chain. This
process is used to create a dataset of correct and incorrect reasoning chain
chat completions from a large-scale LLM. This dataset is used to train a
smaller LLM using Reinforcement Learning from Human Feedback (RLHF),
specifically employing the Direct Preference Optimization (DPO) technique.
Experimental results demonstrate how the proposed approach balances the
trade-off between model size and performance, improving the ability of function
calling for reasoning tasks, in smaller models.
</summary>
    <author>
      <name>Graziano A. Manduzio</name>
    </author>
    <author>
      <name>Federico A. Galatolo</name>
    </author>
    <author>
      <name>Mario G. C. A. Cimino</name>
    </author>
    <author>
      <name>Enzo Pasquale Scilingo</name>
    </author>
    <author>
      <name>Lorenzo Cominelli</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18889v1</id>
    <updated>2024-10-24T16:27:03Z</updated>
    <published>2024-10-24T16:27:03Z</published>
    <title>Are LLMs Better than Reported? Detecting Label Errors and Mitigating
  Their Effect on Model Performance</title>
    <summary>  NLP benchmarks rely on standardized datasets for training and evaluating
models and are crucial for advancing the field. Traditionally, expert
annotations ensure high-quality labels; however, the cost of expert annotation
does not scale well with the growing demand for larger datasets required by
modern models. While crowd-sourcing provides a more scalable solution, it often
comes at the expense of annotation precision and consistency. Recent
advancements in large language models (LLMs) offer new opportunities to enhance
the annotation process, particularly for detecting label errors in existing
datasets. In this work, we consider the recent approach of LLM-as-a-judge,
leveraging an ensemble of LLMs to flag potentially mislabeled examples. Through
a case study of four datasets from the TRUE benchmark, covering different tasks
and domains, we empirically analyze the labeling quality of existing datasets,
and compare expert, crowd-sourced, and our LLM-based annotations in terms of
agreement, label quality, and efficiency, demonstrating the strengths and
limitations of each annotation method. Our findings reveal a substantial number
of label errors, which, when corrected, induce a significant upward shift in
reported model performance. This suggests that many of the LLMs so-called
mistakes are due to label errors rather than genuine model failures.
Additionally, we discuss the implications of mislabeled data and propose
methods to mitigate them in training to improve model performance.
</summary>
    <author>
      <name>Omer Nahum</name>
    </author>
    <author>
      <name>Nitay Calderon</name>
    </author>
    <author>
      <name>Orgad Keller</name>
    </author>
    <author>
      <name>Idan Szpektor</name>
    </author>
    <author>
      <name>Roi Reichart</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18889v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18889v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18888v1</id>
    <updated>2024-10-24T16:25:58Z</updated>
    <published>2024-10-24T16:25:58Z</published>
    <title>Existence of solutions to port-Hamiltonian systems: initial value
  problems and optimal control</title>
    <summary>  We investigate the existence of solutions of reversible and irreversible
port-Hamiltonian systems. To this end, we utilize the associated exergy, a
function that is composed of the system's Hamiltonian and entropy, to prove
global existence in time for bounded control functions. The results are then
leveraged to prove existence of solutions of energy- and entropy-optimal
control problems. Last, we explore model predictive control tailored to
irreversible port-Hamiltonian systems by means of a numerical case study with a
heat exchanger network.
</summary>
    <author>
      <name>Willem Esterhuizen</name>
    </author>
    <author>
      <name>Bernhard Maschke</name>
    </author>
    <author>
      <name>Till Preuster</name>
    </author>
    <author>
      <name>Manuel Schaller</name>
    </author>
    <author>
      <name>Karl Worthmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18888v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18888v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="34A12, 49J15, 80M50, 93D20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18885v1</id>
    <updated>2024-10-24T16:20:57Z</updated>
    <published>2024-10-24T16:20:57Z</published>
    <title>Connectivity Labeling Schemes for Edge and Vertex Faults via Expander
  Hierarchies</title>
    <summary>  We consider the problem of assigning short labels to the vertices and edges
of a graph $G$ so that given any query $\langle s,t,F\rangle$ with $|F|\leq f$,
we can determine whether $s$ and $t$ are still connected in $G-F$, given only
the labels of $F\cup\{s,t\}$. This problem has been considered when $F\subset
E$ (edge faults), where correctness is guaranteed with high probability
(w.h.p.) or deterministically, and when $F\subset V$ (vertex faults), both
w.h.p.~and deterministically. Our main results are as follows.
  [Deterministic Edge Faults.] We give a new deterministic labeling scheme for
edge faults that uses $\tilde{O}(\sqrt{f})$-bit labels, which can be
constructed in polynomial time. This improves on Dory and Parter's [PODC 2021]
existential bound of $O(f\log n)$ (requiring exponential time to compute) and
the efficient $\tilde{O}(f^2)$-bit scheme of Izumi, Emek, Wadayama, and
Masuzawa [PODC 2023]. Our construction uses an improved edge-expander hierarchy
and a distributed coding technique based on Reed-Solomon codes.
  [Deterministic Vertex Faults.] We improve Parter, Petruschka, and Pettie's
[STOC 2024] deterministic $O(f^7\log^{13} n)$-bit labeling scheme for vertex
faults to $O(f^4\log^{7.5} n)$ bits, using an improved vertex-expander
hierarchy and better sparsification of shortcut graphs.
  [Randomized Edge/Verex Faults.] We improve the size of Dory and Parter's
[PODC 2021] randomized edge fault labeling scheme from $O(\min\{f+\log n,
\log^3 n\})$ bits to $O(\min\{f+\log n, \log^2 n\log f\})$ bits, shaving a
$\log n/\log f$ factor. We also improve the size of Parter, Petruschka, and
Pettie's [STOC 2024] randomized vertex fault labeling scheme from $O(f^3\log^5
n)$ bits to $O(f^2\log^6 n)$ bits, which comes closer to their $\Omega(f)$-bit
lower bound.
</summary>
    <author>
      <name>Yaowei Long</name>
    </author>
    <author>
      <name>Seth Pettie</name>
    </author>
    <author>
      <name>Thatchaphol Saranurak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in SODA 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18885v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18885v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18882v1</id>
    <updated>2024-10-24T16:17:47Z</updated>
    <published>2024-10-24T16:17:47Z</published>
    <title>A Survey of Multimodal Sarcasm Detection</title>
    <summary>  Sarcasm is a rhetorical device that is used to convey the opposite of the
literal meaning of an utterance. Sarcasm is widely used on social media and
other forms of computer-mediated communication motivating the use of
computational models to identify it automatically. While the clear majority of
approaches to sarcasm detection have been carried out on text only, sarcasm
detection often requires additional information present in tonality, facial
expression, and contextual images. This has led to the introduction of
multimodal models, opening the possibility to detect sarcasm in multiple
modalities such as audio, images, text, and video. In this paper, we present
the first comprehensive survey on multimodal sarcasm detection - henceforth MSD
- to date. We survey papers published between 2018 and 2023 on the topic, and
discuss the models and datasets used for this task. We also present future
research directions in MSD.
</summary>
    <author>
      <name>Shafkat Farabi</name>
    </author>
    <author>
      <name>Tharindu Ranasinghe</name>
    </author>
    <author>
      <name>Diptesh Kanojia</name>
    </author>
    <author>
      <name>Yu Kong</name>
    </author>
    <author>
      <name>Marcos Zampieri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.24963/ijcai.2024/887</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.24963/ijcai.2024/887" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the Proceedings of the Thirty-Third International Joint
  Conference on Artificial Intelligence Survey Track. Pages 8020-8028</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18881v1</id>
    <updated>2024-10-24T16:17:18Z</updated>
    <published>2024-10-24T16:17:18Z</published>
    <title>Diff-Instruct++: Training One-step Text-to-image Generator Model to
  Align with Human Preferences</title>
    <summary>  One-step text-to-image generator models offer advantages such as swift
inference efficiency, flexible architectures, and state-of-the-art generation
performance. In this paper, we study the problem of aligning one-step generator
models with human preferences for the first time. Inspired by the success of
reinforcement learning using human feedback (RLHF), we formulate the alignment
problem as maximizing expected human reward functions while adding an Integral
Kullback-Leibler divergence term to prevent the generator from diverging. By
overcoming technical challenges, we introduce Diff-Instruct++ (DI++), the
first, fast-converging and image data-free human preference alignment method
for one-step text-to-image generators. We also introduce novel theoretical
insights, showing that using CFG for diffusion distillation is secretly doing
RLHF with DI++. Such an interesting finding brings understanding and potential
contributions to future research involving CFG. In the experiment sections, we
align both UNet-based and DiT-based one-step generators using DI++, which use
the Stable Diffusion 1.5 and the PixelArt-$\alpha$ as the reference diffusion
processes. The resulting DiT-based one-step text-to-image model achieves a
strong Aesthetic Score of 6.19 and an Image Reward of 1.24 on the COCO
validation prompt dataset. It also achieves a leading Human preference Score
(HPSv2.0) of 28.48, outperforming other open-sourced models such as Stable
Diffusion XL, DMD2, SD-Turbo, as well as PixelArt-$\alpha$. Both theoretical
contributions and empirical evidence indicate that DI++ is a strong
human-preference alignment approach for one-step text-to-image models.
</summary>
    <author>
      <name>Weijian Luo</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18879v1</id>
    <updated>2024-10-24T16:13:06Z</updated>
    <published>2024-10-24T16:13:06Z</published>
    <title>Multi-Class Abnormality Classification in Video Capsule Endoscopy Using
  Deep Learning</title>
    <summary>  This report outlines Team Seq2Cure's deep learning approach for the Capsule
Vision 2024 Challenge, leveraging an ensemble of convolutional neural networks
(CNNs) and transformer-based architectures for multi-class abnormality
classification in video capsule endoscopy frames. The dataset comprised over
50,000 frames from three public sources and one private dataset, labeled across
10 abnormality classes. To overcome the limitations of traditional CNNs in
capturing global context, we integrated CNN and transformer models within a
multi-model ensemble. Our approach achieved a balanced accuracy of 86.34
percent and a mean AUC-ROC score of 0.9908 on the validation set, with
significant improvements in classifying complex abnormalities. Code is
available at http://github.com/arnavs04/capsule-vision-2024 .
</summary>
    <author>
      <name>Arnav Samal</name>
    </author>
    <author>
      <name> Ranya</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18878v1</id>
    <updated>2024-10-24T16:08:41Z</updated>
    <published>2024-10-24T16:08:41Z</published>
    <title>Packing Short Cycles</title>
    <summary>  Cycle packing is a fundamental problem in optimization, graph theory, and
algorithms. Motivated by recent advancements in finding vertex-disjoint paths
between a specified set of vertices that either minimize the total length of
the paths [Bj\"orklund, Husfeldt, ICALP 2014; Mari, Mukherjee, Pilipczuk, and
Sankowski, SODA 2024] or request the paths to be shortest [Lochet, SODA 2021],
we consider the following cycle packing problems: Min-Sum Cycle Packing and
Shortest Cycle Packing.
  In Min-Sum Cycle Packing, we try to find, in a weighted undirected graph, $k$
vertex-disjoint cycles of minimum total weight. Our first main result is an
algorithm that, for any fixed $k$, solves the problem in polynomial time. We
complement this result by establishing the W[1]-hardness of Min-Sum Cycle
Packing parameterized by $k$. The same results hold for the version of the
problem where the task is to find $k$ edge-disjoint cycles.
  Our second main result concerns Shortest Cycle Packing, which is a special
case of Min-Sum Cycle Packing that asks to find a packing of $k$ shortest
cycles in a graph. We prove this problem to be fixed-parameter tractable (FPT)
when parameterized by $k$ on weighted planar graphs. We also obtain a
polynomial kernel for the edge-disjoint variant of the problem on planar
graphs. Deciding whether Min-Sum Cycle Packing is FPT on planar graphs and
whether Shortest Cycle Packing is FPT on general graphs remain challenging open
questions.
</summary>
    <author>
      <name>Matthias Bentert</name>
    </author>
    <author>
      <name>Fedor V. Fomin</name>
    </author>
    <author>
      <name>Petr A. Golovach</name>
    </author>
    <author>
      <name>Tuukka Korhonen</name>
    </author>
    <author>
      <name>William Lochet</name>
    </author>
    <author>
      <name>Fahad Panolan</name>
    </author>
    <author>
      <name>M. S. Ramanujan</name>
    </author>
    <author>
      <name>Saket Saurabh</name>
    </author>
    <author>
      <name>Kirill Simonov</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18878v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18878v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18876v1</id>
    <updated>2024-10-24T16:05:38Z</updated>
    <published>2024-10-24T16:05:38Z</published>
    <title>Guiding Empowerment Model: Liberating Neurodiversity in Online Higher
  Education</title>
    <summary>  In this innovative practice full paper, we address the equity gap for
neurodivergent and situationally limited learners by identifying the spectrum
of dynamic factors that impact learning and function. Educators have shown a
growing interest in identifying learners' cognitive abilities and learning
preferences to measure their impact on academic achievement. Often institutions
employ one-size-fits-all approaches leaving the burden on disabled students to
self-advocate or tolerate inadequate support. Emerging frameworks guide
neurodivergent learners through instructional approaches, such as online
education. However, these frameworks fail to address holistic environmental
needs or recommend technology interventions, particularly for those with
undisclosed learning or developmental disabilities and situational limitations.
In this article, we integrate a neurodivergent perspective through secondary
research of around 100 articles to introduce a Guiding Empowerment Model
involving key cognitive and situational factors that contextualize day-to-day
experiences affecting learner ability. We synthesize three sample student
profiles that highlight user problems in functioning. We use this model to
evaluate sample learning platform features and other supportive technology
solutions. The proposed approach augments frameworks such as Universal Design
for Learning to consider factors including various sensory processing
differences, social connection challenges, and environmental limitations. We
suggest that by applying the mode through technology-enabled features such as
customizable task management, guided varied content access, and guided
multi-modal collaboration, major learning barriers of neurodivergent and
situationally limited learners will be removed to activate the successful
pursuit of their academic goals.
</summary>
    <author>
      <name>Hannah Beaux</name>
    </author>
    <author>
      <name>Pegah Karimi</name>
    </author>
    <author>
      <name>Otilia Pop</name>
    </author>
    <author>
      <name>Rob Clark</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 Figure, 1 Table, Accepted in FIE 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18875v1</id>
    <updated>2024-10-24T16:05:11Z</updated>
    <published>2024-10-24T16:05:11Z</published>
    <title>Exploring the Universe with SNAD: Anomaly Detection in Astronomy</title>
    <summary>  SNAD is an international project with a primary focus on detecting
astronomical anomalies within large-scale surveys, using active learning and
other machine learning algorithms. The work carried out by SNAD not only
contributes to the discovery and classification of various astronomical
phenomena but also enhances our understanding and implementation of machine
learning techniques within the field of astrophysics. This paper provides a
review of the SNAD project and summarizes the advancements and achievements
made by the team over several years.
</summary>
    <author>
      <name>Alina A. Volnova</name>
    </author>
    <author>
      <name>Patrick D. Aleo</name>
    </author>
    <author>
      <name>Anastasia Lavrukhina</name>
    </author>
    <author>
      <name>Etienne Russeil</name>
    </author>
    <author>
      <name>Timofey Semenikhin</name>
    </author>
    <author>
      <name>Emmanuel Gangler</name>
    </author>
    <author>
      <name>Emille E. O. Ishida</name>
    </author>
    <author>
      <name>Matwey V. Kornilov</name>
    </author>
    <author>
      <name>Vladimir Korolev</name>
    </author>
    <author>
      <name>Konstantin Malanchev</name>
    </author>
    <author>
      <name>Maria V. Pruzhinskaya</name>
    </author>
    <author>
      <name>Sreevarsha Sreejith</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-031-67826-4_15</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-031-67826-4_15" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: Baixeries, J., Ignatov, D.I., Kuznetsov, S.O., Stupnikov, S.
  (eds) Data Analytics and Management in Data Intensive Domains. DAMDID/RCDL
  2023. Communications in Computer and Information Science, vol 2086. Springer,
  Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2410.18875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18871v1</id>
    <updated>2024-10-24T15:58:14Z</updated>
    <published>2024-10-24T15:58:14Z</published>
    <title>Learning Collusion in Episodic, Inventory-Constrained Markets</title>
    <summary>  Pricing algorithms have demonstrated the capability to learn tacit collusion
that is largely unaddressed by current regulations. Their increasing use in
markets, including oligopolistic industries with a history of collusion, calls
for closer examination by competition authorities. In this paper, we extend the
study of tacit collusion in learning algorithms from basic pricing games to
more complex markets characterized by perishable goods with fixed supply and
sell-by dates, such as airline tickets, perishables, and hotel rooms. We
formalize collusion within this framework and introduce a metric based on price
levels under both the competitive (Nash) equilibrium and collusive
(monopolistic) optimum. Since no analytical expressions for these price levels
exist, we propose an efficient computational approach to derive them. Through
experiments, we demonstrate that deep reinforcement learning agents can learn
to collude in this more complex domain. Additionally, we analyze the underlying
mechanisms and structures of the collusive strategies these agents adopt.
</summary>
    <author>
      <name>Paul Friedrich</name>
    </author>
    <author>
      <name>Barna Pásztor</name>
    </author>
    <author>
      <name>Giorgia Ramponi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages, 25 figures. Under review</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18871v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18871v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18870v1</id>
    <updated>2024-10-24T15:57:17Z</updated>
    <published>2024-10-24T15:57:17Z</published>
    <title>End-to-end Training for Recommendation with Language-based User Profiles</title>
    <summary>  Many online platforms maintain user profiles for personalization.
Unfortunately, these profiles are typically not interpretable or easily
modifiable by the user. To remedy this shortcoming, we explore natural
language-based user profiles, as they promise enhanced transparency and
scrutability of recommender systems. While existing work has shown that
language-based profiles from standard LLMs can be effective, such generalist
LLMs are unlikely to be optimal for this task. In this paper, we introduce
LangPTune, the first end-to-end learning method for training LLMs to produce
language-based user profiles that optimize recommendation effectiveness.
Through comprehensive evaluations of LangPTune across various training
configurations and benchmarks, we demonstrate that our approach significantly
outperforms existing profile-based methods. In addition, it approaches
performance levels comparable to state-of-the-art, less transparent recommender
systems, providing a robust and interpretable alternative to conventional
systems. Finally, we validate the relative interpretability of these
language-based user profiles through user studies involving crowdworkers and
GPT-4-based evaluations. Implementation of LangPTune can be found at
https://github.com/ZhaolinGao/LangPTune.
</summary>
    <author>
      <name>Zhaolin Gao</name>
    </author>
    <author>
      <name>Joyce Zhou</name>
    </author>
    <author>
      <name>Yijia Dai</name>
    </author>
    <author>
      <name>Thorsten Joachims</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18870v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18870v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18868v1</id>
    <updated>2024-10-24T15:53:21Z</updated>
    <published>2024-10-24T15:53:21Z</published>
    <title>A Riemannian Framework for Learning Reduced-order Lagrangian Dynamics</title>
    <summary>  By incorporating physical consistency as inductive bias, deep neural networks
display increased generalization capabilities and data efficiency in learning
nonlinear dynamic models. However, the complexity of these models generally
increases with the system dimensionality, requiring larger datasets, more
complex deep networks, and significant computational effort. We propose a novel
geometric network architecture to learn physically-consistent reduced-order
dynamic parameters that accurately describe the original high-dimensional
system behavior. This is achieved by building on recent advances in model-order
reduction and by adopting a Riemannian perspective to jointly learn a
structure-preserving latent space and the associated low-dimensional dynamics.
Our approach enables accurate long-term predictions of the high-dimensional
dynamics of rigid and deformable systems with increased data efficiency by
inferring interpretable and physically plausible reduced Lagrangian models.
</summary>
    <author>
      <name>Katharina Friedl</name>
    </author>
    <author>
      <name>Noémie Jaquier</name>
    </author>
    <author>
      <name>Jens Lundell</name>
    </author>
    <author>
      <name>Tamim Asfour</name>
    </author>
    <author>
      <name>Danica Kragic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18866v1</id>
    <updated>2024-10-24T15:51:04Z</updated>
    <published>2024-10-24T15:51:04Z</published>
    <title>The Cat and Mouse Game: The Ongoing Arms Race Between Diffusion Models
  and Detection Methods</title>
    <summary>  The emergence of diffusion models has transformed synthetic media generation,
offering unmatched realism and control over content creation. These
advancements have driven innovation across fields such as art, design, and
scientific visualization. However, they also introduce significant ethical and
societal challenges, particularly through the creation of hyper-realistic
images that can facilitate deepfakes, misinformation, and unauthorized
reproduction of copyrighted material. In response, the need for effective
detection mechanisms has become increasingly urgent. This review examines the
evolving adversarial relationship between diffusion model development and the
advancement of detection methods. We present a thorough analysis of
contemporary detection strategies, including frequency and spatial domain
techniques, deep learning-based approaches, and hybrid models that combine
multiple methodologies. We also highlight the importance of diverse datasets
and standardized evaluation metrics in improving detection accuracy and
generalizability. Our discussion explores the practical applications of these
detection systems in copyright protection, misinformation prevention, and
forensic analysis, while also addressing the ethical implications of synthetic
media. Finally, we identify key research gaps and propose future directions to
enhance the robustness and adaptability of detection methods in line with the
rapid advancements of diffusion models. This review emphasizes the necessity of
a comprehensive approach to mitigating the risks associated with AI-generated
content in an increasingly digital world.
</summary>
    <author>
      <name>Linda Laurier</name>
    </author>
    <author>
      <name>Ave Giulietta</name>
    </author>
    <author>
      <name>Arlo Octavia</name>
    </author>
    <author>
      <name>Meade Cleti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18864v1</id>
    <updated>2024-10-24T15:50:35Z</updated>
    <published>2024-10-24T15:50:35Z</published>
    <title>Omics-driven hybrid dynamic modeling of bioprocesses with uncertainty
  estimation</title>
    <summary>  This work presents an omics-driven modeling pipeline that integrates
machine-learning tools to facilitate the dynamic modeling of multiscale
biological systems. Random forests and permutation feature importance are
proposed to mine omics datasets, guiding feature selection and dimensionality
reduction for dynamic modeling. Continuous and differentiable machine-learning
functions can be trained to link the reduced omics feature set to key
components of the dynamic model, resulting in a hybrid model. As proof of
concept, we apply this framework to a high-dimensional proteomics dataset of
$\textit{Saccharomyces cerevisiae}$. After identifying key intracellular
proteins that correlate with cell growth, targeted dynamic experiments are
designed, and key model parameters are captured as functions of the selected
proteins using Gaussian processes. This approach captures the dynamic behavior
of yeast strains under varying proteome profiles while estimating the
uncertainty in the hybrid model's predictions. The outlined modeling framework
is adaptable to other scenarios, such as integrating additional layers of omics
data for more advanced multiscale biological systems, or employing alternative
machine-learning methods to handle larger datasets. Overall, this study
outlines a strategy for leveraging omics data to inform multiscale dynamic
modeling in systems biology and bioprocess engineering.
</summary>
    <author>
      <name>Sebastián Espinel-Ríos</name>
    </author>
    <author>
      <name>José Montaño López</name>
    </author>
    <author>
      <name>José L. Avalos</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18862v1</id>
    <updated>2024-10-24T15:48:34Z</updated>
    <published>2024-10-24T15:48:34Z</published>
    <title>FedSPD: A Soft-clustering Approach for Personalized Decentralized
  Federated Learning</title>
    <summary>  Federated learning has recently gained popularity as a framework for
distributed clients to collaboratively train a machine learning model using
local data. While traditional federated learning relies on a central server for
model aggregation, recent advancements adopt a decentralized framework,
enabling direct model exchange between clients and eliminating the single point
of failure. However, existing decentralized frameworks often assume all clients
train a shared model. Personalizing each client's model can enhance
performance, especially with heterogeneous client data distributions. We
propose FedSPD, an efficient personalized federated learning algorithm for the
decentralized setting, and show that it learns accurate models even in
low-connectivity networks. To provide theoretical guarantees on convergence, we
introduce a clustering-based framework that enables consensus on models for
distinct data clusters while personalizing to unique mixtures of these clusters
at different clients. This flexibility, allowing selective model updates based
on data distribution, substantially reduces communication costs compared to
prior work on personalized federated learning in decentralized settings.
Experimental results on real-world datasets show that FedSPD outperforms
multiple decentralized variants of personalized federated learning algorithms,
especially in scenarios with low-connectivity networks.
</summary>
    <author>
      <name>I-Cheng Lin</name>
    </author>
    <author>
      <name>Osman Yagan</name>
    </author>
    <author>
      <name>Carlee Joe-Wong</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18861v1</id>
    <updated>2024-10-24T15:44:34Z</updated>
    <published>2024-10-24T15:44:34Z</published>
    <title>Provably Robust Watermarks for Open-Source Language Models</title>
    <summary>  The recent explosion of high-quality language models has necessitated new
methods for identifying AI-generated text. Watermarking is a leading solution
and could prove to be an essential tool in the age of generative AI. Existing
approaches embed watermarks at inference and crucially rely on the large
language model (LLM) specification and parameters being secret, which makes
them inapplicable to the open-source setting. In this work, we introduce the
first watermarking scheme for open-source LLMs. Our scheme works by modifying
the parameters of the model, but the watermark can be detected from just the
outputs of the model. Perhaps surprisingly, we prove that our watermarks are
unremovable under certain assumptions about the adversary's knowledge. To
demonstrate the behavior of our construction under concrete parameter
instantiations, we present experimental results with OPT-6.7B and OPT-1.3B. We
demonstrate robustness to both token substitution and perturbation of the model
parameters. We find that the stronger of these attacks, the model-perturbation
attack, requires deteriorating the quality score to 0 out of 100 in order to
bring the detection rate down to 50%.
</summary>
    <author>
      <name>Miranda Christ</name>
    </author>
    <author>
      <name>Sam Gunn</name>
    </author>
    <author>
      <name>Tal Malkin</name>
    </author>
    <author>
      <name>Mariana Raykova</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18860v1</id>
    <updated>2024-10-24T15:44:33Z</updated>
    <published>2024-10-24T15:44:33Z</published>
    <title>DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate
  Hallucinations</title>
    <summary>  Large Language Models (LLMs) often hallucinate, producing unfaithful or
factually incorrect outputs by misrepresenting the provided context or
incorrectly recalling internal knowledge. Recent studies have identified
specific attention heads within the Transformer architecture, known as
retrieval heads, responsible for extracting relevant contextual information. We
hypothesise that masking these retrieval heads can induce hallucinations and
that contrasting the outputs of the base LLM and the masked LLM can reduce
hallucinations. To this end, we propose Decoding by Contrasting Retrieval Heads
(DeCoRe), a novel training-free decoding strategy that amplifies information
found in the context and model parameters. DeCoRe mitigates potentially
hallucinated responses by dynamically contrasting the outputs of the base LLM
and the masked LLM, using conditional entropy as a guide. Our extensive
experiments confirm that DeCoRe significantly improves performance on tasks
requiring high contextual faithfulness, such as summarisation (XSum by 18.6%),
instruction following (MemoTrap by 10.9%), and open-book question answering
(NQ-Open by 2.4% and NQ-Swap by 5.5%).
</summary>
    <author>
      <name>Aryo Pradipta Gema</name>
    </author>
    <author>
      <name>Chen Jin</name>
    </author>
    <author>
      <name>Ahmed Abdulaal</name>
    </author>
    <author>
      <name>Tom Diethe</name>
    </author>
    <author>
      <name>Philip Teare</name>
    </author>
    <author>
      <name>Beatrice Alex</name>
    </author>
    <author>
      <name>Pasquale Minervini</name>
    </author>
    <author>
      <name>Amrutha Saseendran</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18858v1</id>
    <updated>2024-10-24T15:44:03Z</updated>
    <published>2024-10-24T15:44:03Z</published>
    <title>Bilinear Sequence Regression: A Model for Learning from Long Sequences
  of High-dimensional Tokens</title>
    <summary>  Current progress in artificial intelligence is centered around so-called
large language models that consist of neural networks processing long sequences
of high-dimensional vectors called tokens. Statistical physics provides
powerful tools to study the functioning of learning with neural networks and
has played a recognized role in the development of modern machine learning. The
statistical physics approach relies on simplified and analytically tractable
models of data. However, simple tractable models for long sequences of
high-dimensional tokens are largely underexplored. Inspired by the crucial role
models such as the single-layer teacher-student perceptron (aka generalized
linear regression) played in the theory of fully connected neural networks, in
this paper, we introduce and study the bilinear sequence regression (BSR) as
one of the most basic models for sequences of tokens. We note that modern
architectures naturally subsume the BSR model due to the skip connections.
Building on recent methodological progress, we compute the Bayes-optimal
generalization error for the model in the limit of long sequences of
high-dimensional tokens, and provide a message-passing algorithm that matches
this performance. We quantify the improvement that optimal learning brings with
respect to vectorizing the sequence of tokens and learning via simple linear
regression. We also unveil surprising properties of the gradient descent
algorithms in the BSR model.
</summary>
    <author>
      <name>Vittorio Erba</name>
    </author>
    <author>
      <name>Emanuele Troiani</name>
    </author>
    <author>
      <name>Luca Biggio</name>
    </author>
    <author>
      <name>Antoine Maillard</name>
    </author>
    <author>
      <name>Lenka Zdeborová</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18858v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18858v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18857v1</id>
    <updated>2024-10-24T15:42:25Z</updated>
    <published>2024-10-24T15:42:25Z</published>
    <title>Probabilistic Language-Image Pre-Training</title>
    <summary>  Vision-language models (VLMs) embed aligned image-text pairs into a joint
space but often rely on deterministic embeddings, assuming a one-to-one
correspondence between images and texts. This oversimplifies real-world
relationships, which are inherently many-to-many, with multiple captions
describing a single image and vice versa. We introduce Probabilistic
Language-Image Pre-training (ProLIP), the first probabilistic VLM pre-trained
on a billion-scale image-text dataset using only probabilistic objectives,
achieving a strong zero-shot capability (e.g., 74.6% ImageNet zero-shot
accuracy with ViT-B/16). ProLIP efficiently estimates uncertainty by an
"uncertainty token" without extra parameters. We also introduce a novel
inclusion loss that enforces distributional inclusion relationships between
image-text pairs and between original and masked inputs. Experiments
demonstrate that, by leveraging uncertainty estimates, ProLIP benefits
downstream tasks and aligns with intuitive notions of uncertainty, e.g.,
shorter texts being more uncertain and more general inputs including specific
ones. Utilizing text uncertainties, we further improve ImageNet accuracy from
74.6% to 75.8% (under a few-shot setting), supporting the practical advantages
of our probabilistic approach. The code is available at
https://github.com/naver-ai/prolip
</summary>
    <author>
      <name>Sanghyuk Chun</name>
    </author>
    <author>
      <name>Wonjae Kim</name>
    </author>
    <author>
      <name>Song Park</name>
    </author>
    <author>
      <name>Sangdoo Yun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code: https://github.com/naver-ai/prolip; 23 pages, 5.7 MB</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18857v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18857v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18856v1</id>
    <updated>2024-10-24T15:41:56Z</updated>
    <published>2024-10-24T15:41:56Z</published>
    <title>Demystifying Large Language Models for Medicine: A Primer</title>
    <summary>  Large language models (LLMs) represent a transformative class of AI tools
capable of revolutionizing various aspects of healthcare by generating
human-like responses across diverse contexts and adapting to novel tasks
following human instructions. Their potential application spans a broad range
of medical tasks, such as clinical documentation, matching patients to clinical
trials, and answering medical questions. In this primer paper, we propose an
actionable guideline to help healthcare professionals more efficiently utilize
LLMs in their work, along with a set of best practices. This approach consists
of several main phases, including formulating the task, choosing LLMs, prompt
engineering, fine-tuning, and deployment. We start with the discussion of
critical considerations in identifying healthcare tasks that align with the
core capabilities of LLMs and selecting models based on the selected task and
data, performance requirements, and model interface. We then review the
strategies, such as prompt engineering and fine-tuning, to adapt standard LLMs
to specialized medical tasks. Deployment considerations, including regulatory
compliance, ethical guidelines, and continuous monitoring for fairness and
bias, are also discussed. By providing a structured step-by-step methodology,
this tutorial aims to equip healthcare professionals with the tools necessary
to effectively integrate LLMs into clinical practice, ensuring that these
powerful technologies are applied in a safe, reliable, and impactful manner.
</summary>
    <author>
      <name>Qiao Jin</name>
    </author>
    <author>
      <name>Nicholas Wan</name>
    </author>
    <author>
      <name>Robert Leaman</name>
    </author>
    <author>
      <name>Shubo Tian</name>
    </author>
    <author>
      <name>Zhizheng Wang</name>
    </author>
    <author>
      <name>Yifan Yang</name>
    </author>
    <author>
      <name>Zifeng Wang</name>
    </author>
    <author>
      <name>Guangzhi Xiong</name>
    </author>
    <author>
      <name>Po-Ting Lai</name>
    </author>
    <author>
      <name>Qingqing Zhu</name>
    </author>
    <author>
      <name>Benjamin Hou</name>
    </author>
    <author>
      <name>Maame Sarfo-Gyamfi</name>
    </author>
    <author>
      <name>Gongbo Zhang</name>
    </author>
    <author>
      <name>Aidan Gilson</name>
    </author>
    <author>
      <name>Balu Bhasuran</name>
    </author>
    <author>
      <name>Zhe He</name>
    </author>
    <author>
      <name>Aidong Zhang</name>
    </author>
    <author>
      <name>Jimeng Sun</name>
    </author>
    <author>
      <name>Chunhua Weng</name>
    </author>
    <author>
      <name>Ronald M. Summers</name>
    </author>
    <author>
      <name>Qingyu Chen</name>
    </author>
    <author>
      <name>Yifan Peng</name>
    </author>
    <author>
      <name>Zhiyong Lu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18852v1</id>
    <updated>2024-10-24T15:35:08Z</updated>
    <published>2024-10-24T15:35:08Z</published>
    <title>DL-Polycube: Deep learning enhanced polycube method for high-quality
  hexahedral mesh generation and volumetric spline construction</title>
    <summary>  In this paper, we present a novel algorithm that integrates deep learning
with the polycube method (DL-Polycube) to generate high-quality hexahedral
(hex) meshes, which are then used to construct volumetric splines for
isogeometric analysis. Our DL-Polycube algorithm begins by establishing a
connection between surface triangular meshes and polycube structures. We employ
deep neural network to classify surface triangular meshes into their
corresponding polycube structures. Following this, we combine the acquired
polycube structural information with unsupervised learning to perform surface
segmentation of triangular meshes. This step addresses the issue of
segmentation not corresponding to a polycube while reducing manual
intervention. Quality hex meshes are then generated from the polycube
structures, with employing octree subdivision, parametric mapping and quality
improvement techniques. The incorporation of deep learning for creating
polycube structures, combined with unsupervised learning for segmentation of
surface triangular meshes, substantially accelerates hex mesh generation.
Finally, truncated hierarchical B-splines are constructed on the generated hex
meshes. We extract trivariate B\'ezier elements from these splines and apply
them directly in isogeometric analysis. We offer several examples to
demonstrate the robustness of our DL-Polycube algorithm.
</summary>
    <author>
      <name>Yuxuan Yu</name>
    </author>
    <author>
      <name>Yuzhuo Fang</name>
    </author>
    <author>
      <name>Hua Tong</name>
    </author>
    <author>
      <name>Yongjie Jessica Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18852v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18852v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18851v1</id>
    <updated>2024-10-24T15:33:34Z</updated>
    <published>2024-10-24T15:33:34Z</published>
    <title>Intention Is All You Need</title>
    <summary>  Among the many narratives of the transformative power of Generative AI is one
that sees in the world a latent nation of programmers who need to wield nothing
but intentions and natural language to render their ideas in software. In this
paper, this outlook is problematised in two ways. First, it is observed that
generative AI is not a neutral vehicle of intention. Multiple recent studies
paint a picture of the "mechanised convergence" phenomenon, namely, that
generative AI has a homogenising effect on intention. Second, it is observed
that the formation of intention itself is immensely challenging. Constraints,
materiality, and resistance can offer paths to design metaphors for intentional
tools. Finally, existentialist approaches to intention are discussed and
possible implications for programming are proposed in the form of a
speculative, illustrative set of intentional programming practices.
</summary>
    <author>
      <name>Advait Sarkar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 35th Annual Conference of the Psychology of
  Programming Interest Group (PPIG 2024)</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18850v1</id>
    <updated>2024-10-24T15:32:52Z</updated>
    <published>2024-10-24T15:32:52Z</published>
    <title>We Augmented Whisper With kNN and You Won't Believe What Came Next</title>
    <summary>  Speech recognition performance varies by language, domain, and speaker
characteristics such as accent, and fine-tuning a model on any of these
categories may lead to catastrophic forgetting. $k$ nearest neighbor search
($k$NN), first proposed for neural sequence decoders for natural language
generation (NLG) and machine translation (MT), is a non-parametric method that
can instead adapt by building an external datastore that can then be searched
during inference time, without training the underlying model. We show that
Whisper, a transformer end-to-end speech model, benefits from $k$NN. We
investigate the differences between the speech and text setups. We discuss
implications for speaker adaptation, and analyze improvements by gender,
accent, and age.
</summary>
    <author>
      <name>Maya K. Nachesa</name>
    </author>
    <author>
      <name>Vlad Niculae</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages incl. appendix, 2 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18845v1</id>
    <updated>2024-10-24T15:26:34Z</updated>
    <published>2024-10-24T15:26:34Z</published>
    <title>Expanding AI Awareness Through Everyday Interactions with AI: A
  Reflective Journal Study</title>
    <summary>  As the application of AI continues to expand, students in technology programs
are poised to be both producers and users of the technologies. They are also
positioned to engage with AI applications within and outside the classroom.
While focusing on the curriculum when examining students' AI knowledge is
common, extending this connection to students' everyday interactions with AI
provides a more complete picture of their learning. In this paper, we explore
student's awareness and engagement with AI in the context of school and their
daily lives. Over six weeks, 22 undergraduate students participated in a
reflective journal study and submitted a weekly journal entry about their
interactions with AI. The participants were recruited from a technology and
society course that focuses on the implications of technology on people,
communities, and processes. In their weekly journal entries, participants
reflected on interactions with AI on campus (coursework, advertises campus
events, or seminars) and beyond (social media, news, or conversations with
friends and family). The journal prompts were designed to help them think
through what they had read, watched, or been told and reflect on the
development of their own perspectives, knowledge, and literacy on the topic.
Overall, students described nine categories of interactions: coursework, news
and current events, using software and applications, university events, social
media related to their work, personal discussions with friends and family,
interacting with content, and gaming. Students reported that completing the
diaries allowed them time for reflection and made them more aware of the
presence of AI in their daily lives and of its potential benefits and
drawbacks. This research contributes to the ongoing work on AI awareness and
literacy by bringing in perspectives from beyond a formal educational context.
</summary>
    <author>
      <name>Ashish Hingle</name>
    </author>
    <author>
      <name>Aditya Johri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted and presented at the Frontiers in Education 2024 (FIE2024)</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18844v1</id>
    <updated>2024-10-24T15:26:14Z</updated>
    <published>2024-10-24T15:26:14Z</published>
    <title>Learning to Explore with Lagrangians for Bandits under Unknown Linear
  Constraints</title>
    <summary>  Pure exploration in bandits models multiple real-world problems, such as
tuning hyper-parameters or conducting user studies, where different safety,
resource, and fairness constraints on the decision space naturally appear. We
study these problems as pure exploration in multi-armed bandits with unknown
linear constraints, where the aim is to identify an $r$$\textit{-good feasible
policy}$. First, we propose a Lagrangian relaxation of the sample complexity
lower bound for pure exploration under constraints. We show how this lower
bound evolves with the sequential estimation of constraints. Second, we
leverage the Lagrangian lower bound and the properties of convex optimisation
to propose two computationally efficient extensions of Track-and-Stop and
Gamified Explorer, namely LATS and LAGEX. To this end, we propose a
constraint-adaptive stopping rule, and while tracking the lower bound, use
pessimistic estimate of the feasible set at each step. We show that these
algorithms achieve asymptotically optimal sample complexity upper bounds up to
constraint-dependent constants. Finally, we conduct numerical experiments with
different reward distributions and constraints that validate efficient
performance of LAGEX and LATS with respect to baselines.
</summary>
    <author>
      <name>Udvas Das</name>
    </author>
    <author>
      <name>Debabrota Basu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18844v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18844v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18841v1</id>
    <updated>2024-10-24T15:25:56Z</updated>
    <published>2024-10-24T15:25:56Z</published>
    <title>From Efficiency to Equity: Measuring Fairness in Preference Learning</title>
    <summary>  As AI systems, particularly generative models, increasingly influence
decision-making, ensuring that they are able to fairly represent diverse human
preferences becomes crucial. This paper introduces a novel framework for
evaluating epistemic fairness in preference learning models inspired by
economic theories of inequality and Rawlsian justice. We propose metrics
adapted from the Gini Coefficient, Atkinson Index, and Kuznets Ratio to
quantify fairness in these models. We validate our approach using two datasets:
a custom visual preference dataset (AI-EDI-Space) and the Jester Jokes dataset.
Our analysis reveals variations in model performance across users, highlighting
potential epistemic injustices. We explore pre-processing and in-processing
techniques to mitigate these inequalities, demonstrating a complex relationship
between model efficiency and fairness. This work contributes to AI ethics by
providing a framework for evaluating and improving epistemic fairness in
preference learning models, offering insights for developing more inclusive AI
systems in contexts where diverse human preferences are crucial.
</summary>
    <author>
      <name>Shreeyash Gowaikar</name>
    </author>
    <author>
      <name>Hugo Berard</name>
    </author>
    <author>
      <name>Rashid Mushkani</name>
    </author>
    <author>
      <name>Shin Koseki</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18837v1</id>
    <updated>2024-10-24T15:22:53Z</updated>
    <published>2024-10-24T15:22:53Z</published>
    <title>High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong
  Generalization and Scaling Laws</title>
    <summary>  A growing number of machine learning scenarios rely on knowledge distillation
where one uses the output of a surrogate model as labels to supervise the
training of a target model. In this work, we provide a sharp characterization
of this process for ridgeless, high-dimensional regression, under two settings:
(i) model shift, where the surrogate model is arbitrary, and (ii) distribution
shift, where the surrogate model is the solution of empirical risk minimization
with out-of-distribution data. In both cases, we characterize the precise risk
of the target model through non-asymptotic bounds in terms of sample size and
data distribution under mild conditions. As a consequence, we identify the form
of the optimal surrogate model, which reveals the benefits and limitations of
discarding weak features in a data-dependent fashion. In the context of
weak-to-strong (W2S) generalization, this has the interpretation that (i) W2S
training, with the surrogate as the weak model, can provably outperform
training with strong labels under the same data budget, but (ii) it is unable
to improve the data scaling law. We validate our results on numerical
experiments both on ridgeless regression and on neural network architectures.
</summary>
    <author>
      <name>M. Emrullah Ildiz</name>
    </author>
    <author>
      <name>Halil Alperen Gozeten</name>
    </author>
    <author>
      <name>Ege Onur Taga</name>
    </author>
    <author>
      <name>Marco Mondelli</name>
    </author>
    <author>
      <name>Samet Oymak</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18837v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18837v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18836v1</id>
    <updated>2024-10-24T15:20:54Z</updated>
    <published>2024-10-24T15:20:54Z</published>
    <title>From English-Centric to Effective Bilingual: LLMs with Custom Tokenizers
  for Underrepresented Languages</title>
    <summary>  In this paper, we propose a model-agnostic cost-effective approach to
developing bilingual base large language models (LLMs) to support English and
any target language. The method includes vocabulary expansion, initialization
of new embeddings, model training and evaluation. We performed our experiments
with three languages, each using a non-Latin script - Ukrainian, Arabic, and
Georgian.
  Our approach demonstrates improved language performance while reducing
computational costs. It mitigates the disproportionate penalization of
underrepresented languages, promoting fairness and minimizing adverse phenomena
such as code-switching and broken grammar. Additionally, we introduce new
metrics to evaluate language quality, revealing that vocabulary size
significantly impacts the quality of generated text.
</summary>
    <author>
      <name>Artur Kiulian</name>
    </author>
    <author>
      <name>Anton Polishko</name>
    </author>
    <author>
      <name>Mykola Khandoga</name>
    </author>
    <author>
      <name>Yevhen Kostiuk</name>
    </author>
    <author>
      <name>Guillermo Gabrielli</name>
    </author>
    <author>
      <name>Łukasz Gagała</name>
    </author>
    <author>
      <name>Fadi Zaraket</name>
    </author>
    <author>
      <name>Qusai Abu Obaida</name>
    </author>
    <author>
      <name>Hrishikesh Garud</name>
    </author>
    <author>
      <name>Wendy Wing Yee Mak</name>
    </author>
    <author>
      <name>Dmytro Chaplynskyi</name>
    </author>
    <author>
      <name>Selma Belhadj Amor</name>
    </author>
    <author>
      <name>Grigol Peradze</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18836v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18836v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18835v1</id>
    <updated>2024-10-24T15:20:16Z</updated>
    <published>2024-10-24T15:20:16Z</published>
    <title>Diffusion for Multi-Embodiment Grasping</title>
    <summary>  Grasping is a fundamental skill in robotics with diverse applications across
medical, industrial, and domestic domains. However, current approaches for
predicting valid grasps are often tailored to specific grippers, limiting their
applicability when gripper designs change. To address this limitation, we
explore the transfer of grasping strategies between various gripper designs,
enabling the use of data from diverse sources. In this work, we present an
approach based on equivariant diffusion that facilitates gripper-agnostic
encoding of scenes containing graspable objects and gripper-aware decoding of
grasp poses by integrating gripper geometry into the model. We also develop a
dataset generation framework that produces cluttered scenes with variable-sized
object heaps, improving the training of grasp synthesis methods. Experimental
evaluation on diverse object datasets demonstrates the generalizability of our
approach across gripper architectures, ranging from simple parallel-jaw
grippers to humanoid hands, outperforming both single-gripper and multi-gripper
state-of-the-art methods.
</summary>
    <author>
      <name>Roman Freiberg</name>
    </author>
    <author>
      <name>Alexander Qualmann</name>
    </author>
    <author>
      <name>Ngo Anh Vien</name>
    </author>
    <author>
      <name>Gerhard Neumann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18835v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18835v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18834v1</id>
    <updated>2024-10-24T15:19:59Z</updated>
    <published>2024-10-24T15:19:59Z</published>
    <title>Highly efficient non-rigid registration in k-space with application to
  cardiac Magnetic Resonance Imaging</title>
    <summary>  In Magnetic Resonance Imaging (MRI), high temporal-resolved motion can be
useful for image acquisition and reconstruction, MR-guided radiotherapy,
dynamic contrast-enhancement, flow and perfusion imaging, and functional
assessment of motion patterns in cardiovascular, abdominal, peristaltic, fetal,
or musculoskeletal imaging. Conventionally, these motion estimates are derived
through image-based registration, a particularly challenging task for complex
motion patterns and high dynamic resolution. The accelerated scans in such
applications result in imaging artifacts that compromise the motion estimation.
In this work, we propose a novel self-supervised deep learning-based framework,
dubbed the Local-All Pass Attention Network (LAPANet), for non-rigid motion
estimation directly from the acquired accelerated Fourier space, i.e. k-space.
The proposed approach models non-rigid motion as the cumulative sum of local
translational displacements, following the Local All-Pass (LAP) registration
technique. LAPANet was evaluated on cardiac motion estimation across various
sampling trajectories and acceleration rates. Our results demonstrate superior
accuracy compared to prior conventional and deep learning-based registration
methods, accommodating as few as 2 lines/frame in a Cartesian trajectory and 3
spokes/frame in a non-Cartesian trajectory. The achieved high temporal
resolution (less than 5 ms) for non-rigid motion opens new avenues for motion
detection, tracking and correction in dynamic and real-time MRI applications.
</summary>
    <author>
      <name>Aya Ghoul</name>
    </author>
    <author>
      <name>Kerstin Hammernik</name>
    </author>
    <author>
      <name>Andreas Lingg</name>
    </author>
    <author>
      <name>Patrick Krumm</name>
    </author>
    <author>
      <name>Daniel Rueckert</name>
    </author>
    <author>
      <name>Sergios Gatidis</name>
    </author>
    <author>
      <name>Thomas Küstner</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18834v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18834v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18832v1</id>
    <updated>2024-10-24T15:19:48Z</updated>
    <published>2024-10-24T15:19:48Z</published>
    <title>MazeNet: An Accurate, Fast, and Scalable Deep Learning Solution for
  Steiner Minimum Trees</title>
    <summary>  The Obstacle Avoiding Rectilinear Steiner Minimum Tree (OARSMT) problem,
which seeks the shortest interconnection of a given number of terminals in a
rectilinear plane while avoiding obstacles, is a critical task in integrated
circuit design, network optimization, and robot path planning. Since OARSMT is
NP-hard, exact algorithms scale poorly with the number of terminals, leading
practical solvers to sacrifice accuracy for large problems. We propose MazeNet,
a deep learning-based method that learns to solve the OARSMT from data. MazeNet
reframes OARSMT as a maze-solving task that can be addressed with a recurrent
convolutional neural network (RCNN). A key hallmark of MazeNet is its
scalability: we only need to train the RCNN blocks on mazes with a small number
of terminals; larger mazes can be solved by replicating the same pre-trained
blocks to create a larger network. Across a wide range of experiments, MazeNet
achieves perfect OARSMT-solving accuracy, significantly reduces runtime
compared to classical exact algorithms, and can handle more terminals than
state-of-the-art approximate algorithms.
</summary>
    <author>
      <name>Gabriel Díaz Ramos</name>
    </author>
    <author>
      <name>Toros Arikan</name>
    </author>
    <author>
      <name>Richard G. Baraniuk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 15 figures. Submitted to ICLR 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18830v1</id>
    <updated>2024-10-24T15:18:51Z</updated>
    <published>2024-10-24T15:18:51Z</published>
    <title>Multi-Scale Diffusion: Enhancing Spatial Layout in High-Resolution
  Panoramic Image Generation</title>
    <summary>  Diffusion models have recently gained recognition for generating diverse and
high-quality content, especially in the domain of image synthesis. These models
excel not only in creating fixed-size images but also in producing panoramic
images. However, existing methods often struggle with spatial layout
consistency when producing high-resolution panoramas, due to the lack of
guidance of the global image layout. In this paper, we introduce the
Multi-Scale Diffusion (MSD) framework, a plug-and-play module that extends the
existing panoramic image generation framework to multiple resolution levels. By
utilizing gradient descent techniques, our method effectively incorporates
structural information from low-resolution images into high-resolution outputs.
A comprehensive evaluation of the proposed method was conducted, comparing it
with the prior works in qualitative and quantitative dimensions. The evaluation
results demonstrate that our method significantly outperforms others in
generating coherent high-resolution panoramas.
</summary>
    <author>
      <name>Xiaoyu Zhang</name>
    </author>
    <author>
      <name>Teng Zhou</name>
    </author>
    <author>
      <name>Xinlong Zhang</name>
    </author>
    <author>
      <name>Jia Wei</name>
    </author>
    <author>
      <name>Yongchuan Tang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18825v1</id>
    <updated>2024-10-24T15:17:09Z</updated>
    <published>2024-10-24T15:17:09Z</published>
    <title>A generic approach for reactive stateful mitigation of application
  failures in distributed robotics systems deployed with Kubernetes</title>
    <summary>  Offloading computationally expensive algorithms to the edge or even cloud
offers an attractive option to tackle limitations regarding on-board
computational and energy resources of robotic systems. In cloud-native
applications deployed with the container management system Kubernetes (K8s),
one key problem is ensuring resilience against various types of failures.
However, complex robotic systems interacting with the physical world pose a
very specific set of challenges and requirements that are not yet covered by
failure mitigation approaches from the cloud-native domain. In this paper, we
therefore propose a novel approach for robotic system monitoring and stateful,
reactive failure mitigation for distributed robotic systems deployed using
Kubernetes (K8s) and the Robot Operating System (ROS2). By employing the
generic substrate of Behaviour Trees, our approach can be applied to any
robotic workload and supports arbitrarily complex monitoring and failure
mitigation strategies. We demonstrate the effectiveness and
application-agnosticism of our approach on two example applications, namely
Autonomous Mobile Robot (AMR) navigation and robotic manipulation in a
simulated environment.
</summary>
    <author>
      <name>Florian Mirus</name>
    </author>
    <author>
      <name>Frederik Pasch</name>
    </author>
    <author>
      <name>Nikhil Singhal</name>
    </author>
    <author>
      <name>Kay-Ulrich Scholl</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18825v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18825v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18824v1</id>
    <updated>2024-10-24T15:15:42Z</updated>
    <published>2024-10-24T15:15:42Z</published>
    <title>PSY: Posterior Sampling Based Privacy Enhancer in Large Language Models</title>
    <summary>  Privacy vulnerabilities in LLMs, such as leakage from memorization, have been
constantly identified, and various mitigation proposals have been proposed.
LoRA is usually used in fine-tuning LLMs and a good entry point to insert
privacy-enhancing modules. In this ongoing research, we introduce PSY, a
Posterior Sampling based PrivacY enhancer that can be used in LoRA. We propose
a simple yet effective realization of PSY using posterior sampling, which
effectively prevents privacy leakage from intermediate information and, in
turn, preserves the privacy of data owners. We evaluate LoRA extended with PSY
against state-of-the-art membership inference and data extraction attacks. The
experiments are executed on three different LLM architectures fine-tuned on
three datasets with LoRA. In contrast to the commonly used differential privacy
method, we find that our proposed modification consistently reduces the attack
success rate. Meanwhile, our method has almost no negative impact on model
fine-tuning or final performance. Most importantly, PSY reveals a promising
path toward privacy enhancement with latent space extensions.
</summary>
    <author>
      <name>Yulian Sun</name>
    </author>
    <author>
      <name>Li Duan</name>
    </author>
    <author>
      <name>Yong Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18823v1</id>
    <updated>2024-10-24T15:15:01Z</updated>
    <published>2024-10-24T15:15:01Z</published>
    <title>Towards Visual Text Design Transfer Across Languages</title>
    <summary>  Visual text design plays a critical role in conveying themes, emotions, and
atmospheres in multimodal formats such as film posters and album covers.
Translating these visual and textual elements across languages extends the
concept of translation beyond mere text, requiring the adaptation of aesthetic
and stylistic features. To address this, we introduce a novel task of
Multimodal Style Translation (MuST-Bench), a benchmark designed to evaluate the
ability of visual text generation models to perform translation across
different writing systems while preserving design intent. Our initial
experiments on MuST-Bench reveal that existing visual text generation models
struggle with the proposed task due to the inadequacy of textual descriptions
in conveying visual design. In response, we introduce SIGIL, a framework for
multimodal style translation that eliminates the need for style descriptions.
SIGIL enhances image generation models through three innovations: glyph latent
for multilingual settings, pretrained VAEs for stable style guidance, and an
OCR model with reinforcement learning feedback for optimizing readable
character generation. SIGIL outperforms existing baselines by achieving
superior style consistency and legibility while maintaining visual fidelity,
setting itself apart from traditional description-based approaches. We release
MuST-Bench publicly for broader use and exploration
https://huggingface.co/datasets/yejinc/MuST-Bench.
</summary>
    <author>
      <name>Yejin Choi</name>
    </author>
    <author>
      <name>Jiwan Chung</name>
    </author>
    <author>
      <name>Sumin Shim</name>
    </author>
    <author>
      <name>Giyeong Oh</name>
    </author>
    <author>
      <name>Youngjae Yu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18823v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18823v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18822v1</id>
    <updated>2024-10-24T15:10:27Z</updated>
    <published>2024-10-24T15:10:27Z</published>
    <title>Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse
  View Synthesis</title>
    <summary>  Novel view synthesis from sparse inputs is a vital yet challenging task in 3D
computer vision. Previous methods explore 3D Gaussian Splatting with neural
priors (e.g. depth priors) as an additional supervision, demonstrating
promising quality and efficiency compared to the NeRF based methods. However,
the neural priors from 2D pretrained models are often noisy and blurry, which
struggle to precisely guide the learning of radiance fields. In this paper, We
propose a novel method for synthesizing novel views from sparse views with
Gaussian Splatting that does not require external prior as supervision. Our key
idea lies in exploring the self-supervisions inherent in the binocular stereo
consistency between each pair of binocular images constructed with
disparity-guided image warping. To this end, we additionally introduce a
Gaussian opacity constraint which regularizes the Gaussian locations and avoids
Gaussian redundancy for improving the robustness and efficiency of inferring 3D
Gaussians from sparse views. Extensive experiments on the LLFF, DTU, and
Blender datasets demonstrate that our method significantly outperforms the
state-of-the-art methods.
</summary>
    <author>
      <name>Liang Han</name>
    </author>
    <author>
      <name>Junsheng Zhou</name>
    </author>
    <author>
      <name>Yu-Shen Liu</name>
    </author>
    <author>
      <name>Zhizhong Han</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by NeurIPS 2024. Project page:
  https://hanl2010.github.io/Binocular3DGS/</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18822v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18822v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18820v1</id>
    <updated>2024-10-24T15:08:38Z</updated>
    <published>2024-10-24T15:08:38Z</published>
    <title>Deterministic $(2/3-\varepsilon)$-Approximation of Matroid Intersection
  using Nearly-Linear Independence-Oracle Queries</title>
    <summary>  In the matroid intersection problem, we are given two matroids $\mathcal{M}_1
= (V, \mathcal{I}_1)$ and $\mathcal{M}_2 = (V, \mathcal{I}_2)$ defined on the
same ground set $V$ of $n$ elements, and the objective is to find a common
independent set $S \in \mathcal{I}_1 \cap \mathcal{I}_2$ of largest possible
cardinality, denoted by $r$. In this paper, we consider a deterministic matroid
intersection algorithm with only a nearly linear number of independence oracle
queries. Our contribution is to present a deterministic
$O(\frac{n}{\varepsilon} + r \log r)$-independence-query
$(2/3-\varepsilon)$-approximation algorithm for any $\varepsilon &gt; 0$. Our idea
is very simple: we apply a recent $\tilde{O}(n
\sqrt{r}/\varepsilon)$-independence-query $(1 - \varepsilon)$-approximation
algorithm of Blikstad [ICALP 2021], but terminate it before completion.
Moreover, we also present a semi-streaming algorithm for $(2/3
-\varepsilon)$-approximation of matroid intersection in $O(1/\varepsilon)$
passes.
</summary>
    <author>
      <name>Tatsuya Terao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18820v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18820v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18819v1</id>
    <updated>2024-10-24T15:08:17Z</updated>
    <published>2024-10-24T15:08:17Z</published>
    <title>From Imitation to Introspection: Probing Self-Consciousness in Language
  Models</title>
    <summary>  Self-consciousness, the introspection of one's existence and thoughts,
represents a high-level cognitive process. As language models advance at an
unprecedented pace, a critical question arises: Are these models becoming
self-conscious? Drawing upon insights from psychological and neural science,
this work presents a practical definition of self-consciousness for language
models and refines ten core concepts. Our work pioneers an investigation into
self-consciousness in language models by, for the first time, leveraging causal
structural games to establish the functional definitions of the ten core
concepts. Based on our definitions, we conduct a comprehensive four-stage
experiment: quantification (evaluation of ten leading models), representation
(visualization of self-consciousness within the models), manipulation
(modification of the models' representation), and acquisition (fine-tuning the
models on core concepts). Our findings indicate that although models are in the
early stages of developing self-consciousness, there is a discernible
representation of certain concepts within their internal mechanisms. However,
these representations of self-consciousness are hard to manipulate positively
at the current stage, yet they can be acquired through targeted fine-tuning.
Our datasets and code are at https://github.com/OpenCausaLab/SelfConsciousness.
</summary>
    <author>
      <name>Sirui Chen</name>
    </author>
    <author>
      <name>Shu Yu</name>
    </author>
    <author>
      <name>Shengjie Zhao</name>
    </author>
    <author>
      <name>Chaochao Lu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18810v1</id>
    <updated>2024-10-24T14:57:46Z</updated>
    <published>2024-10-24T14:57:46Z</published>
    <title>TangibleChannel: An Innovative Data Physicalization System for Visual
  Channel Education</title>
    <summary>  In this paper, we provide an overview of our attempts to harness data
physicalizations as pedagogical tools for enhancing the understanding of visual
channels. We first elaborate the research goals that we have crafted for the
physicalization prototype, shedding light on the key principles that guided our
design choices. Then we detail the materials and datasets we employed for nine
channels on our physicalization prototype. A preliminary pilot study is
followed to validate its effectiveness. In the end, we present our upcoming
research initiatives, including a comparative study for assessing the usability
of the physicalization system. In general, the main purpose of our work is to
stimulate a wider engagement among visualization educators and researchers,
encouraging them to delve into the potentialities of data physicalization as an
innovative addition to contemporary teaching methodologies.
</summary>
    <author>
      <name>Siqi Xie</name>
    </author>
    <author>
      <name>Yu Liu</name>
    </author>
    <author>
      <name>Lingyun Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure, IEEE VIS 2023 Poster</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18809v1</id>
    <updated>2024-10-24T14:57:00Z</updated>
    <published>2024-10-24T14:57:00Z</published>
    <title>Learning Global Object-Centric Representations via Disentangled Slot
  Attention</title>
    <summary>  Humans can discern scene-independent features of objects across various
environments, allowing them to swiftly identify objects amidst changing factors
such as lighting, perspective, size, and position and imagine the complete
images of the same object in diverse settings. Existing object-centric learning
methods only extract scene-dependent object-centric representations, lacking
the ability to identify the same object across scenes as humans. Moreover, some
existing methods discard the individual object generation capabilities to
handle complex scenes. This paper introduces a novel object-centric learning
method to empower AI systems with human-like capabilities to identify objects
across scenes and generate diverse scenes containing specific objects by
learning a set of global object-centric representations. To learn the global
object-centric representations that encapsulate globally invariant attributes
of objects (i.e., the complete appearance and shape), this paper designs a
Disentangled Slot Attention module to convert the scene features into
scene-dependent attributes (such as scale, position and orientation) and
scene-independent representations (i.e., appearance and shape). Experimental
results substantiate the efficacy of the proposed method, demonstrating
remarkable proficiency in global object-centric representation learning, object
identification, scene generation with specific objects and scene decomposition.
</summary>
    <author>
      <name>Tonglin Chen</name>
    </author>
    <author>
      <name>Yinxuan Huang</name>
    </author>
    <author>
      <name>Zhimeng Shen</name>
    </author>
    <author>
      <name>Jinghao Huang</name>
    </author>
    <author>
      <name>Bin Li</name>
    </author>
    <author>
      <name>Xiangyang Xue</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Global Object-Centric Representations, Object Identification,
  Unsupervised Learning, Disentangled Learning</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18808v1</id>
    <updated>2024-10-24T14:55:09Z</updated>
    <published>2024-10-24T14:55:09Z</published>
    <title>Delving into the Reversal Curse: How Far Can Large Language Models
  Generalize?</title>
    <summary>  While large language models (LLMs) showcase unprecedented capabilities, they
also exhibit certain inherent limitations when facing seemingly trivial tasks.
A prime example is the recently debated "reversal curse", which surfaces when
models, having been trained on the fact "A is B", struggle to generalize this
knowledge to infer that "B is A". In this paper, we examine the manifestation
of the reversal curse across various tasks and delve into both the
generalization abilities and the problem-solving mechanisms of LLMs. This
investigation leads to a series of significant insights: (1) LLMs are able to
generalize to "B is A" when both A and B are presented in the context as in the
case of a multiple-choice question. (2) This generalization ability is highly
correlated to the structure of the fact "A is B" in the training documents. For
example, this generalization only applies to biographies structured in "[Name]
is [Description]" but not to "[Description] is [Name]". (3) We propose and
verify the hypothesis that LLMs possess an inherent bias in fact recalling
during knowledge application, which explains and underscores the importance of
the document structure to successful learning. (4) The negative impact of this
bias on the downstream performance of LLMs can hardly be mitigated through
training alone. Based on these intriguing findings, our work not only presents
a novel perspective for interpreting LLMs' generalization abilities from their
intrinsic working mechanism but also provides new insights for the development
of more effective learning methods for LLMs.
</summary>
    <author>
      <name>Zhengkai Lin</name>
    </author>
    <author>
      <name>Zhihang Fu</name>
    </author>
    <author>
      <name>Kai Liu</name>
    </author>
    <author>
      <name>Liang Xie</name>
    </author>
    <author>
      <name>Binbin Lin</name>
    </author>
    <author>
      <name>Wenxiao Wang</name>
    </author>
    <author>
      <name>Deng Cai</name>
    </author>
    <author>
      <name>Yue Wu</name>
    </author>
    <author>
      <name>Jieping Ye</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at NeurIPS 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18806v1</id>
    <updated>2024-10-24T14:54:09Z</updated>
    <published>2024-10-24T14:54:09Z</published>
    <title>A Combinatorial Approach to Neural Emergent Communication</title>
    <summary>  Substantial research on deep learning-based emergent communication uses the
referential game framework, specifically the Lewis signaling game, however we
argue that successful communication in this game typically only need one or two
effective symbols (i.e. message length) because of a sampling pitfall in the
training data. To address this issue, we provide a theoretical analysis and
introduce a combinatorial algorithm SolveMinSym (SMS) to determine the minimum
number of symbols for successful communication min(|M|) in the Lewis signaling
game. We use SMS algorithm to create datasets with different min(|M|) to
empirically show that higher min(|M|) for the training data increases the
number of effective symbols in the emergent language.
</summary>
    <author>
      <name>Zheyuan Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18806v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18806v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18804v1</id>
    <updated>2024-10-24T14:52:38Z</updated>
    <published>2024-10-24T14:52:38Z</published>
    <title>Fast constrained sampling in pre-trained diffusion models</title>
    <summary>  Diffusion models have dominated the field of large, generative image models,
with the prime examples of Stable Diffusion and DALL-E 3 being widely adopted.
These models have been trained to perform text-conditioned generation on vast
numbers of image-caption pairs and as a byproduct, have acquired general
knowledge about natural image statistics. However, when confronted with the
task of constrained sampling, e.g. generating the right half of an image
conditioned on the known left half, applying these models is a delicate and
slow process, with previously proposed algorithms relying on expensive
iterative operations that are usually orders of magnitude slower than
text-based inference. This is counter-intuitive, as image-conditioned
generation should rely less on the difficult-to-learn semantic knowledge that
links captions and imagery, and should instead be achievable by lower-level
correlations among image pixels. In practice, inverse models are trained or
tuned separately for each inverse problem, e.g. by providing parts of images
during training as an additional condition, to allow their application in
realistic settings. However, we argue that this is not necessary and propose an
algorithm for fast-constrained sampling in large pre-trained diffusion models
(Stable Diffusion) that requires no expensive backpropagation operations
through the model and produces results comparable even to the state-of-the-art
\emph{tuned} models. Our method is based on a novel optimization perspective to
sampling under constraints and employs a numerical approximation to the
expensive gradients, previously computed using backpropagation, incurring
significant speed-ups.
</summary>
    <author>
      <name>Alexandros Graikos</name>
    </author>
    <author>
      <name>Nebojsa Jojic</name>
    </author>
    <author>
      <name>Dimitris Samaras</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18804v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18804v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18803v1</id>
    <updated>2024-10-24T14:52:21Z</updated>
    <published>2024-10-24T14:52:21Z</published>
    <title>Language-Agnostic Modeling of Source Reliability on Wikipedia</title>
    <summary>  Over the last few years, content verification through reliable sources has
become a fundamental need to combat disinformation. Here, we present a
language-agnostic model designed to assess the reliability of sources across
multiple language editions of Wikipedia. Utilizing editorial activity data, the
model evaluates source reliability within different articles of varying
controversiality such as Climate Change, COVID-19, History, Media, and Biology
topics. Crafting features that express domain usage across articles, the model
effectively predicts source reliability, achieving an F1 Macro score of
approximately 0.80 for English and other high-resource languages. For
mid-resource languages, we achieve 0.65 while the performance of low-resource
languages varies; in all cases, the time the domain remains present in the
articles (which we dub as permanence) is one of the most predictive features.
We highlight the challenge of maintaining consistent model performance across
languages of varying resource levels and demonstrate that adapting models from
higher-resource languages can improve performance. This work contributes not
only to Wikipedia's efforts in ensuring content verifiability but in ensuring
reliability across diverse user-generated content in various language
communities.
</summary>
    <author>
      <name>Jacopo D'Ignazi</name>
    </author>
    <author>
      <name>Andreas Kaltenbrunner</name>
    </author>
    <author>
      <name>Yelena Mejova</name>
    </author>
    <author>
      <name>Michele Tizzani</name>
    </author>
    <author>
      <name>Kyriaki Kalimeri</name>
    </author>
    <author>
      <name>Mariano Beiró</name>
    </author>
    <author>
      <name>Pablo Aragón</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18803v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18803v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18800v1</id>
    <updated>2024-10-24T14:51:09Z</updated>
    <published>2024-10-24T14:51:09Z</published>
    <title>PointPatchRL -- Masked Reconstruction Improves Reinforcement Learning on
  Point Clouds</title>
    <summary>  Perceiving the environment via cameras is crucial for Reinforcement Learning
(RL) in robotics. While images are a convenient form of representation, they
often complicate extracting important geometric details, especially with
varying geometries or deformable objects. In contrast, point clouds naturally
represent this geometry and easily integrate color and positional data from
multiple camera views. However, while deep learning on point clouds has seen
many recent successes, RL on point clouds is under-researched, with only the
simplest encoder architecture considered in the literature. We introduce
PointPatchRL (PPRL), a method for RL on point clouds that builds on the common
paradigm of dividing point clouds into overlapping patches, tokenizing them,
and processing the tokens with transformers. PPRL provides significant
improvements compared with other point-cloud processing architectures
previously used for RL. We then complement PPRL with masked reconstruction for
representation learning and show that our method outperforms strong model-free
and model-based baselines on image observations in complex manipulation tasks
containing deformable objects and variations in target object geometry. Videos
and code are available at https://alrhub.github.io/pprl-website
</summary>
    <author>
      <name>Balázs Gyenes</name>
    </author>
    <author>
      <name>Nikolai Franke</name>
    </author>
    <author>
      <name>Philipp Becker</name>
    </author>
    <author>
      <name>Gerhard Neumann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 15 figures, accepted for publication at the 8th Conference
  on Robot Learning (CoRL 2024)</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18799v1</id>
    <updated>2024-10-24T14:51:00Z</updated>
    <published>2024-10-24T14:51:00Z</published>
    <title>Arbitrary-arity Tree Automata and QCTL</title>
    <summary>  We introduce a new class of automata (which we coin EU-automata) running on
infininte trees of arbitrary (finite) arity. We develop and study several
algorithms to perform classical operations (union, intersection, complement,
projection, alternation removal) for those automata, and precisely characterise
their complexities. We also develop algorithms for solving membership and
emptiness for the languages of trees accepted by EU-automata.
  We then use EU-automata to obtain several algorithmic and expressiveness
results for the temporal logic QCTL (which extends CTL with quantification over
atomic propositions) and for MSO. On the one hand, we obtain decision
procedures with optimal complexity for QCTL satisfiability and model checking;
on the other hand, we obtain an algorithm for translating any QCTL formula with
k quantifier alternations to formulas with at most one quantifier alternation,
at the expense of a $(k + 1)$-exponential blow-up in the size of the formulas.
Using the same techniques, we prove that any MSO formula can be translated into
a formula with at most four quantifier alternations (and only two
second-order-quantifier alternations), again with a $(k + 1)$-exponential
blow-up in the size of the formula.
</summary>
    <author>
      <name>François Laroussinie</name>
    </author>
    <author>
      <name>Nicolas Markey</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18798v1</id>
    <updated>2024-10-24T14:50:42Z</updated>
    <published>2024-10-24T14:50:42Z</published>
    <title>Distill Visual Chart Reasoning Ability from LLMs to MLLMs</title>
    <summary>  Solving complex chart Q&amp;A tasks requires advanced visual reasoning abilities
in multimodal large language models (MLLMs). Recent studies highlight that
these abilities consist of two main parts: recognizing key information from
visual inputs and conducting reasoning over it. Thus, a promising approach to
enhance MLLMs is to construct relevant training data focusing on the two
aspects. However, collecting and annotating complex charts and questions is
costly and time-consuming, and ensuring the quality of annotated answers
remains a challenge. In this paper, we propose Code-as-Intermediary Translation
(CIT), a cost-effective, efficient and easily scalable data synthesis method
for distilling visual reasoning abilities from LLMs to MLLMs. The code serves
as an intermediary that translates visual chart representations into textual
representations, enabling LLMs to understand cross-modal information.
Specifically, we employ text-based synthesizing techniques to construct
chart-plotting code and produce ReachQA, a dataset containing 3k
reasoning-intensive charts and 20k Q&amp;A pairs to enhance both recognition and
reasoning abilities. Experiments show that when fine-tuned with our data,
models not only perform well on chart-related benchmarks, but also demonstrate
improved multimodal reasoning abilities on general mathematical benchmarks like
MathVista. The code and dataset are publicly available at
https://github.com/hewei2001/ReachQA.
</summary>
    <author>
      <name>Wei He</name>
    </author>
    <author>
      <name>Zhiheng Xi</name>
    </author>
    <author>
      <name>Wanxu Zhao</name>
    </author>
    <author>
      <name>Xiaoran Fan</name>
    </author>
    <author>
      <name>Yiwen Ding</name>
    </author>
    <author>
      <name>Zifei Shan</name>
    </author>
    <author>
      <name>Tao Gui</name>
    </author>
    <author>
      <name>Qi Zhang</name>
    </author>
    <author>
      <name>Xuanjing Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under review. The code and dataset are publicly available at
  https://github.com/hewei2001/ReachQA</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18797v1</id>
    <updated>2024-10-24T14:49:59Z</updated>
    <published>2024-10-24T14:49:59Z</published>
    <title>Learning Geodesics of Geometric Shape Deformations From Images</title>
    <summary>  This paper presents a novel method, named geodesic deformable networks (GDN),
that for the first time enables the learning of geodesic flows of deformation
fields derived from images. In particular, the capability of our proposed GDN
being able to predict geodesics is important for quantifying and comparing
deformable shape presented in images. The geodesic deformations, also known as
optimal transformations that align pairwise images, are often parameterized by
a time sequence of smooth vector fields governed by nonlinear differential
equations. A bountiful literature has been focusing on learning the initial
conditions (e.g., initial velocity fields) based on registration networks.
However, the definition of geodesics central to deformation-based shape
analysis is blind to the networks. To address this problem, we carefully
develop an efficient neural operator to treat the geodesics as unknown mapping
functions learned from the latent deformation spaces. A composition of integral
operators and smooth activation functions is then formulated to effectively
approximate such mappings. In contrast to previous works, our GDN jointly
optimizes a newly defined geodesic loss, which adds additional benefits to
promote the network regularizability and generalizability. We demonstrate the
effectiveness of GDN on both 2D synthetic data and 3D real brain magnetic
resonance imaging (MRI).
</summary>
    <author>
      <name>Nian Wu</name>
    </author>
    <author>
      <name>Miaomiao Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18794v1</id>
    <updated>2024-10-24T14:47:36Z</updated>
    <published>2024-10-24T14:47:36Z</published>
    <title>WARP-LCA: Efficient Convolutional Sparse Coding with Locally Competitive
  Algorithm</title>
    <summary>  The locally competitive algorithm (LCA) can solve sparse coding problems
across a wide range of use cases. Recently, convolution-based LCA approaches
have been shown to be highly effective for enhancing robustness for image
recognition tasks in vision pipelines. To additionally maximize
representational sparsity, LCA with hard-thresholding can be applied. While
this combination often yields very good solutions satisfying an $\ell_0$
sparsity criterion, it comes with significant drawbacks for practical
application: (i) LCA is very inefficient, typically requiring hundreds of
optimization cycles for convergence; (ii) the use of hard-thresholding results
in a non-convex loss function, which might lead to suboptimal minima. To
address these issues, we propose the Locally Competitive Algorithm with State
Warm-up via Predictive Priming (WARP-LCA), which leverages a predictor network
to provide a suitable initial guess of the LCA state based on the current
input. Our approach significantly improves both convergence speed and the
quality of solutions, while maintaining and even enhancing the overall
strengths of LCA. We demonstrate that WARP-LCA converges faster by orders of
magnitude and reaches better minima compared to conventional LCA. Moreover, the
learned representations are more sparse and exhibit superior properties in
terms of reconstruction and denoising quality as well as robustness when
applied in deep recognition pipelines. Furthermore, we apply WARP-LCA to image
denoising tasks, showcasing its robustness and practical effectiveness. Our
findings confirm that the naive use of LCA with hard-thresholding results in
suboptimal minima, whereas initializing LCA with a predictive guess results in
better outcomes. This research advances the field of biologically inspired deep
learning by providing a novel approach to convolutional sparse coding.
</summary>
    <author>
      <name>Geoffrey Kasenbacher</name>
    </author>
    <author>
      <name>Felix Ehret</name>
    </author>
    <author>
      <name>Gerrit Ecke</name>
    </author>
    <author>
      <name>Sebastian Otte</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18793v1</id>
    <updated>2024-10-24T14:47:28Z</updated>
    <published>2024-10-24T14:47:28Z</published>
    <title>Adapting MLOps for Diverse In-Network Intelligence in 6G Era: Challenges
  and Solutions</title>
    <summary>  Seamless integration of artificial intelligence (AI) and machine learning
(ML) techniques with wireless systems is a crucial step for 6G AInization.
However, such integration faces challenges in terms of model functionality and
lifecycle management. ML operations (MLOps) offer a systematic approach to
tackle these challenges. Existing approaches toward implementing MLOps in a
centralized platform often overlook the challenges posed by diverse learning
paradigms and network heterogeneity. This article provides a new approach to
MLOps targeting the intricacies of future wireless networks. Considering unique
aspects of the future radio access network (RAN), we formulate three
operational pipelines, namely reinforcement learning operations (RLOps),
federated learning operations (FedOps), and generative AI operations (GenOps).
These pipelines form the foundation for seamlessly integrating various
learning/inference capabilities into networks. We outline the specific
challenges and proposed solutions for each operation, facilitating large-scale
deployment of AI-Native 6G networks.
</summary>
    <author>
      <name>Peizheng Li</name>
    </author>
    <author>
      <name>Ioannis Mavromatis</name>
    </author>
    <author>
      <name>Tim Farnham</name>
    </author>
    <author>
      <name>Adnan Aijaz</name>
    </author>
    <author>
      <name>Aftab Khan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures. This paper has been submitted to IEEE for
  possible publication</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18792v1</id>
    <updated>2024-10-24T14:47:25Z</updated>
    <published>2024-10-24T14:47:25Z</published>
    <title>An LLM Agent for Automatic Geospatial Data Analysis</title>
    <summary>  Large language models (LLMs) are being used in data science code generation
tasks, but they often struggle with complex sequential tasks, leading to
logical errors. Their application to geospatial data processing is particularly
challenging due to difficulties in incorporating complex data structures and
spatial constraints, effectively utilizing diverse function calls, and the
tendency to hallucinate less-used geospatial libraries. To tackle these
problems, we introduce GeoAgent, a new interactive framework designed to help
LLMs handle geospatial data processing more effectively. GeoAgent pioneers the
integration of a code interpreter, static analysis, and Retrieval-Augmented
Generation (RAG) techniques within a Monte Carlo Tree Search (MCTS) algorithm,
offering a novel approach to geospatial data processing. In addition, we
contribute a new benchmark specifically designed to evaluate the LLM-based
approach in geospatial tasks. This benchmark leverages a variety of Python
libraries and includes both single-turn and multi-turn tasks such as data
acquisition, data analysis, and visualization. By offering a comprehensive
evaluation among diverse geospatial contexts, this benchmark sets a new
standard for developing LLM-based approaches in geospatial data analysis tasks.
Our findings suggest that relying solely on knowledge of LLM is insufficient
for accurate geospatial task programming, which requires coherent multi-step
processes and multiple function calls. Compared to the baseline LLMs, the
proposed GeoAgent has demonstrated superior performance, yielding notable
improvements in function calls and task completion. In addition, these results
offer valuable insights for the future development of LLM agents in automatic
geospatial data analysis task programming.
</summary>
    <author>
      <name>Yuxing Chen</name>
    </author>
    <author>
      <name>Weijie Wang</name>
    </author>
    <author>
      <name>Sylvain Lobry</name>
    </author>
    <author>
      <name>Camille Kurtz</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18792v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18792v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18790v1</id>
    <updated>2024-10-24T14:43:35Z</updated>
    <published>2024-10-24T14:43:35Z</published>
    <title>Large Generative AI Models meet Open Networks for 6G: Integration,
  Platform, and Monetization</title>
    <summary>  Generative artificial intelligence (GAI) has emerged as a pivotal technology
for content generation, reasoning, and decision-making, making it a promising
solution on the 6G stage characterized by openness, connected intelligence, and
service democratization. This article explores strategies for integrating and
monetizing GAI within future open 6G networks, mainly from the perspectives of
mobile network operators (MNOs). We propose a novel API-centric telecoms GAI
marketplace platform, designed to serve as a central hub for deploying,
managing, and monetizing diverse GAI services directly within the network. This
platform underpins a flexible and interoperable ecosystem, enhances service
delivery, and facilitates seamless integration of GAI capabilities across
various network segments, thereby enabling new revenue streams through
customer-centric generative services. Results from experimental evaluation in
an end-to-end Open RAN testbed, show the latency benefits of this platform for
local large language model (LLM) deployment, by comparing token timing for
various generated lengths with cloud-based general-purpose LLMs. Lastly, the
article discusses key considerations for implementing the GAI marketplace
within 6G networks, including monetization strategy, regulatory, management,
and service platform aspects.
</summary>
    <author>
      <name>Peizheng Li</name>
    </author>
    <author>
      <name>Adrián Sánchez-Mompó</name>
    </author>
    <author>
      <name>Tim Farnham</name>
    </author>
    <author>
      <name>Aftab Khan</name>
    </author>
    <author>
      <name>Adnan Aijaz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures. This paper has been submitted to IEEE for
  possible publication</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18790v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18790v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18789v1</id>
    <updated>2024-10-24T14:43:00Z</updated>
    <published>2024-10-24T14:43:00Z</published>
    <title>Single-Shot Phase Diversity Wavefront Sensing in Deep Turbulence via
  Metasurface Optics</title>
    <summary>  Free-space optical communication (FSOC) systems offer high-bandwidth and
secure communication with minimal capital costs. Adaptive optics (AO) are
typically added to these systems to decrease atmospheric channel losses;
however, the performance of traditional AO wavefront sensors degrades in
long-range, deep turbulence conditions. Alternative wavefront sensors using
phase diversity can successfully reconstruct wavefronts in deep turbulence, but
current implementations require bulky setups with high latency. In this work,
we employ a nanostructured birefringent metasurface optic that enables
low-latency phase diversity wavefront sensing in a compact form factor. We
prove the effectiveness of this approach in mid-to-high turbulence (Rytov
numbers from 0.2 to 0.6) through simulation and experimental demonstration. In
both cases an average 16-fold increase in signal from the corrected beam is
obtained. Our approach opens a pathway for compact, robust wavefront sensing
that enhances range and accuracy of FSOC systems.
</summary>
    <author>
      <name>Arturo Martin Jimenez</name>
    </author>
    <author>
      <name>Marc Baltes</name>
    </author>
    <author>
      <name>Jackson Cornelius</name>
    </author>
    <author>
      <name>Neset Akozbek</name>
    </author>
    <author>
      <name>Zachary Coppens</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18789v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18789v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18786v1</id>
    <updated>2024-10-24T14:37:55Z</updated>
    <published>2024-10-24T14:37:55Z</published>
    <title>Applying Neural Monte Carlo Tree Search to Unsignalized
  Multi-intersection Scheduling for Autonomous Vehicles</title>
    <summary>  Dynamic scheduling of access to shared resources by autonomous systems is a
challenging problem, characterized as being NP-hard. The complexity of this
task leads to a combinatorial explosion of possibilities in highly dynamic
systems where arriving requests must be continuously scheduled subject to
strong safety and time constraints. An example of such a system is an
unsignalized intersection, where automated vehicles' access to potential
conflict zones must be dynamically scheduled. In this paper, we apply Neural
Monte Carlo Tree Search (NMCTS) to the challenging task of scheduling platoons
of vehicles crossing unsignalized intersections. Crucially, we introduce a
transformation model that maps successive sequences of potentially conflicting
road-space reservation requests from platoons of vehicles into a series of
board-game-like problems and use NMCTS to search for solutions representing
optimal road-space allocation schedules in the context of past allocations. To
optimize search, we incorporate a prioritized re-sampling method with parallel
NMCTS (PNMCTS) to improve the quality of training data. To optimize training, a
curriculum learning strategy is used to train the agent to schedule
progressively more complex boards culminating in overlapping boards that
represent busy intersections. In a busy single four-way unsignalized
intersection simulation, PNMCTS solved 95\% of unseen scenarios, reducing
crossing time by 43\% in light and 52\% in heavy traffic versus first-in,
first-out control. In a 3x3 multi-intersection network, the proposed method
maintained free-flow in light traffic when all intersections are under control
of PNMCTS and outperformed state-of-the-art RL-based traffic-light controllers
in average travel time by 74.5\% and total throughput by 16\% in heavy traffic.
</summary>
    <author>
      <name>Yucheng Shi</name>
    </author>
    <author>
      <name>Wenlong Wang</name>
    </author>
    <author>
      <name>Xiaowen Tao</name>
    </author>
    <author>
      <name>Ivana Dusparic</name>
    </author>
    <author>
      <name>Vinny Cahill</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18785v1</id>
    <updated>2024-10-24T14:36:48Z</updated>
    <published>2024-10-24T14:36:48Z</published>
    <title>Should We Really Edit Language Models? On the Evaluation of Edited
  Language Models</title>
    <summary>  Model editing has become an increasingly popular alternative for efficiently
updating knowledge within language models. Current methods mainly focus on
reliability, generalization, and locality, with many methods excelling across
these criteria. Some recent works disclose the pitfalls of these editing
methods such as knowledge distortion or conflict. However, the general
abilities of post-edited language models remain unexplored. In this paper, we
perform a comprehensive evaluation on various editing methods and different
language models, and have following findings. (1) Existing editing methods lead
to inevitable performance deterioration on general benchmarks, indicating that
existing editing methods maintain the general abilities of the model within
only a few dozen edits. When the number of edits is slightly large, the
intrinsic knowledge structure of the model is disrupted or even completely
damaged. (2) Instruction-tuned models are more robust to editing, showing less
performance drop on general knowledge after editing. (3) Language model with
large scale is more resistant to editing compared to small model. (4) The
safety of the edited model, is significantly weakened, even for those
safety-aligned models. Our findings indicate that current editing methods are
only suitable for small-scale knowledge updates within language models, which
motivates further research on more practical and reliable editing methods. The
details of code and reproduction can be found in
https://github.com/lqinfdim/EditingEvaluation.
</summary>
    <author>
      <name>Qi Li</name>
    </author>
    <author>
      <name>Xiang Liu</name>
    </author>
    <author>
      <name>Zhenheng Tang</name>
    </author>
    <author>
      <name>Peijie Dong</name>
    </author>
    <author>
      <name>Zeyu Li</name>
    </author>
    <author>
      <name>Xinglin Pan</name>
    </author>
    <author>
      <name>Xiaowen Chu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2024 https://github.com/lqinfdim/EditingEvaluation</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18784v1</id>
    <updated>2024-10-24T14:36:12Z</updated>
    <published>2024-10-24T14:36:12Z</published>
    <title>Denoising diffusion probabilistic models are optimally adaptive to
  unknown low dimensionality</title>
    <summary>  The denoising diffusion probabilistic model (DDPM) has emerged as a
mainstream generative model in generative AI. While sharp convergence
guarantees have been established for the DDPM, the iteration complexity is, in
general, proportional to the ambient data dimension, resulting in overly
conservative theory that fails to explain its practical efficiency. This has
motivated the recent work Li and Yan (2024a) to investigate how the DDPM can
achieve sampling speed-ups through automatic exploitation of intrinsic low
dimensionality of data. We strengthen this prior work by demonstrating, in some
sense, optimal adaptivity to unknown low dimensionality. For a broad class of
data distributions with intrinsic dimension $k$, we prove that the iteration
complexity of the DDPM scales nearly linearly with $k$, which is optimal when
using KL divergence to measure distributional discrepancy. Our theory is
established based on a key observation: the DDPM update rule is equivalent to
running a suitably parameterized SDE upon discretization, where the nonlinear
component of the drift term is intrinsically low-dimensional.
</summary>
    <author>
      <name>Zhihan Huang</name>
    </author>
    <author>
      <name>Yuting Wei</name>
    </author>
    <author>
      <name>Yuxin Chen</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18780v1</id>
    <updated>2024-10-24T14:31:57Z</updated>
    <published>2024-10-24T14:31:57Z</published>
    <title>Variational problems with gradient constraints: $\textit{A priori}$ and
  $\textit{a posteriori}$ error identities</title>
    <summary>  In this paper, on the basis of a (Fenchel) duality theory on the continuous
level, we derive an $\textit{a posteriori}$ error identity for arbitrary
conforming approximations of a primal formulation and a dual formulation of
variational problems involving gradient constraints. In addition, on the basis
of a (Fenchel) duality theory on the discrete level, we derive an $\textit{a
priori}$ error identity that applies to the approximation of the primal
formulation using the Crouzeix-Raviart element and to the approximation of the
dual formulation using the Raviart-Thomas element, and leads to error decay
rates that are optimal with respect to the regularity of a dual solution.
</summary>
    <author>
      <name>Harbir Antil</name>
    </author>
    <author>
      <name>Sören Bartels</name>
    </author>
    <author>
      <name>Alex Kaltenbach</name>
    </author>
    <author>
      <name>Rohit Khandelwal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="49J40, 49M29, 65N30, 65N15, 65N50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18779v1</id>
    <updated>2024-10-24T14:31:52Z</updated>
    <published>2024-10-24T14:31:52Z</published>
    <title>A Little Help Goes a Long Way: Efficient LLM Training by Leveraging
  Small LMs</title>
    <summary>  A primary challenge in large language model (LLM) development is their
onerous pre-training cost. Typically, such pre-training involves optimizing a
self-supervised objective (such as next-token prediction) over a large corpus.
This paper explores a promising paradigm to improve LLM pre-training efficiency
and quality by suitably leveraging a small language model (SLM). In particular,
this paradigm relies on an SLM to both (1) provide soft labels as additional
training supervision, and (2) select a small subset of valuable ("informative"
and "hard") training examples. Put together, this enables an effective transfer
of the SLM's predictive distribution to the LLM, while prioritizing specific
regions of the training data distribution. Empirically, this leads to reduced
LLM training time compared to standard training, while improving the overall
quality. Theoretically, we develop a statistical framework to systematically
study the utility of SLMs in enabling efficient training of high-quality LLMs.
In particular, our framework characterizes how the SLM's seemingly low-quality
supervision can enhance the training of a much more capable LLM. Furthermore,
it also highlights the need for an adaptive utilization of such supervision, by
striking a balance between the bias and variance introduced by the SLM-provided
soft labels. We corroborate our theoretical framework by improving the
pre-training of an LLM with 2.8B parameters by utilizing a smaller LM with 1.5B
parameters on the Pile dataset.
</summary>
    <author>
      <name>Ankit Singh Rawat</name>
    </author>
    <author>
      <name>Veeranjaneyulu Sadhanala</name>
    </author>
    <author>
      <name>Afshin Rostamizadeh</name>
    </author>
    <author>
      <name>Ayan Chakrabarti</name>
    </author>
    <author>
      <name>Wittawat Jitkrittum</name>
    </author>
    <author>
      <name>Vladimir Feinberg</name>
    </author>
    <author>
      <name>Seungyeon Kim</name>
    </author>
    <author>
      <name>Hrayr Harutyunyan</name>
    </author>
    <author>
      <name>Nikunj Saunshi</name>
    </author>
    <author>
      <name>Zachary Nado</name>
    </author>
    <author>
      <name>Rakesh Shivanna</name>
    </author>
    <author>
      <name>Sashank J. Reddi</name>
    </author>
    <author>
      <name>Aditya Krishna Menon</name>
    </author>
    <author>
      <name>Rohan Anil</name>
    </author>
    <author>
      <name>Sanjiv Kumar</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18779v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18779v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18777v1</id>
    <updated>2024-10-24T14:28:53Z</updated>
    <published>2024-10-24T14:28:53Z</published>
    <title>Online path planning for kinematic-constrained UAVs in a dynamic
  environment based on a Differential Evolution algorithm</title>
    <summary>  This research presents an online path planner for Unmanned Aerial Vehicles
(UAVs) that can handle dynamic obstacles and UAV motion constraints, including
maximum curvature and desired orientations. Our proposed planner uses a NURBS
path representation and a Differential Evolution algorithm, incorporating
concepts from the Velocity Obstacle approach in a constraint function. Initial
results show that our approach is feasible and provides a foundation for future
extensions to three-dimensional (3D) environments.
</summary>
    <author>
      <name>Elias J. R. Freitas</name>
    </author>
    <author>
      <name>Miri Weiss Cohen</name>
    </author>
    <author>
      <name>Frederico G. Guimarães</name>
    </author>
    <author>
      <name>Luciano C. A. Pimenta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the 40th Anniversary of the IEEE Conference on Robotics
  and Automation (ICRA@40)</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18777v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18777v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18775v1</id>
    <updated>2024-10-24T14:28:32Z</updated>
    <published>2024-10-24T14:28:32Z</published>
    <title>Robust Watermarking Using Generative Priors Against Image Editing: From
  Benchmarking to Advances</title>
    <summary>  Current image watermarking methods are vulnerable to advanced image editing
techniques enabled by large-scale text-to-image models. These models can
distort embedded watermarks during editing, posing significant challenges to
copyright protection. In this work, we introduce W-Bench, the first
comprehensive benchmark designed to evaluate the robustness of watermarking
methods against a wide range of image editing techniques, including image
regeneration, global editing, local editing, and image-to-video generation.
Through extensive evaluations of eleven representative watermarking methods
against prevalent editing techniques, we demonstrate that most methods fail to
detect watermarks after such edits. To address this limitation, we propose
VINE, a watermarking method that significantly enhances robustness against
various image editing techniques while maintaining high image quality. Our
approach involves two key innovations: (1) we analyze the frequency
characteristics of image editing and identify that blurring distortions exhibit
similar frequency properties, which allows us to use them as surrogate attacks
during training to bolster watermark robustness; (2) we leverage a large-scale
pretrained diffusion model SDXL-Turbo, adapting it for the watermarking task to
achieve more imperceptible and robust watermark embedding. Experimental results
show that our method achieves outstanding watermarking performance under
various image editing techniques, outperforming existing methods in both image
quality and robustness. Code is available at https://github.com/Shilin-LU/VINE.
</summary>
    <author>
      <name>Shilin Lu</name>
    </author>
    <author>
      <name>Zihan Zhou</name>
    </author>
    <author>
      <name>Jiayou Lu</name>
    </author>
    <author>
      <name>Yuanzhi Zhu</name>
    </author>
    <author>
      <name>Adams Wai-Kin Kong</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18774v1</id>
    <updated>2024-10-24T14:26:58Z</updated>
    <published>2024-10-24T14:26:58Z</published>
    <title>Fully Stochastic Primal-dual Gradient Algorithm for Non-convex
  Optimization on Random Graphs</title>
    <summary>  Stochastic decentralized optimization algorithms often suffer from issues
such as synchronization overhead and intermittent communication. This paper
proposes a $\underline{\rm F}$ully $\underline{\rm S}$tochastic $\underline{\rm
P}$rimal $\underline{\rm D}$ual gradient $\underline{\rm A}$lgorithm (FSPDA)
that suggests an asynchronous decentralized procedure with (i) sparsified
non-blocking communication on random undirected graphs and (ii) local
stochastic gradient updates. FSPDA allows multiple local gradient steps to
accelerate convergence to stationarity while finding a consensual solution with
stochastic primal-dual updates. For problems with smooth (possibly non-convex)
objective function, we show that FSPDA converges to an $\mathrm{\mathcal{O}(
{\it \sigma /\sqrt{nT}} )}$-stationary solution after $\mathrm{\it T}$
iterations without assuming data heterogeneity. The performance of FSPDA is on
par with state-of-the-art algorithms whose convergence depend on static graph
and synchronous updates. To our best knowledge, FSPDA is the first asynchronous
algorithm that converges exactly under the non-convex setting. Numerical
experiments are presented to show the benefits of FSPDA.
</summary>
    <author>
      <name>Chung-Yiu Yau</name>
    </author>
    <author>
      <name>Haoming Liu</name>
    </author>
    <author>
      <name>Hoi-To Wai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18773v1</id>
    <updated>2024-10-24T14:26:42Z</updated>
    <published>2024-10-24T14:26:42Z</published>
    <title>A frequency-domain approach for estimating continuous-time diffusively
  coupled linear networks</title>
    <summary>  This paper addresses the problem of consistently estimating a continuous-time
(CT) diffusively coupled network (DCN) to identify physical components in a
physical network. We develop a three-step frequency-domain identification
method for linear CT DCNs that allows to accurately recover all the physical
component values of the network while exploiting the particular symmetric
structure in a DCN model. This method uses the estimated noise covariance as a
non-parametric noise model to minimize variance of the parameter estimates,
obviating the need to select a parametric noise model. Moreover, this method is
extended to subnetworks identification, which enables identifying the local
dynamics in DCNs on the basis of partial measurements. The method is
illustrated with an application from In-Circuit Testing of printed circuit
boards. Experimental results highlight the method's ability to consistently
estimate component values in a complex network with only a single excitation.
</summary>
    <author>
      <name>Desen Liang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lizan</arxiv:affiliation>
    </author>
    <author>
      <name>E. M. M.</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lizan</arxiv:affiliation>
    </author>
    <author>
      <name> Kivits</name>
    </author>
    <author>
      <name>Maarten Schoukens</name>
    </author>
    <author>
      <name>Paul M. J. Van den Hof</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 6 figures, extended version of paper submitted to European
  Control Conference, 2025, Thessaloniki, Greece</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18772v1</id>
    <updated>2024-10-24T14:26:00Z</updated>
    <published>2024-10-24T14:26:00Z</published>
    <title>Search for shortest paths based on a projective description of
  unweighted graphs</title>
    <summary>  The search is based on the preliminary transformation of matrices or
adjacency lists traditionally used in the study of graphs into projections
cleared of redundant information (refined) followed by the selection of the
desired shortest paths. Each projection contains complete information about all
the shortest paths from its base (angle vertex) and is based on an enumeration
of reachability relations, more complex than the traditionally used binary
adjacency relations. The class of graphs considered was expanded to mixed
graphs containing both undirected and oriented edges (arcs). A method for
representing graph projections in computer memory and finding shortest paths
using them is proposed. The reduction in algorithmic complexity achieved, at
the same time, will allow the proposed method to be used in information network
applications, scientific and technical, transport and logistics, and economic
fields.
</summary>
    <author>
      <name>V. A. Melent'ev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 1 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18768v1</id>
    <updated>2024-10-24T14:21:45Z</updated>
    <published>2024-10-24T14:21:45Z</published>
    <title>A New Definition of Demand Response in the Distributed Energy Resource
  Era</title>
    <summary>  Demand response is a concept that has been around since the very first
electric power systems. However, we have seen an explosion of research on
demand response and demand-side technologies in the past 30 years, coinciding
with the shift towards liberalized/deregulated electricity markets and efforts
to decarbonize the power sector. Now we are also seeing a shift towards more
distributed/decentralized electric systems; we have entered the era of
"distributed energy resources," which require new grid management, operational,
and control strategies. Given this paradigm shift, we argue that the concept of
demand response needs to be revisited, and more carefully/consistently defined
to enable us to better utilize this massive resource for economic, technical,
environmental, and societal aims. In this paper, we survey existing demand
response definitions, highlight their shortcomings, propose a new definition,
and describe how this new definition enables us to more effectively harness the
value of demand response in modern power systems. We conclude with a demand
response research agenda informed by a discussion of demand response barriers
and enablers.
</summary>
    <author>
      <name>Johanna L. Mathieu</name>
    </author>
    <author>
      <name>Gregor Verbič</name>
    </author>
    <author>
      <name>Thomas Morstyn</name>
    </author>
    <author>
      <name>Mads Almassalkhi</name>
    </author>
    <author>
      <name>Kyri Baker</name>
    </author>
    <author>
      <name>Julio Braslavsky</name>
    </author>
    <author>
      <name>Kenneth Bruninx</name>
    </author>
    <author>
      <name>Yury Dvorkin</name>
    </author>
    <author>
      <name>Gregory S. Ledva</name>
    </author>
    <author>
      <name>Nariman Mahdavi</name>
    </author>
    <author>
      <name>Hrvoje Pandžić</name>
    </author>
    <author>
      <name>Alessandra Parisio</name>
    </author>
    <author>
      <name>Vedran Perić</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18766v1</id>
    <updated>2024-10-24T14:19:38Z</updated>
    <published>2024-10-24T14:19:38Z</published>
    <title>Attention-based Citywide Electric Vehicle Charging Demand Prediction
  Approach Considering Urban Region and Dynamic Influences</title>
    <summary>  Electric vehicle charging demand prediction is important for vacant charging
pile recommendation and charging infrastructure planning, thus facilitating
vehicle electrification and green energy development. The performance of
previous spatio-temporal studies is still far from satisfactory because the
traditional graphs are difficult to model non-pairwise spatial relationships
and multivariate temporal features are not adequately taken into account. To
tackle these issues, we propose an attention-based heterogeneous multivariate
data fusion approach (AHMDF) for citywide electric vehicle charging demand
prediction, which incorporates geo-based clustered hypergraph and multivariate
gated Transformer to considers both static and dynamic influences. To learn
non-pairwise relationships, we cluster service areas by the types and numbers
of points of interest in the areas and develop attentive hypergraph networks
accordingly. Graph attention mechanisms are used for information propagation
between neighboring areas. Additionally, we improve the Transformer encoder
utilizing gated mechanisms so that it can selectively learn dynamic auxiliary
information and temporal features. Experiments on an electric vehicle charging
benchmark dataset demonstrate the effectiveness of our proposed approach
compared with a broad range of competing baselines. Furthermore, we demonstrate
the impact of dynamic influences on prediction results in different areas of
the city and the effectiveness of our clustering method.
</summary>
    <author>
      <name>Haoxuan Kuang</name>
    </author>
    <author>
      <name>Kunxiang Deng</name>
    </author>
    <author>
      <name>Linlin You</name>
    </author>
    <author>
      <name>Jun Li</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18764v1</id>
    <updated>2024-10-24T14:18:32Z</updated>
    <published>2024-10-24T14:18:32Z</published>
    <title>Task Calibration: Calibrating Large Language Models on Inference Tasks</title>
    <summary>  Large language models (LLMs) have exhibited impressive zero-shot performance
on inference tasks. However, LLMs may suffer from spurious correlations between
input texts and output labels, which limits LLMs' ability to reason based
purely on general language understanding. In other words, LLMs may make
predictions primarily based on premise or hypothesis, rather than both
components. To address this problem that may lead to unexpected performance
degradation, we propose task calibration (TC), a zero-shot and inference-only
calibration method inspired by mutual information which recovers LLM
performance through task reformulation. TC encourages LLMs to reason based on
both premise and hypothesis, while mitigating the models' over-reliance on
individual premise or hypothesis for inference. Experimental results show that
TC achieves a substantial improvement on 13 inference tasks in the zero-shot
setup. We further validate the effectiveness of TC in few-shot setups and
various natural language understanding tasks. Further analysis indicates that
TC is also robust to prompt templates and has the potential to be integrated
with other calibration methods.
</summary>
    <author>
      <name>Yingjie Li</name>
    </author>
    <author>
      <name>Yun Luo</name>
    </author>
    <author>
      <name>Xiaotian Xie</name>
    </author>
    <author>
      <name>Yue Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18757v1</id>
    <updated>2024-10-24T14:09:09Z</updated>
    <published>2024-10-24T14:09:09Z</published>
    <title>Sliding DFT-based Signal Recovery for Modulo ADC with 1-bit Folding
  Information</title>
    <summary>  The modulo analog-to-digital converter (ADC) is a promising solution to
resolve the limited dynamic range (DR) issue of conventional ADCs. However, a
modulo ADC requires an unfolding scheme to correct the nonlinear distortion
introduced by the modulo operation. This paper presents a sliding discrete
Fourier Transform (DFT)-based method for fast signal reconstruction given the
modulo ADC output sequence and a 1-bit folding information sequence. In
contrast to existing DFT-based signal recovery techniques for modulo ADCs, our
proposed sliding DFT method reduces the required observation time and minimizes
the spectral leakage effects via proper choice of window function parameters. A
mean squared error (MSE) performance guarantee is established for the proposed
signal recovery algorithm. More precisely, we derive sufficient conditions for
the oversampling factor ($\mathrm{OF}$) and the number of quantization bits
($b$) to obtain a specific MSE performance. Our numerical results demonstrate
that modulo ADCs equipped with our proposed recovery method can outperform
conventional ADCs without modulo for $\mathrm{OF} \geq 4$ and $b \geq 4$. The
impact of spectral leakage on the MSE performance of the proposed sliding DFT
recovery method is also quantified.
</summary>
    <author>
      <name>Neil Irwin Bernardo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures, this work has been submitted to the IEEE for
  possible publication</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18756v1</id>
    <updated>2024-10-24T14:07:02Z</updated>
    <published>2024-10-24T14:07:02Z</published>
    <title>Schedule Your Edit: A Simple yet Effective Diffusion Noise Schedule for
  Image Editing</title>
    <summary>  Text-guided diffusion models have significantly advanced image editing,
enabling high-quality and diverse modifications driven by text prompts.
However, effective editing requires inverting the source image into a latent
space, a process often hindered by prediction errors inherent in DDIM
inversion. These errors accumulate during the diffusion process, resulting in
inferior content preservation and edit fidelity, especially with conditional
inputs. We address these challenges by investigating the primary contributors
to error accumulation in DDIM inversion and identify the singularity problem in
traditional noise schedules as a key issue. To resolve this, we introduce the
Logistic Schedule, a novel noise schedule designed to eliminate singularities,
improve inversion stability, and provide a better noise space for image
editing. This schedule reduces noise prediction errors, enabling more faithful
editing that preserves the original content of the source image. Our approach
requires no additional retraining and is compatible with various existing
editing methods. Experiments across eight editing tasks demonstrate the
Logistic Schedule's superior performance in content preservation and edit
fidelity compared to traditional noise schedules, highlighting its adaptability
and effectiveness.
</summary>
    <author>
      <name>Haonan Lin</name>
    </author>
    <author>
      <name>Mengmeng Wang</name>
    </author>
    <author>
      <name>Jiahao Wang</name>
    </author>
    <author>
      <name>Wenbin An</name>
    </author>
    <author>
      <name>Yan Chen</name>
    </author>
    <author>
      <name>Yong Liu</name>
    </author>
    <author>
      <name>Feng Tian</name>
    </author>
    <author>
      <name>Guang Dai</name>
    </author>
    <author>
      <name>Jingdong Wang</name>
    </author>
    <author>
      <name>Qianying Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in NeurIPS 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18751v1</id>
    <updated>2024-10-24T14:00:28Z</updated>
    <published>2024-10-24T14:00:28Z</published>
    <title>Double Auctions: Formalization and Automated Checkers</title>
    <summary>  Double auctions are widely used in financial markets, such as those for
stocks, derivatives, currencies, and commodities, to match demand and supply.
Once all buyers and sellers have placed their trade requests, the exchange
determines how these requests are to be matched. The two most common objectives
for determining the matching are maximizing trade volume at a uniform price and
maximizing trade volume through dynamic pricing. Prior research has primarily
focused on single-quantity trade requests. In this work, we extend the
framework to handle multiple-quantity trade requests and present fully
formalized matching algorithms for double auctions, along with their
correctness proofs. We establish new uniqueness theorems, enabling automatic
detection of violations in exchange systems by comparing their output to that
of a verified program. All proofs are formalized in the Coq Proof Assistant,
and we extract verified OCaml and Haskell programs that could serve as a
resource for exchanges and market regulators. We demonstrate the practical
applicability of our work by running the verified program on real market data
from an exchange to automatically check for violations in the exchange
algorithm.
</summary>
    <author>
      <name>Mohit Garg</name>
    </author>
    <author>
      <name>N. Raja</name>
    </author>
    <author>
      <name>Suneel Sarswat</name>
    </author>
    <author>
      <name>Abhishek Kr Singh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, Preliminary version of this work was published in ITP 2021</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.3.1; K.4.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18749v1</id>
    <updated>2024-10-24T13:59:03Z</updated>
    <published>2024-10-24T13:59:03Z</published>
    <title>Does Differential Privacy Impact Bias in Pretrained NLP Models?</title>
    <summary>  Differential privacy (DP) is applied when fine-tuning pre-trained large
language models (LLMs) to limit leakage of training examples. While most DP
research has focused on improving a model's privacy-utility tradeoff, some find
that DP can be unfair to or biased against underrepresented groups. In this
work, we show the impact of DP on bias in LLMs through empirical analysis.
Differentially private training can increase the model bias against protected
groups w.r.t AUC-based bias metrics. DP makes it more difficult for the model
to differentiate between the positive and negative examples from the protected
groups and other groups in the rest of the population. Our results also show
that the impact of DP on bias is not only affected by the privacy protection
level but also the underlying distribution of the dataset.
</summary>
    <author>
      <name>Md. Khairul Islam</name>
    </author>
    <author>
      <name>Andrew Wang</name>
    </author>
    <author>
      <name>Tianhao Wang</name>
    </author>
    <author>
      <name>Yangfeng Ji</name>
    </author>
    <author>
      <name>Judy Fox</name>
    </author>
    <author>
      <name>Jieyu Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Github https://github.com/khairulislam/DP-on-NLP-Bias</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18745v1</id>
    <updated>2024-10-24T13:51:50Z</updated>
    <published>2024-10-24T13:51:50Z</published>
    <title>Why Does the Effective Context Length of LLMs Fall Short?</title>
    <summary>  Advancements in distributed training and efficient attention mechanisms have
significantly expanded the context window sizes of large language models
(LLMs). However, recent work reveals that the effective context lengths of
open-source LLMs often fall short, typically not exceeding half of their
training lengths. In this work, we attribute this limitation to the left-skewed
frequency distribution of relative positions formed in LLMs pretraining and
post-training stages, which impedes their ability to effectively gather distant
information. To address this challenge, we introduce ShifTed Rotray position
embeddING (STRING). STRING shifts well-trained positions to overwrite the
original ineffective positions during inference, enhancing performance within
their existing training lengths. Experimental results show that without
additional training, STRING dramatically improves the performance of the latest
large-scale models, such as Llama3.1 70B and Qwen2 72B, by over 10 points on
popular long-context benchmarks RULER and InfiniteBench, establishing new
state-of-the-art results for open-source LLMs. Compared to commercial models,
Llama 3.1 70B with \method even achieves better performance than GPT-4-128K and
clearly surpasses Claude 2 and Kimi-chat.
</summary>
    <author>
      <name>Chenxin An</name>
    </author>
    <author>
      <name>Jun Zhang</name>
    </author>
    <author>
      <name>Ming Zhong</name>
    </author>
    <author>
      <name>Lei Li</name>
    </author>
    <author>
      <name>Shansan Gong</name>
    </author>
    <author>
      <name>Yao Luo</name>
    </author>
    <author>
      <name>Jingjing Xu</name>
    </author>
    <author>
      <name>Lingpeng Kong</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18742v1</id>
    <updated>2024-10-24T13:45:02Z</updated>
    <published>2024-10-24T13:45:02Z</published>
    <title>Continuous Dynamic Modeling via Neural ODEs for Popularity Trajectory
  Prediction</title>
    <summary>  Popularity prediction for information cascades has significant applications
across various domains, including opinion monitoring and advertising
recommendations. While most existing methods consider this as a discrete
problem, popularity actually evolves continuously, exhibiting rich dynamic
properties such as change rates and growth patterns. In this paper, we argue
that popularity trajectory prediction is more practical, as it aims to forecast
the entire trajectory of how popularity unfolds over arbitrary future time.
This approach offers insights into both instantaneous popularity and the
underlying dynamic properties. However, traditional methods for popularity
trajectory prediction primarily rely on specific diffusion mechanism
assumptions, which may not align well with real-world dynamics and compromise
their performance. To address these limitations, we propose NODEPT, a novel
approach based on neural ordinary differential equations (ODEs) for popularity
trajectory prediction. NODEPT models the continuous dynamics of the underlying
diffusion system using neural ODEs. We first employ an encoder to initialize
the latent state representations of information cascades, consisting of two
representation learning modules that capture the co-evolution structural
characteristics and temporal patterns of cascades from different perspectives.
More importantly, we then introduce an ODE-based generative module that learns
the dynamics of the diffusion system in the latent space. Finally, a decoder
transforms the latent state into the prediction of the future popularity
trajectory. Our experimental results on three real-world datasets demonstrate
the superiority and rationality of the proposed NODEPT method.
</summary>
    <author>
      <name>Songbo Yang</name>
    </author>
    <author>
      <name>Ziwei Zhao</name>
    </author>
    <author>
      <name>Zihang Chen</name>
    </author>
    <author>
      <name>Haotian Zhang</name>
    </author>
    <author>
      <name>Tong Xu</name>
    </author>
    <author>
      <name>Mengxiao Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18739v1</id>
    <updated>2024-10-24T13:42:05Z</updated>
    <published>2024-10-24T13:42:05Z</published>
    <title>5G Replicates TSN: Extending IEEE 802.1CB Capabilities to Integrated
  5G/TSN Systems</title>
    <summary>  The IEEE 802.1 time-sensitive networking (TSN) standards improve real-time
capabilities of the standard Ethernet. TSN and local/private 5G systems are
envisaged to co-exist in industrial environments. The IEEE 802.1CB standard
provides fault tolerance to TSN systems via frame replication and elimination
for reliability (FRER) capabilities. This paper presents X-FRER, a novel
framework for extending FRER capabilities to the 3GPP-defined bridge model for
5G and TSN integration. The different embodiments of X-FRER realize FRER-like
functionality through multi-path transmissions in a 5G system based on a single
or multiple protocol data unit (PDU) sessions. X-FRER also provides enhanced
replication and elimination functionality for integrated deployments.
Performance evaluation shows that X-FRER empowers a vanilla 5G system with
TSN-like capabilities for end-to-end reliability in integrated TSN and 5G
deployments.
</summary>
    <author>
      <name>Adnan Aijaz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in IEEE CSCN 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18739v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18739v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18738v1</id>
    <updated>2024-10-24T13:41:40Z</updated>
    <published>2024-10-24T13:41:40Z</published>
    <title>Cellpose+, a morphological analysis tool for feature extraction of
  stained cell images</title>
    <summary>  Advanced image segmentation and processing tools present an opportunity to
study cell processes and their dynamics. However, image analysis is often
routine and time-consuming. Nowadays, alternative data-driven approaches using
deep learning are potentially offering automatized, accurate, and fast image
analysis. In this paper, we extend the applications of Cellpose, a
state-of-the-art cell segmentation framework, with feature extraction
capabilities to assess morphological characteristics. We also introduce a
dataset of DAPI and FITC stained cells to which our new method is applied.
</summary>
    <author>
      <name>Israel A. Huaman</name>
    </author>
    <author>
      <name>Fares D. E. Ghorabe</name>
    </author>
    <author>
      <name>Sofya S. Chumakova</name>
    </author>
    <author>
      <name>Alexandra A. Pisarenko</name>
    </author>
    <author>
      <name>Alexey E. Dudaev</name>
    </author>
    <author>
      <name>Tatiana G. Volova</name>
    </author>
    <author>
      <name>Galina A. Ryltseva</name>
    </author>
    <author>
      <name>Sviatlana A. Ulasevich</name>
    </author>
    <author>
      <name>Ekaterina I. Shishatskaya</name>
    </author>
    <author>
      <name>Ekaterina V. Skorb</name>
    </author>
    <author>
      <name>Pavel S. Zun</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T07" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18737v1</id>
    <updated>2024-10-24T13:41:32Z</updated>
    <published>2024-10-24T13:41:32Z</published>
    <title>Rectified Diffusion Guidance for Conditional Generation</title>
    <summary>  Classifier-Free Guidance (CFG), which combines the conditional and
unconditional score functions with two coefficients summing to one, serves as a
practical technique for diffusion model sampling. Theoretically, however,
denoising with CFG cannot be expressed as a reciprocal diffusion process, which
may consequently leave some hidden risks during use. In this work, we revisit
the theory behind CFG and rigorously confirm that the improper configuration of
the combination coefficients (i.e., the widely used summing-to-one version)
brings about expectation shift of the generative distribution. To rectify this
issue, we propose ReCFG with a relaxation on the guidance coefficients such
that denoising with ReCFG strictly aligns with the diffusion theory. We further
show that our approach enjoys a closed-form solution given the guidance
strength. That way, the rectified coefficients can be readily pre-computed via
traversing the observed data, leaving the sampling speed barely affected.
Empirical evidence on real-world data demonstrate the compatibility of our
post-hoc design with existing state-of-the-art diffusion models, including both
class-conditioned ones (e.g., EDM2 on ImageNet) and text-conditioned ones
(e.g., SD3 on CC12M), without any retraining. We will open-source the code to
facilitate further research.
</summary>
    <author>
      <name>Mengfei Xia</name>
    </author>
    <author>
      <name>Nan Xue</name>
    </author>
    <author>
      <name>Yujun Shen</name>
    </author>
    <author>
      <name>Ran Yi</name>
    </author>
    <author>
      <name>Tieliang Gong</name>
    </author>
    <author>
      <name>Yong-Jin Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18727v1</id>
    <updated>2024-10-24T13:33:23Z</updated>
    <published>2024-10-24T13:33:23Z</published>
    <title>Breaking Down the Barriers: Investigating Non-Expert User Experiences in
  Robotic Teleoperation in UK and Japan</title>
    <summary>  Robots are being created each year with the goal of integrating them into our
daily lives. As such, there is an interest in research in evaluating the trust
of humans toward robots. In addition, teleoperating robotic arms can be
challenging for non-experts. In order to reduce the strain put on the user, we
created TELESIM, a modular and plug-and-play framework that enables direct
teleoperation of any robotic arm using a digital twin as the interface between
users and the robotic system. However, analysis of the strain put on the user
and its ability to trust robots was omitted. This paper addresses these
omissions by presenting the additional results of our user survey of 37
participants carried out in UK. In addition, we present the results of an
additional user survey, under similar conditions performed in Japan, with the
goal of addressing the limitations of our previous approach, by interfacing a
VR controller with a UR5e. Our experimental results show that the UR5e has a
higher number of towers built. Additionally, the UR5e gives the least amount of
cognitive stress, while the combination of Senseglove and UR3 gives the user
the highest physical strain and causes the user to feel more frustrated.
Finally, Japanese seems more trusting towards robots than British.
</summary>
    <author>
      <name>Florent P Audonnet</name>
    </author>
    <author>
      <name>Andrew Hamilton</name>
    </author>
    <author>
      <name>Yakiyasu Domae</name>
    </author>
    <author>
      <name>Ixchel G Ramirez-Alpizar</name>
    </author>
    <author>
      <name>Gerardo Aragon-Camarasa</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18725v1</id>
    <updated>2024-10-24T13:30:18Z</updated>
    <published>2024-10-24T13:30:18Z</published>
    <title>AI Readiness in Healthcare through Storytelling XAI</title>
    <summary>  Artificial Intelligence is rapidly advancing and radically impacting everyday
life, driven by the increasing availability of computing power. Despite this
trend, the adoption of AI in real-world healthcare is still limited. One of the
main reasons is the trustworthiness of AI models and the potential hesitation
of domain experts with model predictions. Explainable Artificial Intelligence
(XAI) techniques aim to address these issues. However, explainability can mean
different things to people with different backgrounds, expertise, and goals. To
address the target audience with diverse needs, we develop storytelling XAI. In
this research, we have developed an approach that combines multi-task
distillation with interpretability techniques to enable audience-centric
explainability. Using multi-task distillation allows the model to exploit the
relationships between tasks, potentially improving interpretability as each
task supports the other leading to an enhanced interpretability from the
perspective of a domain expert. The distillation process allows us to extend
this research to large deep models that are highly complex. We focus on both
model-agnostic and model-specific methods of interpretability, supported by
textual justification of the results in healthcare through our use case. Our
methods increase the trust of both the domain experts and the machine learning
experts to enable a responsible AI.
</summary>
    <author>
      <name>Akshat Dubey</name>
    </author>
    <author>
      <name>Zewen Yang</name>
    </author>
    <author>
      <name>Georges Hattab</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pre-print of the accepted manuscript in EXPLIMED - First Workshop on
  Explainable Artificial Intelligence for the Medical Domain, European
  Conference on Artificial Intelligence (ECAI) - 2024, Santiago de Compostela,
  Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18723v1</id>
    <updated>2024-10-24T13:28:40Z</updated>
    <published>2024-10-24T13:28:40Z</published>
    <title>VoxelKeypointFusion: Generalizable Multi-View Multi-Person Pose
  Estimation</title>
    <summary>  In the rapidly evolving field of computer vision, the task of accurately
estimating the poses of multiple individuals from various viewpoints presents a
formidable challenge, especially if the estimations should be reliable as well.
This work presents an extensive evaluation of the generalization capabilities
of multi-view multi-person pose estimators to unseen datasets and presents a
new algorithm with strong performance in this task. It also studies the
improvements by additionally using depth information. Since the new approach
can not only generalize well to unseen datasets, but also to different
keypoints, the first multi-view multi-person whole-body estimator is presented.
To support further research on those topics, all of the work is publicly
accessible.
</summary>
    <author>
      <name>Daniel Bermuth</name>
    </author>
    <author>
      <name>Alexander Poeppel</name>
    </author>
    <author>
      <name>Wolfgang Reif</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18723v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18723v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18720v1</id>
    <updated>2024-10-24T13:26:10Z</updated>
    <published>2024-10-24T13:26:10Z</published>
    <title>GeoLoRA: Geometric integration for parameter efficient fine-tuning</title>
    <summary>  Low-Rank Adaptation (LoRA) has become a widely used method for
parameter-efficient fine-tuning of large-scale, pre-trained neural networks.
However, LoRA and its extensions face several challenges, including the need
for rank adaptivity, robustness, and computational efficiency during the
fine-tuning process. We introduce GeoLoRA, a novel approach that addresses
these limitations by leveraging dynamical low-rank approximation theory.
GeoLoRA requires only a single backpropagation pass over the small-rank
adapters, significantly reducing computational cost as compared to similar
dynamical low-rank training methods and making it faster than popular baselines
such as AdaLoRA. This allows GeoLoRA to efficiently adapt the allocated
parameter budget across the model, achieving smaller low-rank adapters compared
to heuristic methods like AdaLoRA and LoRA, while maintaining critical
convergence, descent, and error-bound theoretical guarantees. The resulting
method is not only more efficient but also more robust to varying
hyperparameter settings. We demonstrate the effectiveness of GeoLoRA on several
state-of-the-art benchmarks, showing that it outperforms existing methods in
both accuracy and computational efficiency.
</summary>
    <author>
      <name>Steffen Schotthöfer</name>
    </author>
    <author>
      <name>Emanuele Zangrando</name>
    </author>
    <author>
      <name>Gianluca Ceruti</name>
    </author>
    <author>
      <name>Francesco Tudisco</name>
    </author>
    <author>
      <name>Jonas Kusch</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18718v1</id>
    <updated>2024-10-24T13:22:50Z</updated>
    <published>2024-10-24T13:22:50Z</published>
    <title>LLM-based Online Prediction of Time-varying Graph Signals</title>
    <summary>  In this paper, we propose a novel framework that leverages large language
models (LLMs) for predicting missing values in time-varying graph signals by
exploiting spatial and temporal smoothness. We leverage the power of LLM to
achieve a message-passing scheme. For each missing node, its neighbors and
previous estimates are fed into and processed by LLM to infer the missing
observations. Tested on the task of the online prediction of wind-speed graph
signals, our model outperforms online graph filtering algorithms in terms of
accuracy, demonstrating the potential of LLMs in effectively addressing
partially observed signals in graphs.
</summary>
    <author>
      <name>Dayu Qin</name>
    </author>
    <author>
      <name>Yi Yan</name>
    </author>
    <author>
      <name>Ercan Engin Kuruoglu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18718v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18718v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18717v1</id>
    <updated>2024-10-24T13:22:33Z</updated>
    <published>2024-10-24T13:22:33Z</published>
    <title>Low-Latency Video Anonymization for Crowd Anomaly Detection: Privacy vs.
  Performance</title>
    <summary>  Recent advancements in artificial intelligence promise ample potential in
monitoring applications with surveillance cameras. However, concerns about
privacy and model bias have made it challenging to utilize them in public.
Although de-identification approaches have been proposed in the literature,
aiming to achieve a certain level of anonymization, most of them employ deep
learning models that are computationally demanding for real-time edge
deployment. In this study, we revisit conventional anonymization solutions for
privacy protection and real-time video anomaly detection (VAD) applications. We
propose a novel lightweight adaptive anonymization for VAD (LA3D) that employs
dynamic adjustment to enhance privacy protection. We evaluated the approaches
on publicly available privacy and VAD data sets to examine the strengths and
weaknesses of the different anonymization techniques and highlight the
promising efficacy of our approach. Our experiment demonstrates that LA3D
enables substantial improvement in the privacy anonymization capability without
majorly degrading VAD efficacy.
</summary>
    <author>
      <name>Mulugeta Weldezgina Asres</name>
    </author>
    <author>
      <name>Lei Jiao</name>
    </author>
    <author>
      <name>Christian Walter Omlin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16pages, 8 figures, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18715v1</id>
    <updated>2024-10-24T13:19:22Z</updated>
    <published>2024-10-24T13:19:22Z</published>
    <title>ChatSearch: a Dataset and a Generative Retrieval Model for General
  Conversational Image Retrieval</title>
    <summary>  In this paper, we investigate the task of general conversational image
retrieval on open-domain images. The objective is to search for images based on
interactive conversations between humans and computers. To advance this task,
we curate a dataset called ChatSearch. This dataset includes a multi-round
multimodal conversational context query for each target image, thereby
requiring the retrieval system to find the accurate image from database.
Simultaneously, we propose a generative retrieval model named ChatSearcher,
which is trained end-to-end to accept/produce interleaved image-text
inputs/outputs. ChatSearcher exhibits strong capability in reasoning with
multimodal context and can leverage world knowledge to yield visual retrieval
results. It demonstrates superior performance on the ChatSearch dataset and
also achieves competitive results on other image retrieval tasks and visual
conversation tasks. We anticipate that this work will inspire further research
on interactive multimodal retrieval systems. Our dataset will be available at
https://github.com/joez17/ChatSearch.
</summary>
    <author>
      <name>Zijia Zhao</name>
    </author>
    <author>
      <name>Longteng Guo</name>
    </author>
    <author>
      <name>Tongtian Yue</name>
    </author>
    <author>
      <name>Erdong Hu</name>
    </author>
    <author>
      <name>Shuai Shao</name>
    </author>
    <author>
      <name>Zehuan Yuan</name>
    </author>
    <author>
      <name>Hua Huang</name>
    </author>
    <author>
      <name>Jing Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18712v1</id>
    <updated>2024-10-24T13:14:39Z</updated>
    <published>2024-10-24T13:14:39Z</published>
    <title>Retrieval-Augmented Diffusion Models for Time Series Forecasting</title>
    <summary>  While time series diffusion models have received considerable focus from many
recent works, the performance of existing models remains highly unstable.
Factors limiting time series diffusion models include insufficient time series
datasets and the absence of guidance. To address these limitations, we propose
a Retrieval- Augmented Time series Diffusion model (RATD). The framework of
RATD consists of two parts: an embedding-based retrieval process and a
reference-guided diffusion model. In the first part, RATD retrieves the time
series that are most relevant to historical time series from the database as
references. The references are utilized to guide the denoising process in the
second part. Our approach allows leveraging meaningful samples within the
database to aid in sampling, thus maximizing the utilization of datasets.
Meanwhile, this reference-guided mechanism also compensates for the
deficiencies of existing time series diffusion models in terms of guidance.
Experiments and visualizations on multiple datasets demonstrate the
effectiveness of our approach, particularly in complicated prediction tasks.
</summary>
    <author>
      <name>Jingwei Liu</name>
    </author>
    <author>
      <name>Ling Yang</name>
    </author>
    <author>
      <name>Hongyan Li</name>
    </author>
    <author>
      <name>Shenda Hong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NeurIPS 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18712v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18712v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18705v1</id>
    <updated>2024-10-24T13:07:56Z</updated>
    <published>2024-10-24T13:07:56Z</published>
    <title>Exploiting Interpretable Capabilities with Concept-Enhanced Diffusion
  and Prototype Networks</title>
    <summary>  Concept-based machine learning methods have increasingly gained importance
due to the growing interest in making neural networks interpretable. However,
concept annotations are generally challenging to obtain, making it crucial to
leverage all their prior knowledge. By creating concept-enriched models that
incorporate concept information into existing architectures, we exploit their
interpretable capabilities to the fullest extent. In particular, we propose
Concept-Guided Conditional Diffusion, which can generate visual representations
of concepts, and Concept-Guided Prototype Networks, which can create a concept
prototype dataset and leverage it to perform interpretable concept prediction.
These results open up new lines of research by exploiting pre-existing
information in the quest for rendering machine learning more
human-understandable.
</summary>
    <author>
      <name>Alba Carballo-Castro</name>
    </author>
    <author>
      <name>Sonia Laguna</name>
    </author>
    <author>
      <name>Moritz Vandenhirtz</name>
    </author>
    <author>
      <name>Julia E. Vogt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Interpretable AI: Past, Present and Future Workshop at NeurIPS 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18704v1</id>
    <updated>2024-10-24T13:02:46Z</updated>
    <published>2024-10-24T13:02:46Z</published>
    <title>Deterministic Edge Connectivity and Max Flow using Subquadratic Cut
  Queries</title>
    <summary>  We give the first deterministic algorithm that makes sub-quadratic queries to
find the global min-cut of a simple graph in the cut query model. Given an
$n$-vertex graph $G$, our algorithm makes $\widetilde{O}(n^{5/3})$ queries to
compute the global min-cut in $G$. As a key ingredient, we also show an
algorithm for finding $s$-$t$ max-flows of size $\widetilde{O}(n)$ in
$\widetilde{O}(n^{5/3})$ queries. We also show efficient cut-query
implementations of versions of expander decomposition and isolating cuts, which
may be of independent interest.
</summary>
    <author>
      <name>Aditya Anand</name>
    </author>
    <author>
      <name>Thatchaphol Saranurak</name>
    </author>
    <author>
      <name>Yunfan Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18704v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18704v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18703v1</id>
    <updated>2024-10-24T12:59:05Z</updated>
    <published>2024-10-24T12:59:05Z</published>
    <title>Whose fault is it anyway? SILC: Safe Integration of LLM-Generated Code</title>
    <summary>  In modern software development, multiple software components, often sourced
from different contributors, including AI assistants, are combined to create a
cohesive system. Although these components might each be individually safe,
their composition might not be so. At the core of this issue is often a
misalignment between the requirements and assumptions made by each component.
Once discovered it is important to determine which component is accountable for
addressing the misalignment issue and to prevent its occurrence in the future.
  In this work we propose SILC, a framework for localising fault, i.e. blame,
and for assigning sanitization obligations to prevent memory issues resulting
from the composition of multiple software components. In particular, we show
the role Incorrectness Logic could have in automatically extracting implicit
non-functional assumptions in auto-generated code and render them explicit in
order to detect misalignment with the requirements in existing code. In other
words, we are looking at the problem of code comprehension from a perspective
focused on safety properties rather than the traditional approach centered on
functionality. To do that, we enhance Incorrectness Separation Logic with
capabilities for fault tracking and sanitization insertion. We show the
benefits of this framework by running experiments on millions of lines of code
from open source projects where parts of existing functionality are regenerated
by AI assistants. We empirically show that AI assistants produce unsafe code
and demonstrate the utility of our framework in proposing appropriate blame and
sanitization obligations.
</summary>
    <author>
      <name>Peisen Lin</name>
    </author>
    <author>
      <name>Yuntong Zhang</name>
    </author>
    <author>
      <name>Andreea Costea</name>
    </author>
    <author>
      <name>Abhik Roychoudhury</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18703v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18703v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18702v1</id>
    <updated>2024-10-24T12:56:01Z</updated>
    <published>2024-10-24T12:56:01Z</published>
    <title>GrammaMT: Improving Machine Translation with Grammar-Informed In-Context
  Learning</title>
    <summary>  We introduce GrammaMT, a grammatically-aware prompting approach for machine
translation that uses Interlinear Glossed Text (IGT), a common form of
linguistic description providing morphological and lexical annotations for
source sentences. GrammaMT proposes three prompting strategies: gloss-shot,
chain-gloss and model-gloss. All are training-free, requiring only a few
examples that involve minimal effort to collect, and making them well-suited
for low-resource setups. Experiments show that GrammaMT enhances translation
performance on open-source instruction-tuned LLMs for various low- to
high-resource languages across three benchmarks: (1) the largest IGT corpus,
(2) the challenging 2023 SIGMORPHON Shared Task data over endangered languages,
and (3) even in an out-of-domain setting with FLORES. Moreover, ablation
studies reveal that leveraging gloss resources could substantially boost MT
performance (by over 17 BLEU points) if LLMs accurately generate or access
input sentence glosses.
</summary>
    <author>
      <name>Rita Ramos</name>
    </author>
    <author>
      <name>Everlyn Asiko Chimoto</name>
    </author>
    <author>
      <name>Maartje ter Hoeve</name>
    </author>
    <author>
      <name>Natalie Schluter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under review at COLING 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18702v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18702v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18701v1</id>
    <updated>2024-10-24T12:53:39Z</updated>
    <published>2024-10-24T12:53:39Z</published>
    <title>BATON: Enhancing Batch-wise Inference Efficiency for Large Language
  Models via Dynamic Re-batching</title>
    <summary>  The advanced capabilities of Large Language Models (LLMs) have inspired the
development of various interactive web services or applications, such as
ChatGPT, which offer query inference services for users. Unlike traditional DNN
model, the inference of LLM entails different iterations of forward computation
for different queries, which result in efficiency challenges for existing
run-to-completion batch-wise inference. Hence, some methods refine batch-wise
inference to iteration-level by duplicating all nonlinear layers of LLM.
However, this approach not only increases resource usage but also introduces
idle computations to the batch due to the prefilling of newly added queries.
Therefore, we propose BATON, an efficient batch-wise LLM inference scheme by
dynamically adjusting processing batch, which can achieve near-zero idle
computations without incurring additional resource consumption. To do so, BATON
1) shapes the vectors involved in the inference of the newly inserted query and
processing batch to align dimensions and generates a new attention mask based
on vector shaping to ensure inference correctness, which enables query
inserting without consuming additional resource; 2) embeds prefilled Keys and
Values of the new query into the KV_Cache of the processing batch by leveraging
the prefilling and decoding separation mechanism, eliminating idle computations
to the batch introduced by the prefilling process of the new query.
Experimental results show that compared to the state-of-the-art solution Orca,
BATON improves query processing by up to 1.75 times.
</summary>
    <author>
      <name>Peizhuang Cong</name>
    </author>
    <author>
      <name>Qizhi Chen</name>
    </author>
    <author>
      <name>Haochen Zhao</name>
    </author>
    <author>
      <name>Tong Yang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18698v1</id>
    <updated>2024-10-24T12:48:12Z</updated>
    <published>2024-10-24T12:48:12Z</published>
    <title>Transferring Knowledge from High-Quality to Low-Quality MRI for Adult
  Glioma Diagnosis</title>
    <summary>  Glioma, a common and deadly brain tumor, requires early diagnosis for
improved prognosis. However, low-quality Magnetic Resonance Imaging (MRI)
technology in Sub-Saharan Africa (SSA) hinders accurate diagnosis. This paper
presents our work in the BraTS Challenge on SSA Adult Glioma. We adopt the
model from the BraTS-GLI 2021 winning solution and utilize it with three
training strategies: (1) initially training on the BraTS-GLI 2021 dataset with
fine-tuning on the BraTS-Africa dataset, (2) training solely on the
BraTS-Africa dataset, and (3) training solely on the BraTS-Africa dataset with
2x super-resolution enhancement. Results show that initial training on the
BraTS-GLI 2021 dataset followed by fine-tuning on the BraTS-Africa dataset has
yielded the best results. This suggests the importance of high-quality datasets
in providing prior knowledge during training. Our top-performing model achieves
Dice scores of 0.882, 0.840, and 0.926, and Hausdorff Distance (95%) scores of
15.324, 37.518, and 13.971 for enhancing tumor, tumor core, and whole tumor,
respectively, in the validation phase. In the final phase of the competition,
our approach successfully secured second place overall, reflecting the strength
and effectiveness of our model and training strategies. Our approach provides
insights into improving glioma diagnosis in SSA, showing the potential of deep
learning in resource-limited settings and the importance of transfer learning
from high-quality datasets.
</summary>
    <author>
      <name>Yanguang Zhao</name>
    </author>
    <author>
      <name>Long Bai</name>
    </author>
    <author>
      <name>Zhaoxi Zhang</name>
    </author>
    <author>
      <name>Yanan Wu</name>
    </author>
    <author>
      <name>Mobarakol Islam</name>
    </author>
    <author>
      <name>Hongliang Ren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report, MICCAI 2024 BraTS-SSA Challenge Runner Up</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18698v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18698v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18697v1</id>
    <updated>2024-10-24T12:48:03Z</updated>
    <published>2024-10-24T12:48:03Z</published>
    <title>How Good Are LLMs for Literary Translation, Really? Literary Translation
  Evaluation with Humans and LLMs</title>
    <summary>  Recent research has focused on literary machine translation (MT) as a new
challenge in MT. However, the evaluation of literary MT remains an open
problem. We contribute to this ongoing discussion by introducing
LITEVAL-CORPUS, a paragraph-level parallel corpus comprising multiple verified
human translations and outputs from 9 MT systems, which totals over 2k
paragraphs and includes 13k annotated sentences across four language pairs,
costing 4.5k Euro. This corpus enables us to (i) examine the consistency and
adequacy of multiple annotation schemes, (ii) compare evaluations by students
and professionals, and (iii) assess the effectiveness of LLM-based metrics. We
find that Multidimensional Quality Metrics (MQM), as the de facto standard in
non-literary human MT evaluation, is inadequate for literary translation: While
Best-Worst Scaling (BWS) with students and Scalar Quality Metric (SQM) with
professional translators prefer human translations at rates of ~82% and ~94%,
respectively, MQM with student annotators prefers human professional
translations over the translations of the best-performing LLMs in only ~42% of
cases. While automatic metrics generally show a moderate correlation with human
MQM and SQM, they struggle to accurately identify human translations, with
rates of at most ~20%. Our overall evaluation indicates that human professional
translations consistently outperform LLM translations, where even the most
recent LLMs tend to produce more literal and less diverse translations compared
to human translations. However, newer LLMs such as GPT-4o perform substantially
better than older ones.
</summary>
    <author>
      <name>Ran Zhang</name>
    </author>
    <author>
      <name>Wei Zhao</name>
    </author>
    <author>
      <name>Steffen Eger</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18697v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18697v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18695v1</id>
    <updated>2024-10-24T12:45:25Z</updated>
    <published>2024-10-24T12:45:25Z</published>
    <title>PESFormer: Boosting Macro- and Micro-expression Spotting with Direct
  Timestamp Encoding</title>
    <summary>  The task of macro- and micro-expression spotting aims to precisely localize
and categorize temporal expression instances within untrimmed videos. Given the
sparse distribution and varying durations of expressions, existing anchor-based
methods often represent instances by encoding their deviations from predefined
anchors. Additionally, these methods typically slice the untrimmed videos into
fixed-length sliding windows. However, anchor-based encoding often fails to
capture all training intervals, and slicing the original video as sliding
windows can result in valuable training intervals being discarded. To overcome
these limitations, we introduce PESFormer, a simple yet effective model based
on the vision transformer architecture to achieve point-to-interval expression
spotting. PESFormer employs a direct timestamp encoding (DTE) approach to
replace anchors, enabling binary classification of each timestamp instead of
optimizing entire ground truths. Thus, all training intervals are retained in
the form of discrete timestamps. To maximize the utilization of training
intervals, we enhance the preprocessing process by replacing the short videos
produced through the sliding window method.Instead, we implement a strategy
that involves zero-padding the untrimmed training videos to create uniform,
longer videos of a predetermined duration. This operation efficiently preserves
the original training intervals and eliminates video slice
enhancement.Extensive qualitative and quantitative evaluations on three
datasets -- CAS(ME)^2, CAS(ME)^3 and SAMM-LV -- demonstrate that our PESFormer
outperforms existing techniques, achieving the best performance.
</summary>
    <author>
      <name>Wang-Wang Yu</name>
    </author>
    <author>
      <name>Kai-Fu Yang</name>
    </author>
    <author>
      <name>Xiangrui Hu</name>
    </author>
    <author>
      <name>Jingwen Jiang</name>
    </author>
    <author>
      <name>Hong-Mei Yan</name>
    </author>
    <author>
      <name>Yong-Jie Li</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18693v1</id>
    <updated>2024-10-24T12:42:04Z</updated>
    <published>2024-10-24T12:42:04Z</published>
    <title>Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis
  from Scratch</title>
    <summary>  The availability of high-quality data is one of the most important factors in
improving the reasoning capability of LLMs. Existing works have demonstrated
the effectiveness of creating more instruction data from seed questions or
knowledge bases. Recent research indicates that continually scaling up data
synthesis from strong models (e.g., GPT-4) can further elicit reasoning
performance. Though promising, the open-sourced community still lacks
high-quality data at scale and scalable data synthesis methods with affordable
costs. To address this, we introduce ScaleQuest, a scalable and novel data
synthesis method that utilizes "small-size" (e.g., 7B) open-source models to
generate questions from scratch without the need for seed data with complex
augmentation constraints. With the efficient ScaleQuest, we automatically
constructed a mathematical reasoning dataset consisting of 1 million
problem-solution pairs, which are more effective than existing open-sourced
datasets. It can universally increase the performance of mainstream open-source
models (i.e., Mistral, Llama3, DeepSeekMath, and Qwen2-Math) by achieving 29.2%
to 46.4% gains on MATH. Notably, simply fine-tuning the Qwen2-Math-7B-Base
model with our dataset can even surpass Qwen2-Math-7B-Instruct, a strong and
well-aligned model on closed-source data, and proprietary models such as
GPT-4-Turbo and Claude-3.5 Sonnet.
</summary>
    <author>
      <name>Yuyang Ding</name>
    </author>
    <author>
      <name>Xinyu Shi</name>
    </author>
    <author>
      <name>Xiaobo Liang</name>
    </author>
    <author>
      <name>Juntao Li</name>
    </author>
    <author>
      <name>Qiaoming Zhu</name>
    </author>
    <author>
      <name>Min Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint. Project page: https://scalequest.github.io/</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18687v1</id>
    <updated>2024-10-24T12:32:22Z</updated>
    <published>2024-10-24T12:32:22Z</published>
    <title>ODDN: Addressing Unpaired Data Challenges in Open-World Deepfake
  Detection on Online Social Networks</title>
    <summary>  Despite significant advances in deepfake detection, handling varying image
quality, especially due to different compressions on online social networks
(OSNs), remains challenging. Current methods succeed by leveraging correlations
between paired images, whether raw or compressed. However, in open-world
scenarios, paired data is scarce, with compressed images readily available but
corresponding raw versions difficult to obtain. This imbalance, where unpaired
data vastly outnumbers paired data, often leads to reduced detection
performance, as existing methods struggle without corresponding raw images. To
overcome this issue, we propose a novel approach named the open-world deepfake
detection network (ODDN), which comprises two core modules: open-world data
aggregation (ODA) and compression-discard gradient correction (CGC). ODA
effectively aggregates correlations between compressed and raw samples through
both fine-grained and coarse-grained analyses for paired and unpaired data,
respectively. CGC incorporates a compression-discard gradient correction to
further enhance performance across diverse compression methods in OSN. This
technique optimizes the training gradient to ensure the model remains
insensitive to compression variations. Extensive experiments conducted on 17
popular deepfake datasets demonstrate the superiority of the ODDN over SOTA
baselines.
</summary>
    <author>
      <name>Renshuai Tao</name>
    </author>
    <author>
      <name>Manyi Le</name>
    </author>
    <author>
      <name>Chuangchuang Tan</name>
    </author>
    <author>
      <name>Huan Liu</name>
    </author>
    <author>
      <name>Haotong Qin</name>
    </author>
    <author>
      <name>Yao Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18686v1</id>
    <updated>2024-10-24T12:32:19Z</updated>
    <published>2024-10-24T12:32:19Z</published>
    <title>Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced
  Time Series Classification</title>
    <summary>  Leveraging large language models (LLMs) has garnered increasing attention and
introduced novel perspectives in time series classification. However, existing
approaches often overlook the crucial dynamic temporal information inherent in
time series data and face challenges in aligning this data with textual
semantics. To address these limitations, we propose HiTime, a hierarchical
multi-modal model that seamlessly integrates temporal information into LLMs for
multivariate time series classification (MTSC). Our model employs a
hierarchical feature encoder to capture diverse aspects of time series data
through both data-specific and task-specific embeddings. To facilitate semantic
space alignment between time series and text, we introduce a dual-view
contrastive alignment module that bridges the gap between modalities.
Additionally, we adopt a hybrid prompting strategy to fine-tune the pre-trained
LLM in a parameter-efficient manner. By effectively incorporating dynamic
temporal features and ensuring semantic alignment, HiTime enables LLMs to
process continuous time series data and achieves state-of-the-art
classification performance through text generation. Extensive experiments on
benchmark datasets demonstrate that HiTime significantly enhances time series
classification accuracy compared to most competitive baseline methods. Our
findings highlight the potential of integrating temporal features into LLMs,
paving the way for advanced time series analysis. The code is publicly
available for further research and validation. Our codes are publicly
available1.
</summary>
    <author>
      <name>Xiaoyu Tao</name>
    </author>
    <author>
      <name>Tingyue Pan</name>
    </author>
    <author>
      <name>Mingyue Cheng</name>
    </author>
    <author>
      <name>Yucong Luo</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18684v1</id>
    <updated>2024-10-24T12:26:05Z</updated>
    <published>2024-10-24T12:26:05Z</published>
    <title>Every Component Counts: Rethinking the Measure of Success for Medical
  Semantic Segmentation in Multi-Instance Segmentation Tasks</title>
    <summary>  We present Connected-Component~(CC)-Metrics, a novel semantic segmentation
evaluation protocol, targeted to align existing semantic segmentation metrics
to a multi-instance detection scenario in which each connected component
matters. We motivate this setup in the common medical scenario of semantic
metastases segmentation in a full-body PET/CT. We show how existing semantic
segmentation metrics suffer from a bias towards larger connected components
contradicting the clinical assessment of scans in which tumor size and clinical
relevance are uncorrelated. To rebalance existing segmentation metrics, we
propose to evaluate them on a per-component basis thus giving each tumor the
same weight irrespective of its size. To match predictions to ground-truth
segments, we employ a proximity-based matching criterion, evaluating common
metrics locally at the component of interest. Using this approach, we break
free of biases introduced by large metastasis for overlap-based metrics such as
Dice or Surface Dice. CC-Metrics also improves distance-based metrics such as
Hausdorff Distances which are uninformative for small changes that do not
influence the maximum or 95th percentile, and avoids pitfalls introduced by
directly combining counting-based metrics with overlap-based metrics as it is
done in Panoptic Quality.
</summary>
    <author>
      <name>Alexander Jaus</name>
    </author>
    <author>
      <name>Constantin Seibold</name>
    </author>
    <author>
      <name>Simon Reiß</name>
    </author>
    <author>
      <name>Zdravko Marinov</name>
    </author>
    <author>
      <name>Keyi Li</name>
    </author>
    <author>
      <name>Zeling Ye</name>
    </author>
    <author>
      <name>Stefan Krieg</name>
    </author>
    <author>
      <name>Jens Kleesiek</name>
    </author>
    <author>
      <name>Rainer Stiefelhagen</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18684v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18684v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18683v1</id>
    <updated>2024-10-24T12:24:27Z</updated>
    <published>2024-10-24T12:24:27Z</published>
    <title>Rigid Single-Slice-in-Volume registration via rotation-equivariant 2D/3D
  feature matching</title>
    <summary>  2D to 3D registration is essential in tasks such as diagnosis, surgical
navigation, environmental understanding, navigation in robotics, autonomous
systems, or augmented reality. In medical imaging, the aim is often to place a
2D image in a 3D volumetric observation to w. Current approaches for rigid
single slice in volume registration are limited by requirements such as pose
initialization, stacks of adjacent slices, or reliable anatomical landmarks.
Here, we propose a self-supervised 2D/3D registration approach to match a
single 2D slice to the corresponding 3D volume. The method works in data
without anatomical priors such as images of tumors. It addresses the
dimensionality disparity and establishes correspondences between 2D in-plane
and 3D out-of-plane rotation-equivariant features by using group equivariant
CNNs. These rotation-equivariant features are extracted from the 2D query slice
and aligned with their 3D counterparts. Results demonstrate the robustness of
the proposed slice-in-volume registration on the NSCLC-Radiomics CT and KIRBY21
MRI datasets, attaining an absolute median angle error of less than 2 degrees
and a mean-matching feature accuracy of 89% at a tolerance of 3 pixels.
</summary>
    <author>
      <name>Stefan Brandstätter</name>
    </author>
    <author>
      <name>Philipp Seeböck</name>
    </author>
    <author>
      <name>Christoph Fürböck</name>
    </author>
    <author>
      <name>Svitlana Pochepnia</name>
    </author>
    <author>
      <name>Helmut Prosch</name>
    </author>
    <author>
      <name>Georg Langs</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-031-73480-9_22</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-031-73480-9_22" rel="related"/>
    <link href="http://arxiv.org/abs/2410.18683v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18683v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18678v1</id>
    <updated>2024-10-24T12:12:46Z</updated>
    <published>2024-10-24T12:12:46Z</published>
    <title>Ali-AUG: Innovative Approaches to Labeled Data Augmentation using
  One-Step Diffusion Model</title>
    <summary>  This paper introduces Ali-AUG, a novel single-step diffusion model for
efficient labeled data augmentation in industrial applications. Our method
addresses the challenge of limited labeled data by generating synthetic,
labeled images with precise feature insertion. Ali-AUG utilizes a stable
diffusion architecture enhanced with skip connections and LoRA modules to
efficiently integrate masks and images, ensuring accurate feature placement
without affecting unrelated image content. Experimental validation across
various industrial datasets demonstrates Ali-AUG's superiority in generating
high-quality, defect-enhanced images while maintaining rapid single-step
inference. By offering precise control over feature insertion and minimizing
required training steps, our technique significantly enhances data augmentation
capabilities, providing a powerful tool for improving the performance of deep
learning models in scenarios with limited labeled data. Ali-AUG is especially
useful for use cases like defective product image generation to train AI-based
models to improve their ability to detect defects in manufacturing processes.
Using different data preparation strategies, including Classification Accuracy
Score (CAS) and Naive Augmentation Score (NAS), we show that Ali-AUG improves
model performance by 31% compared to other augmentation methods and by 45%
compared to models without data augmentation. Notably, Ali-AUG reduces training
time by 32% and supports both paired and unpaired datasets, enhancing
flexibility in data preparation.
</summary>
    <author>
      <name>Ali Hamza</name>
    </author>
    <author>
      <name>Aizea Lojo</name>
    </author>
    <author>
      <name>Adrian Núñez-Marcos</name>
    </author>
    <author>
      <name>Aitziber Atutxa</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18678v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18678v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18677v1</id>
    <updated>2024-10-24T12:11:52Z</updated>
    <published>2024-10-24T12:11:52Z</published>
    <title>Enhancing pretraining efficiency for medical image segmentation via
  transferability metrics</title>
    <summary>  In medical image segmentation tasks, the scarcity of labeled training data
poses a significant challenge when training deep neural networks. When using
U-Net-style architectures, it is common practice to address this problem by
pretraining the encoder part on a large general-purpose dataset like ImageNet.
However, these methods are resource-intensive and do not guarantee improved
performance on the downstream task. In this paper we investigate a variety of
training setups on medical image segmentation datasets, using
ImageNet-pretrained models. By examining over 300 combinations of models,
datasets, and training methods, we find that shorter pretraining often leads to
better results on the downstream task, providing additional proof to the
well-known fact that the accuracy of the model on ImageNet is a poor indicator
for downstream performance. As our main contribution, we introduce a novel
transferability metric, based on contrastive learning, that measures how
robustly a pretrained model is able to represent the target data. In contrast
to other transferability scores, our method is applicable to the case of
transferring from ImageNet classification to medical image segmentation. We
apply our robustness score by measuring it throughout the pretraining phase to
indicate when the model weights are optimal for downstream transfer. This
reduces pretraining time and improves results on the target task.
</summary>
    <author>
      <name>Gábor Hidy</name>
    </author>
    <author>
      <name>Bence Bakos</name>
    </author>
    <author>
      <name>András Lukács</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18677v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18677v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18676v1</id>
    <updated>2024-10-24T12:09:01Z</updated>
    <published>2024-10-24T12:09:01Z</published>
    <title>Homomorphism Counts as Structural Encodings for Graph Learning</title>
    <summary>  Graph Transformers are popular neural networks that extend the well-known
Transformer architecture to the graph domain. These architectures operate by
applying self-attention on graph nodes and incorporating graph structure
through the use of positional encodings (e.g., Laplacian positional encoding)
or structural encodings (e.g., random-walk structural encoding). The quality of
such encodings is critical, since they provide the necessary $\textit{graph
inductive biases}$ to condition the model on graph structure. In this work, we
propose $\textit{motif structural encoding}$ (MoSE) as a flexible and powerful
structural encoding framework based on counting graph homomorphisms.
Theoretically, we compare the expressive power of MoSE to random-walk
structural encoding and relate both encodings to the expressive power of
standard message passing neural networks. Empirically, we observe that MoSE
outperforms other well-known positional and structural encodings across a range
of architectures, and it achieves state-of-the-art performance on widely
studied molecular property prediction datasets.
</summary>
    <author>
      <name>Linus Bao</name>
    </author>
    <author>
      <name>Emily Jin</name>
    </author>
    <author>
      <name>Michael Bronstein</name>
    </author>
    <author>
      <name>İsmail İlkan Ceylan</name>
    </author>
    <author>
      <name>Matthias Lanzinger</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18671v1</id>
    <updated>2024-10-24T12:01:57Z</updated>
    <published>2024-10-24T12:01:57Z</published>
    <title>Axe 'Em: Eliminating Spurious States with Induction Axioms</title>
    <summary>  First-order logic (FOL) has proved to be a versatile and expressive tool as
the basis of abstract modeling languages. Used to verify complex systems with
unbounded domains, such as heap-manipulating programs and distributed
protocols, FOL, and specifically uninterpreted functions and quantifiers,
strike a balance between expressiveness and amenity to automation. However, FOL
semantics may differ in important ways from the intended semantics of the
modeled system, due to the inability to distinguish between finite and infinite
first-order structures, for example, or the undefinability of well-founded
relations in FOL. This semantic gap may give rise to spurious states and unreal
behaviors, which only exist as an artifact of the first-order abstraction and
impede the verification process.
  In this paper we take a step towards bridging this semantic gap. We present
an approach for soundly refining the first-order abstraction according to
either well-founded semantics or finite-domain semantics, utilizing induction
axioms for an abstract order relation, a common primitive in verification. We
first formalize sound axiom schemata for each of the aforementioned semantics,
based on well-founded induction. Second, we show how to use spurious
counter-models, which are necessarily infinite, to guide the instantiation of
these axiom schemata. Finally, we present a sound and complete reduction of
well-founded semantics and finite-domain semantics to standard semantics in the
recently discovered Ordered Self-Cycle (OSC) fragment of FOL, and prove that
satisfiability under these semantics is decidable in OSC.
  We implement a prototype tool to evaluate our approach, and test it on
various examples where spurious models arise. Our tool quickly finds the
necessary axioms to refine the semantics, and successfully completes the
verification process.
</summary>
    <author>
      <name>Neta Elad</name>
    </author>
    <author>
      <name>Sharon Shoham</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18670v1</id>
    <updated>2024-10-24T12:00:51Z</updated>
    <published>2024-10-24T12:00:51Z</published>
    <title>Health Misinformation in Social Networks: A Survey of IT Approaches</title>
    <summary>  In this paper, we present a comprehensive survey on the pervasive issue of
medical misinformation in social networks from the perspective of information
technology. The survey aims at providing a systematic review of related
research and helping researchers and practitioners navigate through this
fast-changing field. Specifically, we first present manual and automatic
approaches for fact-checking. We then explore fake news detection methods,
using content, propagation features, or source features, as well as mitigation
approaches for countering the spread of misinformation. We also provide a
detailed list of several datasets on health misinformation and of publicly
available tools. We conclude the survey with a discussion on the open
challenges and future research directions in the battle against health
misinformation.
</summary>
    <author>
      <name>Vasiliki Papanikou</name>
    </author>
    <author>
      <name>Panagiotis Papadakos</name>
    </author>
    <author>
      <name>Theodora Karamanidou</name>
    </author>
    <author>
      <name>Thanos G. Stavropoulos</name>
    </author>
    <author>
      <name>Evaggelia Pitoura</name>
    </author>
    <author>
      <name>Panayiotis Tsaparas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint -- Under review in the ACM Transactions on Computing for
  Healthcare (HEALTH) journal</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18670v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18670v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18669v1</id>
    <updated>2024-10-24T12:00:37Z</updated>
    <published>2024-10-24T12:00:37Z</published>
    <title>Active Target Tracking Using Bearing-only Measurements With Gaussian
  Process Learning</title>
    <summary>  This paper studies the tracking problem of target with the partially unknown
motion model by an active agent with bearing-only measurements using Gaussian
process learning. To address this problem, a learning-planning-control
framework is proposed. First, to learn and predict the target motion under mild
assumptions, a Gaussian-process-based scheme is proposed, and a probabilistic
uniform prediction error bound can be rigorously proved. Second, by analyzing
the data dependence of the posterior covariance, we obtain an optimal relative
trajectory to achieve efficient sampling. Third, to realize efficient learning,
a controller to track the planned path is proposed based on the learned target
motion, which can provide guaranteed tracking performance. Theoretical analysis
is conducted to prove the the given probabilistic error bounds. Numerical
examples and comparison with other typical methods verify the feasibility and
superior performance of our proposed framework.
</summary>
    <author>
      <name>Yingbo Fu</name>
    </author>
    <author>
      <name>Ziwen Yang</name>
    </author>
    <author>
      <name>Shanying Zhu</name>
    </author>
    <author>
      <name>Cailian Chen</name>
    </author>
    <author>
      <name>Xinping Guan</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18669v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18669v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18668v1</id>
    <updated>2024-10-24T11:59:32Z</updated>
    <published>2024-10-24T11:59:32Z</published>
    <title>3D Shape Completion with Test-Time Training</title>
    <summary>  This work addresses the problem of \textit{shape completion}, i.e., the task
of restoring incomplete shapes by predicting their missing parts. While
previous works have often predicted the fractured and restored shape in one
step, we approach the task by separately predicting the fractured and newly
restored parts, but ensuring these predictions are interconnected. We use a
decoder network motivated by related work on the prediction of signed distance
functions (DeepSDF). In particular, our representation allows us to consider
test-time-training, i.e., finetuning network parameters to match the given
incomplete shape more accurately during inference. While previous works often
have difficulties with artifacts around the fracture boundary, we demonstrate
that our overfitting to the fractured parts leads to significant improvements
in the restoration of eight different shape categories of the ShapeNet data set
in terms of their chamfer distances.
</summary>
    <author>
      <name>Michael Schopf-Kuester</name>
    </author>
    <author>
      <name>Zorah Lähner</name>
    </author>
    <author>
      <name>Michael Moeller</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18666v1</id>
    <updated>2024-10-24T11:57:20Z</updated>
    <published>2024-10-24T11:57:20Z</published>
    <title>DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe
  Dataset Curation</title>
    <summary>  Image restoration (IR) in real-world scenarios presents significant
challenges due to the lack of high-capacity models and comprehensive datasets.
To tackle these issues, we present a dual strategy: GenIR, an innovative data
curation pipeline, and DreamClear, a cutting-edge Diffusion Transformer
(DiT)-based image restoration model. GenIR, our pioneering contribution, is a
dual-prompt learning pipeline that overcomes the limitations of existing
datasets, which typically comprise only a few thousand images and thus offer
limited generalizability for larger models. GenIR streamlines the process into
three stages: image-text pair construction, dual-prompt based fine-tuning, and
data generation &amp; filtering. This approach circumvents the laborious data
crawling process, ensuring copyright compliance and providing a cost-effective,
privacy-safe solution for IR dataset construction. The result is a large-scale
dataset of one million high-quality images. Our second contribution,
DreamClear, is a DiT-based image restoration model. It utilizes the generative
priors of text-to-image (T2I) diffusion models and the robust perceptual
capabilities of multi-modal large language models (MLLMs) to achieve
photorealistic restoration. To boost the model's adaptability to diverse
real-world degradations, we introduce the Mixture of Adaptive Modulator (MoAM).
It employs token-wise degradation priors to dynamically integrate various
restoration experts, thereby expanding the range of degradations the model can
address. Our exhaustive experiments confirm DreamClear's superior performance,
underlining the efficacy of our dual strategy for real-world image restoration.
Code and pre-trained models will be available at:
https://github.com/shallowdream204/DreamClear.
</summary>
    <author>
      <name>Yuang Ai</name>
    </author>
    <author>
      <name>Xiaoqiang Zhou</name>
    </author>
    <author>
      <name>Huaibo Huang</name>
    </author>
    <author>
      <name>Xiaotian Han</name>
    </author>
    <author>
      <name>Zhengyu Chen</name>
    </author>
    <author>
      <name>Quanzeng You</name>
    </author>
    <author>
      <name>Hongxia Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by NeurIPS 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18662v1</id>
    <updated>2024-10-24T11:47:14Z</updated>
    <published>2024-10-24T11:47:14Z</published>
    <title>New paper-by-paper classification for Scopus based on references
  reclassified by the origin of the papers citing them</title>
    <summary>  A reference-based classification system for individual Scopus publications is
presented which takes into account the categories of the papers citing those
references instead of the journals in which those cited papers are published.
It supports multiple assignments of up to 5 categories within the Scopus ASJC
structure, but eliminates the Multidisciplinary Area and the miscellaneous
categories, and it allows for the reclassification of a greater number of
publications (potentially 100%) than traditional reference-based systems.
Twelve variants of the system were obtained by adjusting different parameters,
which were applied to the more than 3.2 million citable papers from the active
Scientific Journals in 2020 indexed in Scopus. The results were analyzed and
compared with other classification systems such as the original journal-based
Scopus ASJC, the 2-generation-reference based M3-AWC-0.8 (\'Alvarez-Llorente et
al., 2024), and the corresponding authors' assignment based AAC
(\'Alvarez-Llorente et al., 2023). The different variants obtained of the
classification give results that improve those used as referents in multiple
scientometric fields. The variation called U1-F-0.8 seems especially promising
due to its restraint in assigning multiple categories, consistency with
reference classifications and the fact of applying normalization processes to
avoid the overinfluence of articles that have a greater number of references.
</summary>
    <author>
      <name>Jesús M. Álvarez-Llorente</name>
    </author>
    <author>
      <name>Vicente P. Guerrero-Bote</name>
    </author>
    <author>
      <name>Félix de Moya-Anegón</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18662v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18662v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18661v1</id>
    <updated>2024-10-24T11:46:23Z</updated>
    <published>2024-10-24T11:46:23Z</published>
    <title>Recognizing Sumsets is NP-Complete</title>
    <summary>  Sumsets are central objects in additive combinatorics. In 2007, Granville
asked whether one can efficiently recognize whether a given set $S$ is a
sumset, i.e. whether there is a set $A$ such that $A+A=S$. Granville suggested
an algorithm that takes exponential time in the size of the given set, but can
we do polynomial or even linear time? This basic computational question is
indirectly asking a fundamental structural question: do the special
characteristics of sumsets allow them to be efficiently recognizable? In this
paper, we answer this question negatively by proving that the problem is
NP-complete. Specifically, our results hold for integer sets and over any
finite field. Assuming the Exponential Time Hypothesis, our lower bound becomes
$2^{\Omega(n^{1/4})}$.
</summary>
    <author>
      <name>Amir Abboud</name>
    </author>
    <author>
      <name>Nick Fischer</name>
    </author>
    <author>
      <name>Ron Safier</name>
    </author>
    <author>
      <name>Nathan Wallheimer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at SODA 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18658v1</id>
    <updated>2024-10-24T11:36:19Z</updated>
    <published>2024-10-24T11:36:19Z</published>
    <title>NIDS Neural Networks Using Sliding Time Window Data Processing with
  Trainable Activations and its Generalization Capability</title>
    <summary>  This paper presents neural networks for network intrusion detection systems
(NIDS), that operate on flow data preprocessed with a time window. It requires
only eleven features which do not rely on deep packet inspection and can be
found in most NIDS datasets and easily obtained from conventional flow
collectors. The time window aggregates information with respect to hosts
facilitating the identification of flow signatures that are missed by other
aggregation methods. Several network architectures are studied and the use of
Kalmogorov-Arnold Network (KAN)-inspired trainable activation functions that
help to achieve higher accuracy with simpler network structure is proposed. The
reported training accuracy exceeds 99% for the proposed method with as little
as twenty neural network input features. This work also studies the
generalization capability of NIDS, a crucial aspect that has not been
adequately addressed in the previous studies. The generalization experiments
are conducted using CICIDS2017 dataset and a custom dataset collected as part
of this study. It is shown that the performance metrics decline significantly
when changing datasets, and the reduction in performance metrics can be
attributed to the difference in signatures of the same type flows in different
datasets, which in turn can be attributed to the differences between the
underlying networks. It is shown that the generalization accuracy of some
neural networks can be very unstable and sensitive to random initialization
parameters, and neural networks with fewer parameters and well-tuned
activations are more stable and achieve higher accuracy.
</summary>
    <author>
      <name>Anton Raskovalov</name>
    </author>
    <author>
      <name>Nikita Gabdullin</name>
    </author>
    <author>
      <name>Ilya Androsov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 3 figures, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18658v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18658v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18656v1</id>
    <updated>2024-10-24T11:35:39Z</updated>
    <published>2024-10-24T11:35:39Z</published>
    <title>Learning dissipative Hamiltonian dynamics with reproducing kernel
  Hilbert spaces and random Fourier features</title>
    <summary>  This paper presents a new method for learning dissipative Hamiltonian
dynamics from a limited and noisy dataset. The method uses the Helmholtz
decomposition to learn a vector field as the sum of a symplectic and a
dissipative vector field. The two vector fields are learned using two
reproducing kernel Hilbert spaces, defined by a symplectic and a curl-free
kernel, where the kernels are specialized to enforce odd symmetry. Random
Fourier features are used to approximate the kernels to reduce the dimension of
the optimization problem. The performance of the method is validated in
simulations for two dissipative Hamiltonian systems, and it is shown that the
method improves predictive accuracy significantly compared to a method where a
Gaussian separable kernel is used.
</summary>
    <author>
      <name>Torbjørn Smith</name>
    </author>
    <author>
      <name>Olav Egeland</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18655v1</id>
    <updated>2024-10-24T11:34:28Z</updated>
    <published>2024-10-24T11:34:28Z</published>
    <title>Approximate EFX and Exact tEFX Allocations for Indivisible Chores:
  Improved Algorithms</title>
    <summary>  We explore the fair distribution of a set of $m$ indivisible chores among $n$
agents, where each agent's costs are evaluated using a monotone cost function.
Our focus lies on two fairness criteria: envy-freeness up to any item (EFX) and
a relaxed notion, namely envy-freeness up to the transfer of any item (tEFX).
We demonstrate that a 2-approximate EFX allocation exists and is computable in
polynomial time for three agents with subadditive cost functions, improving
upon the previous $(2 + \sqrt{6})$ approximation for additive cost functions.
This result requires extensive case analysis. Christoforidis et al. (IJCAI'24)
independently claim the same approximation for additive cost functions;
however, we provide a counter-example to their algorithm. We expand the number
of agents to any number to get the same approximation guarantee with the
assumption of partially identical ordering (IDO) for the cost functions.
Additionally, we establish that a tEFX allocation is achievable for three
agents if one has an additive 2-ratio bounded cost function, while the others
may have general monotone cost functions. This is an improvement from the prior
requirement of two agents with additive 2-ratio bounded cost functions. This
allocation can also be extended to agent groups with identical valuations.
Further, we show various analyses of EFX allocations for chores, such as the
relaxations for additive $\alpha$-ratio-bounded cost functions.
</summary>
    <author>
      <name>Mahyar Afshinmehr</name>
    </author>
    <author>
      <name>Matin Ansaripour</name>
    </author>
    <author>
      <name>Alireza Danaei</name>
    </author>
    <author>
      <name>Kurt Mehlhorn</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18655v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18655v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18653v1</id>
    <updated>2024-10-24T11:32:01Z</updated>
    <published>2024-10-24T11:32:01Z</published>
    <title>Towards Better Open-Ended Text Generation: A Multicriteria Evaluation
  Framework</title>
    <summary>  Open-ended text generation has become a prominent task in natural language
processing due to the rise of powerful (large) language models. However,
evaluating the quality of these models and the employed decoding strategies
remains challenging because of trade-offs among widely used metrics such as
coherence, diversity, and perplexity. Decoding methods often excel in some
metrics while underperforming in others, complicating the establishment of a
clear ranking. In this paper, we present novel ranking strategies within this
multicriteria framework. Specifically, we employ benchmarking approaches based
on partial orderings and present a new summary metric designed to balance
existing automatic indicators, providing a more holistic evaluation of text
generation quality. Furthermore, we discuss the alignment of these approaches
with human judgments. Our experiments demonstrate that the proposed methods
offer a robust way to compare decoding strategies, exhibit similarities with
human preferences, and serve as valuable tools in guiding model selection for
open-ended text generation tasks. Finally, we suggest future directions for
improving evaluation methodologies in text generation. Our codebase, datasets,
and models are publicly available.
</summary>
    <author>
      <name>Esteban Garces Arias</name>
    </author>
    <author>
      <name>Hannah Blocher</name>
    </author>
    <author>
      <name>Julian Rodemann</name>
    </author>
    <author>
      <name>Meimingwei Li</name>
    </author>
    <author>
      <name>Christian Heumann</name>
    </author>
    <author>
      <name>Matthias Aßenmacher</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18653v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18653v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18652v1</id>
    <updated>2024-10-24T11:32:00Z</updated>
    <published>2024-10-24T11:32:00Z</published>
    <title>$C^2$: Scalable Auto-Feedback for LLM-based Chart Generation</title>
    <summary>  Generating high-quality charts with Large Language Models presents
significant challenges due to limited data and the high cost of scaling through
human curation. Instruction, data, and code triplets are scarce and expensive
to manually curate as their creation demands technical expertise. To address
this scalability issue, we introduce a reference-free automatic feedback
generator, which eliminates the need for costly human intervention. Our novel
framework, $C^2$, consists of (1) an automatic feedback provider (ChartAF) and
(2) a diverse, reference-free dataset (ChartUIE-8K). Quantitative results are
compelling: in our first experiment, 74% of respondents strongly preferred, and
10% preferred, the results after feedback. The second post-feedback experiment
demonstrates that ChartAF outperforms nine baselines. Moreover, ChartUIE-8K
significantly improves data diversity by increasing queries, datasets, and
chart types by 5982%, 1936%, and 91%, respectively, over benchmarks. Finally,
an LLM user study revealed that 94% of participants preferred ChartUIE-8K's
queries, with 93% deeming them aligned with real-world use cases. Core
contributions are available as open-source at an anonymized project site, with
ample qualitative examples.
</summary>
    <author>
      <name>Woosung Koh</name>
    </author>
    <author>
      <name>Jang Han Yoon</name>
    </author>
    <author>
      <name>MinHyung Lee</name>
    </author>
    <author>
      <name>Youngjin Song</name>
    </author>
    <author>
      <name>Jaegwan Cho</name>
    </author>
    <author>
      <name>Jaehyun Kang</name>
    </author>
    <author>
      <name>Taehyeon Kim</name>
    </author>
    <author>
      <name>Se-young Yun</name>
    </author>
    <author>
      <name>Youngjae Yu</name>
    </author>
    <author>
      <name>Bongshin Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18652v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18652v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18650v1</id>
    <updated>2024-10-24T11:25:50Z</updated>
    <published>2024-10-24T11:25:50Z</published>
    <title>Counting Locally Optimal Tours in the TSP</title>
    <summary>  We show that the problem of counting the number of 2-optimal tours in
instances of the Travelling Salesperson Problem (TSP) on complete graphs is
#P-complete. In addition, we show that the expected number of 2-optimal tours
in random instances of the TSP on complete graphs is $O(1.2098^n \sqrt{n!})$.
Based on numerical experiments, we conjecture that the true bound is at most
$O(\sqrt{n!})$, which is approximately the square root of the total number of
tours.
</summary>
    <author>
      <name>Bodo Manthey</name>
    </author>
    <author>
      <name>Jesse van Rhijn</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18648v1</id>
    <updated>2024-10-24T11:21:49Z</updated>
    <published>2024-10-24T11:21:49Z</published>
    <title>GADT: Enhancing Transferable Adversarial Attacks through Gradient-guided
  Adversarial Data Transformation</title>
    <summary>  Current Transferable Adversarial Examples (TAE) are primarily generated by
adding Adversarial Noise (AN). Recent studies emphasize the importance of
optimizing Data Augmentation (DA) parameters along with AN, which poses a
greater threat to real-world AI applications. However, existing DA-based
strategies often struggle to find optimal solutions due to the challenging DA
search procedure without proper guidance. In this work, we propose a novel
DA-based attack algorithm, GADT. GADT identifies suitable DA parameters through
iterative antagonism and uses posterior estimates to update AN based on these
parameters. We uniquely employ a differentiable DA operation library to
identify adversarial DA parameters and introduce a new loss function as a
metric during DA optimization. This loss term enhances adversarial effects
while preserving the original image content, maintaining attack crypticity.
Extensive experiments on public datasets with various networks demonstrate that
GADT can be integrated with existing transferable attack methods, updating
their DA parameters effectively while retaining their AN formulation
strategies. Furthermore, GADT can be utilized in other black-box attack
scenarios, e.g., query-based attacks, offering a new avenue to enhance attacks
on real-world AI applications in both research and industrial contexts.
</summary>
    <author>
      <name>Yating Ma</name>
    </author>
    <author>
      <name>Xiaogang Xu</name>
    </author>
    <author>
      <name>Liming Fang</name>
    </author>
    <author>
      <name>Zhe Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18648v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18648v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18647v1</id>
    <updated>2024-10-24T11:19:30Z</updated>
    <published>2024-10-24T11:19:30Z</published>
    <title>Data Scaling Laws in Imitation Learning for Robotic Manipulation</title>
    <summary>  Data scaling has revolutionized fields like natural language processing and
computer vision, providing models with remarkable generalization capabilities.
In this paper, we investigate whether similar data scaling laws exist in
robotics, particularly in robotic manipulation, and whether appropriate data
scaling can yield single-task robot policies that can be deployed zero-shot for
any object within the same category in any environment. To this end, we conduct
a comprehensive empirical study on data scaling in imitation learning. By
collecting data across numerous environments and objects, we study how a
policy's generalization performance changes with the number of training
environments, objects, and demonstrations. Throughout our research, we collect
over 40,000 demonstrations and execute more than 15,000 real-world robot
rollouts under a rigorous evaluation protocol. Our findings reveal several
intriguing results: the generalization performance of the policy follows a
roughly power-law relationship with the number of environments and objects. The
diversity of environments and objects is far more important than the absolute
number of demonstrations; once the number of demonstrations per environment or
object reaches a certain threshold, additional demonstrations have minimal
effect. Based on these insights, we propose an efficient data collection
strategy. With four data collectors working for one afternoon, we collect
sufficient data to enable the policies for two tasks to achieve approximately
90% success rates in novel environments with unseen objects.
</summary>
    <author>
      <name>Fanqi Lin</name>
    </author>
    <author>
      <name>Yingdong Hu</name>
    </author>
    <author>
      <name>Pingyue Sheng</name>
    </author>
    <author>
      <name>Chuan Wen</name>
    </author>
    <author>
      <name>Jiacheng You</name>
    </author>
    <author>
      <name>Yang Gao</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18644v1</id>
    <updated>2024-10-24T11:14:14Z</updated>
    <published>2024-10-24T11:14:14Z</published>
    <title>PASTRAMI: Performance Assessment of SofTware Routers Addressing
  Measurement Instability</title>
    <summary>  Virtualized environments offer a flexible and scalable platform for
evaluating network performance, but they can introduce significant variability
that complicates accurate measurement. This paper presents PASTRAMI, a
methodology designed to assess the stability of software routers, which is
critical to accurately evaluate performance metrics such as the Partial Drop
Rate at 0.5% (PDR@0.5%). While PDR@0.5% is a key metric to assess packet
processing capabilities of a software router, its reliable evaluation depends
on consistent router performance with minimal measurement variability. Our
research reveals that different Linux versions exhibit distinct behaviors, with
some demonstrating non-negligible packet loss even at low loads and high
variability in loss measurements, rendering them unsuitable for accurate
performance assessments. This paper proposes a systematic approach to
differentiate between stable and unstable environments, offering practical
guidance on selecting suitable configurations for robust networking performance
evaluations in virtualized environments.
</summary>
    <author>
      <name>Paolo Lungaroni</name>
    </author>
    <author>
      <name>Andrea Mayer</name>
    </author>
    <author>
      <name>Stefano Salsano</name>
    </author>
    <author>
      <name>Pierpaolo Loreti</name>
    </author>
    <author>
      <name>Lorenzo Bracciale</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of paper submitted to conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18644v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18644v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18641v1</id>
    <updated>2024-10-24T11:10:54Z</updated>
    <published>2024-10-24T11:10:54Z</published>
    <title>Smart ETL and LLM-based contents classification: the European Smart
  Tourism Tools Observatory experience</title>
    <summary>  Purpose: Our research project focuses on improving the content update of the
online European Smart Tourism Tools (STTs) Observatory by incorporating and
categorizing STTs. The categorization is based on their taxonomy, and it
facilitates the end user's search process. The use of a Smart ETL (Extract,
Transform, and Load) process, where \emph{Smart} indicates the use of
Artificial Intelligence (AI), is central to this endeavor.
  Methods: The contents describing STTs are derived from PDF catalogs, where
PDF-scraping techniques extract QR codes, images, links, and text information.
Duplicate STTs between the catalogs are removed, and the remaining ones are
classified based on their text information using Large Language Models (LLMs).
Finally, the data is transformed to comply with the Dublin Core metadata
structure (the observatory's metadata structure), chosen for its wide
acceptance and flexibility.
  Results: The Smart ETL process to import STTs to the observatory combines
PDF-scraping techniques with LLMs for text content-based classification. Our
preliminary results have demonstrated the potential of LLMs for text
content-based classification.
  Conclusion: The proposed approach's feasibility is a step towards efficient
content-based classification, not only in Smart Tourism but also adaptable to
other fields. Future work will mainly focus on refining this classification
process.
</summary>
    <author>
      <name>Diogo Cosme</name>
    </author>
    <author>
      <name>António Galvão</name>
    </author>
    <author>
      <name>Fernando Brito e Abreu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18641v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18641v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7; I.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18640v1</id>
    <updated>2024-10-24T11:06:29Z</updated>
    <published>2024-10-24T11:06:29Z</published>
    <title>Weak-to-Strong Preference Optimization: Stealing Reward from Weak
  Aligned Model</title>
    <summary>  Aligning language models (LMs) with human preferences has become a key area
of research, enabling these models to meet diverse user needs better. Inspired
by weak-to-strong generalization, where a strong LM fine-tuned on labels
generated by a weaker model can consistently outperform its weak supervisor, we
extend this idea to model alignment. In this work, we observe that the
alignment behavior in weaker models can be effectively transferred to stronger
models and even exhibit an amplification effect. Based on this insight, we
propose a method called Weak-to-Strong Preference Optimization (WSPO), which
achieves strong model alignment by learning the distribution differences before
and after the alignment of the weak model. Experiments demonstrate that WSPO
delivers outstanding performance, improving the win rate of Qwen2-7B-Instruct
on Arena-Hard from 39.70 to 49.60, achieving a remarkable 47.04
length-controlled win rate on AlpacaEval 2, and scoring 7.33 on MT-bench. Our
results suggest that using the weak model to elicit a strong model with a high
alignment ability is feasible.
</summary>
    <author>
      <name>Wenhong Zhu</name>
    </author>
    <author>
      <name>Zhiwei He</name>
    </author>
    <author>
      <name>Xiaofeng Wang</name>
    </author>
    <author>
      <name>Pengfei Liu</name>
    </author>
    <author>
      <name>Rui Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18640v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18640v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18639v1</id>
    <updated>2024-10-24T10:58:17Z</updated>
    <published>2024-10-24T10:58:17Z</published>
    <title>Diffusion Attribution Score: Evaluating Training Data Influence in
  Diffusion Model</title>
    <summary>  As diffusion models become increasingly popular, the misuse of copyrighted
and private images has emerged as a major concern. One promising solution to
mitigate this issue is identifying the contribution of specific training
samples in generative models, a process known as data attribution. Existing
data attribution methods for diffusion models typically quantify the
contribution of a training sample by evaluating the change in diffusion loss
when the sample is included or excluded from the training process. However, we
argue that the direct usage of diffusion loss cannot represent such a
contribution accurately due to the calculation of diffusion loss. Specifically,
these approaches measure the divergence between predicted and ground truth
distributions, which leads to an indirect comparison between the predicted
distributions and cannot represent the variances between model behaviors. To
address these issues, we aim to measure the direct comparison between predicted
distributions with an attribution score to analyse the training sample
importance, which is achieved by Diffusion Attribution Score (DAS). Underpinned
by rigorous theoretical analysis, we elucidate the effectiveness of DAS.
Additionally, we explore strategies to accelerate DAS calculations,
facilitating its application to large-scale diffusion models. Our extensive
experiments across various datasets and diffusion models demonstrate that DAS
significantly surpasses previous benchmarks in terms of the linear
data-modelling score, establishing new state-of-the-art performance.
</summary>
    <author>
      <name>Jinxu Lin</name>
    </author>
    <author>
      <name>Linwei Tao</name>
    </author>
    <author>
      <name>Minjing Dong</name>
    </author>
    <author>
      <name>Chang Xu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18638v1</id>
    <updated>2024-10-24T10:56:02Z</updated>
    <published>2024-10-24T10:56:02Z</published>
    <title>Moving Object Segmentation in Point Cloud Data using Hidden Markov
  Models</title>
    <summary>  Autonomous agents require the capability to identify dynamic objects in their
environment for safe planning and navigation. Incomplete and erroneous dynamic
detections jeopardize the agent's ability to accomplish its task. Dynamic
detection is a challenging problem due to the numerous sources of uncertainty
inherent in the problem's inputs and the wide variety of applications, which
often lead to use-case-tailored solutions. We propose a robust learning-free
approach to segment moving objects in point cloud data. The foundation of the
approach lies in modelling each voxel using a hidden Markov model (HMM), and
probabilistically integrating beliefs into a map using an HMM filter. The
proposed approach is tested on benchmark datasets and consistently performs
better than or as well as state-of-the-art methods with strong generalized
performance across sensor characteristics and environments. The approach is
open-sourced at https://github.com/vb44/HMM-MOS.
</summary>
    <author>
      <name>Vedant Bhandari</name>
    </author>
    <author>
      <name>Jasmin James</name>
    </author>
    <author>
      <name>Tyson Phillips</name>
    </author>
    <author>
      <name>P. Ross McAree</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to the IEEE IROS 2024 workshop on Long-Term Perception for
  Autonomy in Dynamic Human-shared Environments: What Do Robots Need?</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18637v1</id>
    <updated>2024-10-24T10:55:21Z</updated>
    <published>2024-10-24T10:55:21Z</published>
    <title>Remote Detection of Applications for Improved Beam Tracking in
  mmWave/sub-THz 5G/6G Systems</title>
    <summary>  Beam tracking is an essential functionality of millimeter wave (mmWave,
30-100 GHz) and sub-terahertz (sub-THz, 100-300 GHz) 5G/6G systems. It operates
by performing antenna sweeping at both base station (BS) and user equipment
(UE) sides using the Synchronization Signal Blocks (SSB). The optimal frequency
of beam tracking events is not specified by 3GPP standards and heavily depends
on the micromobility properties of the applications currently utilized by the
user. In absence of explicit signalling for the type of application at the air
interface, in this paper, we propose a way to remotely detect it at the BS side
based on the received signal strength pattern. To this aim, we first perform a
multi-stage measurement campaign at 156 GHz, belonging to the sub-THz band, to
obtain the received signal strength traces of popular smartphone applications.
Then, we proceed applying conventional statistical Mann-Whitney tests and
various machine learning (ML) based classification techniques to discriminate
applications remotely. Our results show that Mann-Whitney test can be used to
differentiate between fast and slow application classes with a confidence of
0.95 inducing class detection delay on the order of 1 s after application
initialization. With the same time budget, random forest classifiers can
differentiate between applications with fast and slow micromobility with 80%
accuracy using received signal strength metric only. The accuracy of detecting
a specific application however is lower, reaching 60%. By utilizing the
proposed technique one can estimate the optimal values of the beam tracking
intervals without adding additional signalling to the air interface.
</summary>
    <author>
      <name>Alexander Shurakov</name>
    </author>
    <author>
      <name>Margarita Ershova</name>
    </author>
    <author>
      <name>Abdukodir Khakimov</name>
    </author>
    <author>
      <name>Anatoliy Prikhodko</name>
    </author>
    <author>
      <name>Evgeny Mokrov</name>
    </author>
    <author>
      <name>Vyacheslav Begishev</name>
    </author>
    <author>
      <name>Galina Chulkova</name>
    </author>
    <author>
      <name>Yevgeni Koucheryavy</name>
    </author>
    <author>
      <name>Gregory Gol'tsman</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ins-det" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18636v1</id>
    <updated>2024-10-24T10:48:42Z</updated>
    <published>2024-10-24T10:48:42Z</published>
    <title>Multi-agent cooperation through learning-aware policy gradients</title>
    <summary>  Self-interested individuals often fail to cooperate, posing a fundamental
challenge for multi-agent learning. How can we achieve cooperation among
self-interested, independent learning agents? Promising recent work has shown
that in certain tasks cooperation can be established between learning-aware
agents who model the learning dynamics of each other. Here, we present the
first unbiased, higher-derivative-free policy gradient algorithm for
learning-aware reinforcement learning, which takes into account that other
agents are themselves learning through trial and error based on multiple noisy
trials. We then leverage efficient sequence models to condition behavior on
long observation histories that contain traces of the learning dynamics of
other agents. Training long-context policies with our algorithm leads to
cooperative behavior and high returns on standard social dilemmas, including a
challenging environment where temporally-extended action coordination is
required. Finally, we derive from the iterated prisoner's dilemma a novel
explanation for how and when cooperation arises among self-interested
learning-aware agents.
</summary>
    <author>
      <name>Alexander Meulemans</name>
    </author>
    <author>
      <name>Seijin Kobayashi</name>
    </author>
    <author>
      <name>Johannes von Oswald</name>
    </author>
    <author>
      <name>Nino Scherrer</name>
    </author>
    <author>
      <name>Eric Elmoznino</name>
    </author>
    <author>
      <name>Blake Richards</name>
    </author>
    <author>
      <name>Guillaume Lajoie</name>
    </author>
    <author>
      <name>Blaise Agüera y Arcas</name>
    </author>
    <author>
      <name>João Sacramento</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18636v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18636v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18634v1</id>
    <updated>2024-10-24T10:47:30Z</updated>
    <published>2024-10-24T10:47:30Z</published>
    <title>Little Giants: Synthesizing High-Quality Embedding Data at Scale</title>
    <summary>  Synthetic data generation has become an increasingly popular way of training
models without the need for large, manually labeled datasets. For tasks like
text embedding, synthetic data offers diverse and scalable training examples,
significantly reducing the cost of human annotation. However, most current
approaches rely heavily on proprietary models like GPT-4, which are expensive
and inefficient for generating large-scale embedding data. In this paper, we
introduce SPEED, a framework that aligns open-source small models (8B) to
efficiently generate large-scale synthetic embedding data. Through supervised
fine-tuning, preference optimization, and self-improvement, SPEED enables small
open-source models to produce high-quality data. Remarkably, SPEED uses only
less than 1/10 of the GPT API calls, outperforming the state-of-the-art
embedding model E5_mistral when both are trained solely on their synthetic
data. Using this efficient generator, we conduct a comprehensive study on how
various factors within the alignment pipeline impact data quality and reveal
the scaling law for synthetic embedding data.
</summary>
    <author>
      <name>Haonan Chen</name>
    </author>
    <author>
      <name>Liang Wang</name>
    </author>
    <author>
      <name>Nan Yang</name>
    </author>
    <author>
      <name>Yutao Zhu</name>
    </author>
    <author>
      <name>Ziliang Zhao</name>
    </author>
    <author>
      <name>Furu Wei</name>
    </author>
    <author>
      <name>Zhicheng Dou</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18634v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18634v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18633v1</id>
    <updated>2024-10-24T10:47:14Z</updated>
    <published>2024-10-24T10:47:14Z</published>
    <title>Embodied Manipulation with Past and Future Morphologies through an Open
  Parametric Hand Design</title>
    <summary>  A human-shaped robotic hand offers unparalleled versatility and fine motor
skills, enabling it to perform a broad spectrum of tasks with precision, power
and robustness. Across the paleontological record and animal kingdom we see a
wide range of alternative hand and actuation designs. Understanding the
morphological design space and the resulting emergent behaviors can not only
aid our understanding of dexterous manipulation and its evolution, but also
assist design optimization, achieving, and eventually surpassing human
capabilities. Exploration of hand embodiment has to date been limited by
inaccessibility of customizable hands in the real-world, and by the reality gap
in simulation of complex interactions. We introduce an open parametric design
which integrates techniques for simplified customization, fabrication, and
control with design features to maximize behavioral diversity. Non-linear
rolling joints, anatomical tendon routing, and a low degree-of-freedom,
modulating, actuation system, enable rapid production of single-piece 3D
printable hands without compromising dexterous behaviors. To demonstrate this,
we evaluated the design's low-level behavior range and stability, showing
variable stiffness over two orders of magnitude. Additionally, we fabricated
three hand designs: human, mirrored human with two thumbs, and aye-aye hands.
Manipulation tests evaluate the variation in each hand's proficiency at
handling diverse objects, and demonstrate emergent behaviors unique to each
design. Overall, we shed light on new possible designs for robotic hands,
provide a design space to compare and contrast different hand morphologies and
structures, and share a practical and open-source design for exploring embodied
manipulation.
</summary>
    <author>
      <name>Kieran Gilday</name>
    </author>
    <author>
      <name>Chapa Sirithunge</name>
    </author>
    <author>
      <name>Fumiya Iida</name>
    </author>
    <author>
      <name>Josie Hughes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">44 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18633v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18633v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18631v1</id>
    <updated>2024-10-24T10:43:04Z</updated>
    <published>2024-10-24T10:43:04Z</published>
    <title>Leveraging Graph Neural Networks and Multi-Agent Reinforcement Learning
  for Inventory Control in Supply Chains</title>
    <summary>  Inventory control in modern supply chains has attracted significant attention
due to the increasing number of disruptive shocks and the challenges posed by
complex dynamics, uncertainties, and limited collaboration. Traditional
methods, which often rely on static parameters, struggle to adapt to changing
environments. This paper proposes a Multi-Agent Reinforcement Learning (MARL)
framework with Graph Neural Networks (GNNs) for state representation to address
these limitations.
  Our approach redefines the action space by parameterizing heuristic inventory
control policies, making it adaptive as the parameters dynamically adjust based
on system conditions. By leveraging the inherent graph structure of supply
chains, our framework enables agents to learn the system's topology, and we
employ a centralized learning, decentralized execution scheme that allows
agents to learn collaboratively while overcoming information-sharing
constraints. Additionally, we incorporate global mean pooling and
regularization techniques to enhance performance.
  We test the capabilities of our proposed approach on four different supply
chain configurations and conduct a sensitivity analysis. This work paves the
way for utilizing MARL-GNN frameworks to improve inventory management in
complex, decentralized supply chain environments.
</summary>
    <author>
      <name>Niki Kotecha</name>
    </author>
    <author>
      <name>Antonio del Rio Chanona</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18630v1</id>
    <updated>2024-10-24T10:40:38Z</updated>
    <published>2024-10-24T10:40:38Z</published>
    <title>A Cranial-Feature-Based Registration Scheme for Robotic
  Micromanipulation Using a Microscopic Stereo Camera System</title>
    <summary>  Biological specimens exhibit significant variations in size and shape,
challenging autonomous robotic manipulation. We focus on the mouse skull window
creation task to illustrate these challenges. The study introduces a
microscopic stereo camera system (MSCS) enhanced by the linear model for depth
perception. Alongside this, a precise registration scheme is developed for the
partially exposed mouse cranial surface, employing a CNN-based constrained and
colorized registration strategy. These methods are integrated with the MSCS for
robotic micromanipulation tasks. The MSCS demonstrated a high precision of 0.10
mm $\pm$ 0.02 mm measured in a step height experiment and real-time performance
of 30 FPS in 3D reconstruction. The registration scheme proved its precision,
with a translational error of 1.13 mm $\pm$ 0.31 mm and a rotational error of
3.38$^{\circ}$ $\pm$ 0.89$^{\circ}$ tested on 105 continuous frames with an
average speed of 1.60 FPS. This study presents the application of a MSCS and a
novel registration scheme in enhancing the precision and accuracy of robotic
micromanipulation in scientific and surgical settings. The innovations
presented here offer automation methodology in handling the challenges of
microscopic manipulation, paving the way for more accurate, efficient, and less
invasive procedures in various fields of microsurgery and scientific research.
</summary>
    <author>
      <name>Xiaofeng Lin</name>
    </author>
    <author>
      <name>Saúl Alexis Heredia Pérez</name>
    </author>
    <author>
      <name>Kanako Harada</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/01691864.2024.2415092</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/01691864.2024.2415092" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by Advanced Robotics, Vol. 38, Issue 21</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18630v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18630v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18629v1</id>
    <updated>2024-10-24T10:39:49Z</updated>
    <published>2024-10-24T10:39:49Z</published>
    <title>Supporting Assessment of Novelty of Design Problems Using Concept of
  Problem SAPPhIRE</title>
    <summary>  This paper proposes a framework for assessing the novelty of design problems
using the SAPPhIRE model of causality. The novelty of a problem is measured as
its minimum distance from the problems in a reference problem database. The
distance is calculated by comparing the current problem and each reference past
problem at the various levels of abstraction in the SAPPhIRE ontology. The
basis for comparison is textual similarity. To demonstrate the applicability of
the proposed framework, The current set of problems associated with an
artifact, as collected from its stakeholders, were compared with the past set
of problems, as collected from patents and other web sources, to assess the
novelty of the current set. This approach is aimed at providing a better
understanding of the degree of novelty of any given set of current problems by
comparing them to similar problems available from historical records. Since
manual assessment, the current mode of such assessments as reported in the
literature, is a tedious process, to reduce time complexity and to afford
better applicability for larger sets of problem statements, an automated
assessment is proposed and used in this paper.
</summary>
    <author>
      <name>Sanjay Singh</name>
    </author>
    <author>
      <name>Amaresh Chakrabarti</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18628v1</id>
    <updated>2024-10-24T10:37:54Z</updated>
    <published>2024-10-24T10:37:54Z</published>
    <title>Wavetable Synthesis Using CVAE for Timbre Control Based on Semantic
  Label</title>
    <summary>  Synthesizers are essential in modern music production. However, their complex
timbre parameters, often filled with technical terms, require expertise. This
research introduces a method of timbre control in wavetable synthesis that is
intuitive and sensible and utilizes semantic labels. Using a conditional
variational autoencoder (CVAE), users can select a wavetable and define the
timbre with labels such as bright, warm, and rich. The CVAE model, featuring
convolutional and upsampling layers, effectively captures the wavetable
nuances, ensuring real-time performance owing to their processing in the time
domain. Experiments demonstrate that this approach allows for real-time,
effective control of the timbre of the wavetable using semantic inputs and aims
for intuitive timbre control through data-based semantic control.
</summary>
    <author>
      <name>Tsugumasa Yutani</name>
    </author>
    <author>
      <name>Yuya Yamamoto</name>
    </author>
    <author>
      <name>Shuyo Nakatani</name>
    </author>
    <author>
      <name>Hiroko Terasawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures, Accepted at APSIPA ASC 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18627v1</id>
    <updated>2024-10-24T10:36:16Z</updated>
    <published>2024-10-24T10:36:16Z</published>
    <title>Dynamic Content Caching with Waiting Costs via Restless Multi-Armed
  Bandits</title>
    <summary>  We consider a system with a Base Station (BS) associated with local cache,
which in turn is connected to the backend server and users. The contents get
continuously updated at the backend server, and the BS has a local copy of the
subset of the contents. Upon receiving a request from the user, the BS can
either fetch a fresh version or, serve the local copy or can wait for
additional requests before serving. Fetching content from the BS incurs a fixed
fetching cost, serving it locally incurs an aging cost, and for each request
waiting at the BS, there will be a waiting for cost per unit time. The aging
cost relies on the freshness of the content, which is measured by a metric age
of version (AoV). We aim to minimize the average cost subject to cache capacity
constraints. We pose the problem as Restless Multi-armed Bandits Problem (RMAB)
and propose a Whittle index-based policy that performs very close to the
optimal policy.
</summary>
    <author>
      <name>Ankita Koley</name>
    </author>
    <author>
      <name>Chandramani Singh</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18627v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18627v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18626v1</id>
    <updated>2024-10-24T10:35:02Z</updated>
    <published>2024-10-24T10:35:02Z</published>
    <title>SAMG: State-Action-Aware Offline-to-Online Reinforcement Learning with
  Offline Model Guidance</title>
    <summary>  The offline-to-online (O2O) paradigm in reinforcement learning (RL) utilizes
pre-trained models on offline datasets for subsequent online fine-tuning.
However, conventional O2O RL algorithms typically require maintaining and
retraining the large offline datasets to mitigate the effects of
out-of-distribution (OOD) data, which limits their efficiency in exploiting
online samples. To address this challenge, we introduce a new paradigm called
SAMG: State-Action-Conditional Offline-to-Online Reinforcement Learning with
Offline Model Guidance. In particular, rather than directly training on offline
data, SAMG freezes the pre-trained offline critic to provide offline values for
each state-action pair to deliver compact offline information. This framework
eliminates the need for retraining with offline data by freezing and leveraging
these values of the offline model. These are then incorporated with the online
target critic using a Bellman equation weighted by a policy state-action-aware
coefficient. This coefficient, derived from a conditional variational
auto-encoder (C-VAE), aims to capture the reliability of the offline data on a
state-action level. SAMG could be easily integrated with existing Q-function
based O2O RL algorithms. Theoretical analysis shows good optimality and lower
estimation error of SAMG. Empirical evaluations demonstrate that SAMG
outperforms four state-of-the-art O2O RL algorithms in the D4RL benchmark.
</summary>
    <author>
      <name>Liyu Zhang</name>
    </author>
    <author>
      <name>Haochi Wu</name>
    </author>
    <author>
      <name>Xu Wan</name>
    </author>
    <author>
      <name>Quan Kong</name>
    </author>
    <author>
      <name>Ruilong Deng</name>
    </author>
    <author>
      <name>Mingyang Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18626v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18626v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18624v1</id>
    <updated>2024-10-24T10:32:10Z</updated>
    <published>2024-10-24T10:32:10Z</published>
    <title>Prompting and Fine-Tuning of Small LLMs for Length-Controllable
  Telephone Call Summarization</title>
    <summary>  This paper explores the rapid development of a telephone call summarization
system utilizing large language models (LLMs). Our approach involves initial
experiments with prompting existing LLMs to generate summaries of telephone
conversations, followed by the creation of a tailored synthetic training
dataset utilizing stronger frontier models. We place special focus on the
diversity of the generated data and on the ability to control the length of the
generated summaries to meet various use-case specific requirements. The
effectiveness of our method is evaluated using two state-of-the-art
LLM-as-a-judge-based evaluation techniques to ensure the quality and relevance
of the summaries. Our results show that fine-tuned Llama-2-7B-based
summarization model performs on-par with GPT-4 in terms of factual accuracy,
completeness and conciseness. Our findings demonstrate the potential for
quickly bootstrapping a practical and efficient call summarization system.
</summary>
    <author>
      <name>David Thulke</name>
    </author>
    <author>
      <name>Yingbo Gao</name>
    </author>
    <author>
      <name>Rricha Jalota</name>
    </author>
    <author>
      <name>Christian Dugast</name>
    </author>
    <author>
      <name>Hermann Ney</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the The International Conference on Foundation and Large
  Language Models (FLLM2024)</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18624v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18624v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18622v1</id>
    <updated>2024-10-24T10:27:29Z</updated>
    <published>2024-10-24T10:27:29Z</published>
    <title>Environment Maps Editing using Inverse Rendering and Adversarial
  Implicit Functions</title>
    <summary>  Editing High Dynamic Range (HDR) environment maps using an inverse
differentiable rendering architecture is a complex inverse problem due to the
sparsity of relevant pixels and the challenges in balancing light sources and
background. The pixels illuminating the objects are a small fraction of the
total image, leading to noise and convergence issues when the optimization
directly involves pixel values. HDR images, with pixel values beyond the
typical Standard Dynamic Range (SDR), pose additional challenges. Higher
learning rates corrupt the background during optimization, while lower learning
rates fail to manipulate light sources. Our work introduces a novel method for
editing HDR environment maps using a differentiable rendering, addressing
sparsity and variance between values. Instead of introducing strong priors that
extract the relevant HDR pixels and separate the light sources, or using tricks
such as optimizing the HDR image in the log space, we propose to model the
optimized environment map with a new variant of implicit neural representations
able to handle HDR images. The neural representation is trained with
adversarial perturbations over the weights to ensure smooth changes in the
output when it receives gradients from the inverse rendering. In this way, we
obtain novel and cheap environment maps without relying on latent spaces of
expensive generative models, maintaining the original visual consistency.
Experimental results demonstrate the method's effectiveness in reconstructing
the desired lighting effects while preserving the fidelity of the map and
reflections on objects in the scene. Our approach can pave the way to
interesting tasks, such as estimating a new environment map given a rendering
with novel light sources, maintaining the initial perceptual features, and
enabling brush stroke-based editing of existing environment maps.
</summary>
    <author>
      <name>Antonio D'Orazio</name>
    </author>
    <author>
      <name>Davide Sforza</name>
    </author>
    <author>
      <name>Fabio Pellacini</name>
    </author>
    <author>
      <name>Iacopo Masi</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18621v1</id>
    <updated>2024-10-24T10:21:23Z</updated>
    <published>2024-10-24T10:21:23Z</published>
    <title>Evolutionary Dispersal of Ecological Species via Multi-Agent Deep
  Reinforcement Learning</title>
    <summary>  Understanding species dynamics in heterogeneous environments is essential for
ecosystem studies. Traditional models assumed homogeneous habitats, but recent
approaches include spatial and temporal variability, highlighting species
migration. We adopt starvation-driven diffusion (SDD) models as nonlinear
diffusion to describe species dispersal based on local resource conditions,
showing advantages for species survival. However, accurate prediction remains
challenging due to model simplifications. This study uses multi-agent
reinforcement learning (MARL) with deep Q-networks (DQN) to simulate single
species and predator-prey interactions, incorporating SDD-type rewards. Our
simulations reveal evolutionary dispersal strategies, providing insights into
species dispersal mechanisms and validating traditional mathematical models.
</summary>
    <author>
      <name>Wonhyung Choi</name>
    </author>
    <author>
      <name>Inkyung Ahn</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="35J60, 35K57, 92D25, 68T05, 93E35" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18618v1</id>
    <updated>2024-10-24T10:17:48Z</updated>
    <published>2024-10-24T10:17:48Z</published>
    <title>Adiabatic training for Variational Quantum Algorithms</title>
    <summary>  This paper presents a new hybrid Quantum Machine Learning (QML) model
composed of three elements: a classical computer in charge of the data
preparation and interpretation; a Gate-based Quantum Computer running the
Variational Quantum Algorithm (VQA) representing the Quantum Neural Network
(QNN); and an adiabatic Quantum Computer where the optimization function is
executed to find the best parameters for the VQA.
  As of the moment of this writing, the majority of QNNs are being trained
using gradient-based classical optimizers having to deal with the
barren-plateau effect. Some gradient-free classical approaches such as
Evolutionary Algorithms have also been proposed to overcome this effect. To the
knowledge of the authors, adiabatic quantum models have not been used to train
VQAs.
  The paper compares the results of gradient-based classical algorithms against
adiabatic optimizers showing the feasibility of integration for gate-based and
adiabatic quantum computing models, opening the door to modern hybrid QML
approaches for High Performance Computing.
</summary>
    <author>
      <name>Ernesto Acosta</name>
    </author>
    <author>
      <name>Carlos Cano Gutierrez</name>
    </author>
    <author>
      <name>Guillermo Botella</name>
    </author>
    <author>
      <name>Roberto Campos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 6 figures, Euro PAR 2024 EuroQHPC Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18615v1</id>
    <updated>2024-10-24T10:16:09Z</updated>
    <published>2024-10-24T10:16:09Z</published>
    <title>FairQueue: Rethinking Prompt Learning for Fair Text-to-Image Generation</title>
    <summary>  Recently, prompt learning has emerged as the state-of-the-art (SOTA) for fair
text-to-image (T2I) generation. Specifically, this approach leverages readily
available reference images to learn inclusive prompts for each target Sensitive
Attribute (tSA), allowing for fair image generation. In this work, we first
reveal that this prompt learning-based approach results in degraded sample
quality. Our analysis shows that the approach's training objective -- which
aims to align the embedding differences of learned prompts and reference images
-- could be sub-optimal, resulting in distortion of the learned prompts and
degraded generated images. To further substantiate this claim, as our major
contribution, we deep dive into the denoising subnetwork of the T2I model to
track down the effect of these learned prompts by analyzing the cross-attention
maps. In our analysis, we propose a novel prompt switching analysis: I2H and
H2I. Furthermore, we propose new quantitative characterization of
cross-attention maps. Our analysis reveals abnormalities in the early denoising
steps, perpetuating improper global structure that results in degradation in
the generated samples. Building on insights from our analysis, we propose two
ideas: (i) Prompt Queuing and (ii) Attention Amplification to address the
quality issue. Extensive experimental results on a wide range of tSAs show that
our proposed method outperforms SOTA approach's image generation quality, while
achieving competitive fairness. More resources at FairQueue Project site:
https://sutd-visual-computing-group.github.io/FairQueue
</summary>
    <author>
      <name>Christopher T. H Teo</name>
    </author>
    <author>
      <name>Milad Abdollahzadeh</name>
    </author>
    <author>
      <name>Xinda Ma</name>
    </author>
    <author>
      <name>Ngai-man Cheung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in NeurIPS24</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18613v1</id>
    <updated>2024-10-24T10:08:25Z</updated>
    <published>2024-10-24T10:08:25Z</published>
    <title>Rethinking Softmax: Self-Attention with Polynomial Activations</title>
    <summary>  This paper challenges the conventional belief that softmax attention in
transformers is effective primarily because it generates a probability
distribution for attention allocation. Instead, we theoretically show that its
success lies in its ability to implicitly regularize the Frobenius norm of the
attention matrix during training. We then explore alternative activations that
regularize the Frobenius norm of the attention matrix, demonstrating that
certain polynomial activations can achieve this effect, making them suitable
for attention-based architectures. Empirical results indicate these activations
perform comparably or better than softmax across various computer vision and
language tasks, suggesting new possibilities for attention mechanisms beyond
softmax.
</summary>
    <author>
      <name>Hemanth Saratchandran</name>
    </author>
    <author>
      <name>Jianqiao Zheng</name>
    </author>
    <author>
      <name>Yiping Ji</name>
    </author>
    <author>
      <name>Wenbo Zhang</name>
    </author>
    <author>
      <name>Simon Lucey</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18613v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18613v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18612v1</id>
    <updated>2024-10-24T10:08:05Z</updated>
    <published>2024-10-24T10:08:05Z</published>
    <title>TripCast: Pre-training of Masked 2D Transformers for Trip Time Series
  Forecasting</title>
    <summary>  Deep learning and pre-trained models have shown great success in time series
forecasting. However, in the tourism industry, time series data often exhibit a
leading time property, presenting a 2D structure. This introduces unique
challenges for forecasting in this sector. In this study, we propose a novel
modelling paradigm, TripCast, which treats trip time series as 2D data and
learns representations through masking and reconstruction processes.
Pre-trained on large-scale real-world data, TripCast notably outperforms other
state-of-the-art baselines in in-domain forecasting scenarios and demonstrates
strong scalability and transferability in out-domain forecasting scenarios.
</summary>
    <author>
      <name>Yuhua Liao</name>
    </author>
    <author>
      <name>Zetian Wang</name>
    </author>
    <author>
      <name>Peng Wei</name>
    </author>
    <author>
      <name>Qiangqiang Nie</name>
    </author>
    <author>
      <name>Zhenhua Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by ICONIP 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18612v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18612v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18610v1</id>
    <updated>2024-10-24T10:06:45Z</updated>
    <published>2024-10-24T10:06:45Z</published>
    <title>A Joint Representation Using Continuous and Discrete Features for
  Cardiovascular Diseases Risk Prediction on Chest CT Scans</title>
    <summary>  Cardiovascular diseases (CVD) remain a leading health concern and contribute
significantly to global mortality rates. While clinical advancements have led
to a decline in CVD mortality, accurately identifying individuals who could
benefit from preventive interventions remains an unsolved challenge in
preventive cardiology. Current CVD risk prediction models, recommended by
guidelines, are based on limited traditional risk factors or use CT imaging to
acquire quantitative biomarkers, and still have limitations in predictive
accuracy and applicability. On the other hand, end-to-end trained CVD risk
prediction methods leveraging deep learning on CT images often fail to provide
transparent and explainable decision grounds for assisting physicians. In this
work, we proposed a novel joint representation that integrates discrete
quantitative biomarkers and continuous deep features extracted from chest CT
scans. Our approach initiated with a deep CVD risk classification model by
capturing comprehensive continuous deep learning features while jointly
obtaining currently clinical-established quantitative biomarkers via
segmentation models. In the feature joint representation stage, we use an
instance-wise feature-gated mechanism to align the continuous and discrete
features, followed by a soft instance-wise feature interaction mechanism
fostering independent and effective feature interaction for the final CVD risk
prediction. Our method substantially improves CVD risk predictive performance
and offers individual contribution analysis of each biomarker, which is
important in assisting physicians' decision-making processes. We validated our
method on a public chest low-dose CT dataset and a private external chest
standard-dose CT patient cohort of 17,207 CT volumes from 6,393 unique
subjects, and demonstrated superior predictive performance, achieving AUCs of
0.875 and 0.843, respectively.
</summary>
    <author>
      <name>Minfeng Xu</name>
    </author>
    <author>
      <name>Chen-Chen Fan</name>
    </author>
    <author>
      <name>Yan-Jie Zhou</name>
    </author>
    <author>
      <name>Wenchao Guo</name>
    </author>
    <author>
      <name>Pan Liu</name>
    </author>
    <author>
      <name>Jing Qi</name>
    </author>
    <author>
      <name>Le Lu</name>
    </author>
    <author>
      <name>Hanqing Chao</name>
    </author>
    <author>
      <name>Kunlun He</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.IV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18609v1</id>
    <updated>2024-10-24T10:06:30Z</updated>
    <published>2024-10-24T10:06:30Z</published>
    <title>Computation of symmetries of rational surfaces</title>
    <summary>  In this paper we provide, first, a general symbolic algorithm for computing
the symmetries of a given rational surface, based on the classical differential
invariants of surfaces, i.e. Gauss curvature and mean curvature. In practice,
the algorithm works well for sparse parametrizations (e.g. toric surfaces) and
PN surfaces. Additionally, we provide a specific, also symbolic algorithm for
computing the symmetries of ruled surfaces; this algorithm works extremely well
in practice, since the problem is reduced to that of rational space curves,
which can be efficiently solved by using existing methods. The algorithm for
ruled surfaces is based on the fact, proven in the paper, that every symmetry
of a rational surface must also be a symmetry of its line of striction, which
is a rational space curve. The algorithms have been implemented in the computer
algebra system Maple, and the implementations have been made public; evidence
of their performance is given in the paper.
</summary>
    <author>
      <name>Juan Juan Gerardo Alcázar</name>
    </author>
    <author>
      <name>Carlos Hermoso</name>
    </author>
    <author>
      <name>Hüsnü Anıl Çoban</name>
    </author>
    <author>
      <name>Uğur Gözütok</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18609v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18609v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18608v1</id>
    <updated>2024-10-24T10:05:41Z</updated>
    <published>2024-10-24T10:05:41Z</published>
    <title>Learning Transparent Reward Models via Unsupervised Feature Selection</title>
    <summary>  In complex real-world tasks such as robotic manipulation and autonomous
driving, collecting expert demonstrations is often more straightforward than
specifying precise learning objectives and task descriptions. Learning from
expert data can be achieved through behavioral cloning or by learning a reward
function, i.e., inverse reinforcement learning. The latter allows for training
with additional data outside the training distribution, guided by the inferred
reward function. We propose a novel approach to construct compact and
transparent reward models from automatically selected state features. These
inferred rewards have an explicit form and enable the learning of policies that
closely match expert behavior by training standard reinforcement learning
algorithms from scratch. We validate our method's performance in various
robotic environments with continuous and high-dimensional state spaces.
Webpage: \url{https://sites.google.com/view/transparent-reward}.
</summary>
    <author>
      <name>Daulet Baimukashev</name>
    </author>
    <author>
      <name>Gokhan Alcan</name>
    </author>
    <author>
      <name>Kevin Sebastian Luck</name>
    </author>
    <author>
      <name>Ville Kyrki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18607v1</id>
    <updated>2024-10-24T10:04:24Z</updated>
    <published>2024-10-24T10:04:24Z</published>
    <title>STTATTS: Unified Speech-To-Text And Text-To-Speech Model</title>
    <summary>  Speech recognition and speech synthesis models are typically trained
separately, each with its own set of learning objectives, training data, and
model parameters, resulting in two distinct large networks. We propose a
parameter-efficient approach to learning ASR and TTS jointly via a multi-task
learning objective and shared parameters. Our evaluation demonstrates that the
performance of our multi-task model is comparable to that of individually
trained models while significantly saving computational and memory costs
($\sim$50\% reduction in the total number of parameters required for the two
tasks combined). We experiment with English as a resource-rich language, and
Arabic as a relatively low-resource language due to shortage of TTS data. Our
models are trained with publicly available data, and both the training code and
model checkpoints are openly available for further research.
</summary>
    <author>
      <name>Hawau Olamide Toyin</name>
    </author>
    <author>
      <name>Hao Li</name>
    </author>
    <author>
      <name>Hanan Aldarmaki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 Figures, EMNLP 2024 Findings</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18605v1</id>
    <updated>2024-10-24T09:59:10Z</updated>
    <published>2024-10-24T09:59:10Z</published>
    <title>Understanding Players as if They Are Talking to the Game in a Customized
  Language: A Pilot Study</title>
    <summary>  This pilot study explores the application of language models (LMs) to model
game event sequences, treating them as a customized natural language. We
investigate a popular mobile game, transforming raw event data into textual
sequences and pretraining a Longformer model on this data. Our approach
captures the rich and nuanced interactions within game sessions, effectively
identifying meaningful player segments. The results demonstrate the potential
of self-supervised LMs in enhancing game design and personalization without
relying on ground-truth labels.
</summary>
    <author>
      <name>Tianze Wang</name>
    </author>
    <author>
      <name>Maryam Honari-Jahromi</name>
    </author>
    <author>
      <name>Styliani Katsarou</name>
    </author>
    <author>
      <name>Olga Mikheeva</name>
    </author>
    <author>
      <name>Theodoros Panagiotakopoulos</name>
    </author>
    <author>
      <name>Oleg Smirnov</name>
    </author>
    <author>
      <name>Lele Cao</name>
    </author>
    <author>
      <name>Sahar Asadi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">published in Workshop on Customizable NLP at EMNLP 2024</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18605v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18605v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18603v1</id>
    <updated>2024-10-24T09:58:40Z</updated>
    <published>2024-10-24T09:58:40Z</published>
    <title>AgentStore: Scalable Integration of Heterogeneous Agents As Specialized
  Generalist Computer Assistant</title>
    <summary>  Digital agents capable of automating complex computer tasks have attracted
considerable attention due to their immense potential to enhance human-computer
interaction. However, existing agent methods exhibit deficiencies in their
generalization and specialization capabilities, especially in handling
open-ended computer tasks in real-world environments. Inspired by the rich
functionality of the App store, we present AgentStore, a scalable platform
designed to dynamically integrate heterogeneous agents for automating computer
tasks. AgentStore empowers users to integrate third-party agents, allowing the
system to continuously enrich its capabilities and adapt to rapidly evolving
operating systems. Additionally, we propose a novel core \textbf{MetaAgent}
with the \textbf{AgentToken} strategy to efficiently manage diverse agents and
utilize their specialized and generalist abilities for both domain-specific and
system-wide tasks. Extensive experiments on three challenging benchmarks
demonstrate that AgentStore surpasses the limitations of previous systems with
narrow capabilities, particularly achieving a significant improvement from
11.21\% to 23.85\% on the OSWorld benchmark, more than doubling the previous
results. Comprehensive quantitative and qualitative results further demonstrate
AgentStore's ability to enhance agent systems in both generalization and
specialization, underscoring its potential for developing the specialized
generalist computer assistant. All our codes will be made publicly available in
https://chengyou-jia.github.io/AgentStore-Home.
</summary>
    <author>
      <name>Chengyou Jia</name>
    </author>
    <author>
      <name>Minnan Luo</name>
    </author>
    <author>
      <name>Zhuohang Dang</name>
    </author>
    <author>
      <name>Qiushi Sun</name>
    </author>
    <author>
      <name>Fangzhi Xu</name>
    </author>
    <author>
      <name>Junlin Hu</name>
    </author>
    <author>
      <name>Tianbao Xie</name>
    </author>
    <author>
      <name>Zhiyong Wu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18603v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18603v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18602v1</id>
    <updated>2024-10-24T09:56:24Z</updated>
    <published>2024-10-24T09:56:24Z</published>
    <title>Fair Diffusion Auctions</title>
    <summary>  Diffusion auction design is a new trend in mechanism design which extended
the original incentive compatibility property to include buyers' private
connection report. Reporting connections is equivalent to inviting their
neighbors to join the auction in practice. The social welfare of a diffusion
auction is collectively accumulated by all participants: reporting high
valuations or inviting high-valuation neighbors. Because of this, we can
measure each participant's contribution by the marginal social welfare increase
due to her participation.
  Therefore, in this paper, we introduce a new property called \textit{Shapley
fairness} to capture their social welfare contribution and to use it as a
benchmark to guide our auction design for a fairer utility allocation. Not
surprisingly, none of the existing diffusion auctions has ever approximated the
fairness, because Shapley fairness depends on each buyer's own valuation and
this dependence can easily violate incentive compatibility. Thus, we combat
this challenge by proposing a new diffusion auction called \textit{Permutation
Diffusion Auction} (PDA) for selling $k$ homogeneous items, which is the first
diffusion auction satisfying $\frac{1}{k+1}$-Shapley fairness, incentive
compatibility and individual rationality. Furthermore, PDA can be extended to
the general combinatorial auction setting where the literature did not discover
meaningful diffusion auctions yet.
</summary>
    <author>
      <name>Zixin Gu</name>
    </author>
    <author>
      <name>Yaoxin Ge</name>
    </author>
    <author>
      <name>Yao Zhang</name>
    </author>
    <author>
      <name>Dengji Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18593v1</id>
    <updated>2024-10-24T09:42:52Z</updated>
    <published>2024-10-24T09:42:52Z</published>
    <title>Differential Informed Auto-Encoder</title>
    <summary>  In this article, an encoder was trained to obtain the inner structure of the
original data by obtain a differential equations. A decoder was trained to
resample the original data domain, to generate new data that obey the
differential structure of the original data using the physics-informed neural
network.
</summary>
    <author>
      <name>Jinrui Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18593v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18593v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18592v1</id>
    <updated>2024-10-24T09:42:46Z</updated>
    <published>2024-10-24T09:42:46Z</published>
    <title>Tensor-generated matrices and tensor H-eigenvalues distribution</title>
    <summary>  In this work, we introduce the concept of tensor-generated matrices, which
transform an $m$-order $n$-dimensional tensor into an $n$-dimensional square
matrix by grouping corresponding elements. We demonstrate that if the
tensor-generated matrix from tensor $\mathcal{A}$ is an $H$-matrix, then
$\mathcal{A}$ must be an $H$-tensor. While classical eigenvalue distributions
for matrices are well-established, they do not directly apply to tensor
eigenvalues, such as Brauer's Ovals of Cassini sets, Ostrowski sets, and
$S$-type inclusion sets. To overcome this challenge, we aim to convert
high-order tensor $H$-eigenvalue localization into tensor-generated matrix
eigenvalue localization. By establishing connections, we successfully obtain
higher-order tensor $H$-eigenvalue distributions based on the subclass of
$H$-matrices and matrix eigenvalue distributions. This approach enables us to
extend existing matrix eigenvalue localization sets to higher-order tensor
eigenvalues, resulting in modified versions of Brauer's Ovals of Cassini sets,
Ostrowski sets, and $S$-type inclusion sets.
</summary>
    <author>
      <name>Liang Xiong</name>
    </author>
    <author>
      <name>Jianzhou Liu</name>
    </author>
    <link href="http://arxiv.org/abs/2410.18592v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18592v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18590v1</id>
    <updated>2024-10-24T09:41:47Z</updated>
    <published>2024-10-24T09:41:47Z</published>
    <title>Speech perception: a model of word recognition</title>
    <summary>  We present a model of speech perception which takes into account effects of
correlations between sounds. Words in this model correspond to the attractors
of a suitably chosen descent dynamics. The resulting lexicon is rich in short
words, and much less so in longer ones, as befits a reasonable word length
distribution. We separately examine the decryption of short and long words in
the presence of mishearings. In the regime of short words, the algorithm either
quickly retrieves a word, or proposes another valid word. In the regime of
longer words, the behaviour is markedly different. While the successful
decryption of words continues to be relatively fast, there is a finite
probability of getting lost permanently, as the algorithm wanders round the
landscape of suitable words without ever settling on one.
</summary>
    <author>
      <name>Jean-Marc Luck</name>
    </author>
    <author>
      <name>Anita Mehta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 19 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18590v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18590v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2410.18588v1</id>
    <updated>2024-10-24T09:37:23Z</updated>
    <published>2024-10-24T09:37:23Z</published>
    <title>Knowledge Distillation Using Frontier Open-source LLMs: Generalizability
  and the Role of Synthetic Data</title>
    <summary>  Leading open-source large language models (LLMs) such as
Llama-3.1-Instruct-405B are extremely capable at generating text, answering
questions, and solving a variety of natural language understanding tasks.
However, they incur higher inference cost and latency compared to smaller LLMs.
Knowledge distillation provides a way to use outputs from these large, capable
teacher models to train smaller student models which can be used for inference
at lower cost and latency, while retaining comparable accuracy. We investigate
the efficacy of distillation using the Llama-3.1-405B-Instruct teacher and the
smaller Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct student models.
Contributions of this work include (a) We evaluate the generalizability of
distillation with the above Llama-3.1 teacher-student pairs across different
tasks and datasets (b) We show that using synthetic data during distillation
significantly improves the accuracy of 8B and 70B models, and when used with
reasoning chains, even matches or surpasses the zero-shot accuracy of 405B
model on some datasets (c) We empirically show that distillation enables 8B and
70B models to internalize 405B's reasoning ability by using only standard
fine-tuning (without customizing any loss function). This allows cost and
latency-efficient student model inference. (d) We show pitfalls in evaluation
of distillation, and present task-specific evaluation, including both human and
LLM-grading, and ground-truth based traditional accuracy benchmarks. This
methodical study brings out the fundamental importance of synthetic data
quality in knowledge distillation, and of combining multiple, task-specific
ways of accuracy and quality evaluation in assessing the effectiveness of
distillation.
</summary>
    <author>
      <name>Anup Shirgaonkar</name>
    </author>
    <author>
      <name>Nikhil Pandey</name>
    </author>
    <author>
      <name>Nazmiye Ceren Abay</name>
    </author>
    <author>
      <name>Tolga Aktas</name>
    </author>
    <author>
      <name>Vijay Aski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2410.18588v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2410.18588v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
